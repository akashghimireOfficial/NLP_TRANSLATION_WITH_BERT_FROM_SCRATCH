{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c38fb8b9",
   "metadata": {},
   "source": [
    "## **BERT** \n",
    ">__[*original Turtorial Link*](https://www.tensorflow.org/text/tutorials/transformer)__\n",
    "\n",
    "### Turtorial Summary\n",
    "1. Downloading the Dataset\n",
    "2. Text tokenization & detokenization\n",
    "3. Setup of Input Pipeline \n",
    "4. Positional Encoding\n",
    "5. Buidling Transformer Model from Scracth\n",
    "6. Setting Hyperparameters \n",
    "7. Training and CheckPointing\n",
    "8. Attention Plot\n",
    "9. Exporting the saved model\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ffeb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d7cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad6b0ba5",
   "metadata": {},
   "source": [
    "#### Downloading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9555412",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading the Dataset\n",
    "## useing Tensorflow datasets\n",
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017a9efe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
      "mas e se estes fatores fossem ativos ?\n",
      "mas eles não tinham a curiosidade de me testar .\n",
      "\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "##if got time look more for what does the take() method refers to \n",
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "    for pt in pt_examples.numpy():\n",
    "        print(pt.decode('utf-8'))\n",
    "\n",
    "    print()\n",
    "\n",
    "    for en in en_examples.numpy():\n",
    "        print(en.decode('utf-8'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6dce6c3",
   "metadata": {},
   "source": [
    "### tokenization & detokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e94c266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### to train a NLP model first we need to tokenized them \n",
    "##Converting the text to sequence of token IDS \n",
    "## In simple words converting a sentence or words to list of unique tonek-IDS\n",
    "## for tekenization, in this turtorial we will be using frozen model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc11ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\ted_hrlr_translate_pt_en_converter.zip'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
    "tf.keras.utils.get_file(\n",
    "    f'{model_name}.zip',\n",
    "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c10c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "##loading the model\n",
    "tokenizers=tf.saved_model.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b40e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
       "array([b'and when you improve searchability , you actually take away the one advantage of print , which is serendipity .',\n",
       "       b'but what if it were active ?',\n",
       "       b\"but they did n't test for curiosity .\"], dtype=object)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56254ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Example of tokenization \n",
    "encoded_en_examples=tokenizers.en.tokenize(en_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a330803",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308, 74, 2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15, 3]\n",
      "[2, 87, 90, 107, 76, 129, 1852, 30, 3]\n",
      "[2, 87, 83, 149, 50, 9, 56, 664, 85, 2512, 15, 3]\n"
     ]
    }
   ],
   "source": [
    "## encoded tokens of above en_examples\n",
    "for row in encoded_en_examples.to_list():\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43146852",
   "metadata": {},
   "source": [
    "*the shape of each input array is not same as the lenght of the sentence is not fixed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f23c00f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n ' t test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "### Decoding the encoded english examples \n",
    "round_trip = tokenizers.en.detokenize(encoded_en_examples)\n",
    "for line in round_trip.numpy():\n",
    "    print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94cba068",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How does the sequence of words are tokenized \n",
    "## using lookup() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa9492c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[b'[START]', b'and', b'when', b'you', b'improve', b'search', b'##ability',\n",
      "  b',', b'you', b'actually', b'take', b'away', b'the', b'one', b'advantage',\n",
      "  b'of', b'print', b',', b'which', b'is', b's', b'##ere', b'##nd', b'##ip',\n",
      "  b'##ity', b'.', b'[END]']                                                 ,\n",
      " [b'[START]', b'but', b'what', b'if', b'it', b'were', b'active', b'?',\n",
      "  b'[END]']                                                           ,\n",
      " [b'[START]', b'but', b'they', b'did', b'n', b\"'\", b't', b'test', b'for',\n",
      "  b'curiosity', b'.', b'[END]']                                          ]>\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizers.en.lookup(encoded_en_examples)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "076a03cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................."
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "\n",
    "for pt_examples, en_examples in train_examples.batch(1024):\n",
    "    pt_tokens = tokenizers.en.tokenize(pt_examples)\n",
    "    lengths.append(pt_tokens.row_lengths())\n",
    "    #print(pt_tokens.row_lengths())\n",
    "    en_tokens = tokenizers.en.tokenize(en_examples)\n",
    "    lengths.append(en_tokens.row_lengths())\n",
    "    print('.', end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9144f127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1024,), dtype=int64, numpy=array([45, 21, 23, ..., 21, 47, 35], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([27,  9, 12, ...,  9, 23, 28], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 32,  22,  34, ...,  39, 101,  36], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([17, 12, 20, ..., 30, 56, 13], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([48, 37, 27, ..., 92, 21, 49], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([29, 18, 15, ..., 53, 13, 29], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([72, 38, 35, ..., 20, 54, 13], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([38, 18, 16, ..., 11, 26, 11], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 15,  24,  51, ...,  27,  40, 117], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([10, 16, 24, ..., 20, 24, 71], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([28, 44, 26, ..., 95, 34, 32], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([17, 28, 14, ..., 39, 23, 22], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([35, 28, 43, ..., 71, 20, 18], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([15, 15, 26, ..., 34,  7, 10], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 32,  60,  25, ...,  37, 101,  31], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([18, 29, 15, ..., 22, 42, 21], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([16, 64, 26, ..., 38, 65, 41], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([11, 28, 12, ..., 15, 25, 24], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([21, 74, 30, ..., 32, 84, 71], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([12, 40, 10, ..., 20, 30, 34], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([56, 54, 38, ..., 34, 22, 23], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([45, 22, 21, ..., 14, 10, 16], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 30,  25,  56, ..., 114,  34,  75], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([16, 14, 30, ..., 47, 17, 34], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([26, 24, 28, ..., 17, 29, 30], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([14, 10, 13, ..., 10, 13, 13], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([19, 25, 65, ..., 39, 56, 75], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([10, 14, 33, ..., 15, 26, 39], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([48, 25, 23, ..., 65, 15,  8], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([24,  9, 10, ..., 37, 10,  5], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([50, 35, 56, ..., 33, 23, 58], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([30, 19, 20, ..., 15, 11, 23], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([15, 52, 11, ..., 43, 25, 37], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([10, 34, 10, ..., 25, 11, 21], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([52, 83, 31, ..., 33, 98, 31], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([30, 38, 19, ..., 15, 34, 16], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 30,  14,  24, ..., 103,  17,  55], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([17,  8, 34, ..., 51,  9, 37], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([36,  9,  8, ..., 55, 31, 37], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([19, 10,  5, ..., 28, 13, 17], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 39,  34,  19, ...,  43, 115,  26], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([19, 19, 10, ..., 29, 65,  9], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([51, 28, 57, ..., 48, 25, 41], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([35, 16, 27, ..., 24, 12, 18], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([52, 32, 80, ..., 14, 62, 44], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([27, 19, 42, ..., 11, 31, 20], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([34, 17, 49, ..., 12, 21, 25], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([16, 12, 30, ...,  8, 11, 11], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 68, 119,  19, ...,  11,  21,  35], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([31, 54, 11, ..., 12, 12, 25], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([38, 25, 14, ..., 54, 21, 40], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([25, 10,  6, ..., 24, 10, 27], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 57,  41,  14, ...,  26,  92, 198], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 36,  20,  12, ...,  12,  40, 103], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([25, 30, 40, ..., 35, 36, 30], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([10, 22, 21, ..., 22, 17, 13], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([63, 26, 23, ..., 98, 32, 42], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([35, 16, 12, ..., 52, 14, 23], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([15, 65, 23, ..., 63, 47, 21], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 9, 34, 15, ..., 40, 24, 15], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([12, 21, 37, ..., 28, 16, 25], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([10,  8, 16, ..., 11,  9, 12], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([99, 82, 41, ..., 33, 59, 15], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([41, 46, 22, ..., 13, 25,  8], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 15,  25,  64, ..., 158,  25, 103], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([10, 14, 44, ..., 78, 13, 40], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([28, 13, 78, ..., 25, 39, 12], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([19,  9, 31, ..., 12, 22, 10], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([20,  9, 90, ..., 21, 66, 17], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([11,  5, 34, ..., 12, 27, 10], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([127,  28,  35, ...,  75,  43,  14], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([87, 16, 12, ..., 34, 18, 13], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([  8,  27,  90, ...,  48,  10, 227], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([  5,  19,  38, ...,  23,   4, 130], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([65, 69, 37, ..., 13,  9, 11], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([32, 36, 19, ..., 13,  5, 10], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([27, 37, 21, ..., 49, 15, 23], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([20, 17, 11, ..., 28, 13, 15], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([11, 24, 75, ..., 40,  9, 15], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 8, 12, 53, ..., 21,  8, 10], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([21, 55, 24, ..., 36, 34, 36], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([15, 27, 10, ..., 24, 19, 23], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([46, 38, 28, ..., 56, 53, 40], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([27, 27, 11, ..., 26, 24, 21], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 42, 241,  50, ...,  64,  40,  54], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 15, 117,  23, ...,  31,  24,  21], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([63, 29, 29, ..., 49, 24, 63], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([24,  8, 19, ..., 33, 13, 32], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([43, 27, 28, ..., 76, 51, 46], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([33, 13, 11, ..., 43, 24, 16], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([63, 28, 21, ..., 21, 46, 45], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([24, 16, 12, ..., 10, 23, 26], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([76, 26, 52, ..., 29, 53, 15], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([40, 19, 23, ..., 19, 20, 10], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([106,  15,  14, ...,  73,  25,  56], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([44,  9,  9, ..., 32, 18, 32], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([44, 30, 33, ..., 52, 42, 38], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([18, 13, 21, ..., 27, 16, 21], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([11, 31, 12, ..., 98, 19, 24], dtype=int64)>,\n",
       " <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 7, 19, 11, ..., 73,  9, 14], dtype=int64)>,\n",
       " <tf.Tensor: shape=(585,), dtype=int64, numpy=\n",
       " array([ 25,  22,  11,  26,  34,  34,   8,  63,  15,  37,  71,  67,  18,\n",
       "         11,  53, 109,  84, 143,  20,  17,  30,  30,  19,  10,  46,  30,\n",
       "         24,  23,  22,  60, 153,  19,  69,  20,  18,  20,  40, 113,  54,\n",
       "          9,  20,  15,  43,  48,  55,  34,  55,  38,  56,  14,  24,  20,\n",
       "         45,  28,  32,  26,  18,  15,  40,  57,  32,  28,  39,  13,  30,\n",
       "         89,  18,  48,  57,  40, 128,  25,  36,  70,  94,  71,  85,  29,\n",
       "        148,  48,  39,  50,  33, 111,  19,  31,  19,  45,  34,  29, 100,\n",
       "         30,  28,  25,  66,  76,  36,  67,  18,  55,  50,  35,  85,  17,\n",
       "         51, 130,  19,  14,  33,  23,  84, 108,  34,  24,   9,  23,  18,\n",
       "         17,  32,  67,  21, 135,  24,  53,  57,  78,  43,  30,  36,  22,\n",
       "         54,  24,  34,  62,  65,  63,  10,  87, 151,  16,  53,  41,   9,\n",
       "         45, 138,  29,  67, 122,  31,  33,  27,  53,  17, 138,  54,  81,\n",
       "         33,  35,  81,  32,  46,  29,  25,  13,  55,  92,   9,  29,  48,\n",
       "         54,  25,  75,  91, 109,  56,  63,  54,   9,  65,  15,  39,  39,\n",
       "         23,  23,  78,  21,  60,  66,  65,  30,  22,  27,  51,  29,  31,\n",
       "         27,  42,  49,  31,  19,  13,  71,  25,  23,  81,  12,  88,  16,\n",
       "         99,  18,  31,  20, 106,  21,  11,  29,  71,  21,  47,  20,  19,\n",
       "         72,  14,  34,  58,  18,   9,  15, 248,  67,  50,  94,  22, 150,\n",
       "         49,  14,  37,  80,  47,  89,  29,  60,  30,  98,  24,  91,   9,\n",
       "         44,  26, 131,  43,  50,  10,  40,  19,  87,  58,  20,  17,  27,\n",
       "          8,  35,  15,  67,  33,  28,  11,  39,  27,  18,  39,  45,  37,\n",
       "         86,  27, 106,  36,  26,  20,  53,  31,  41,  24,  24,  21,  51,\n",
       "         18,  55,  10,  29, 178,  65,  33,  24,  99,  44,  91,  18,  24,\n",
       "         41,  28,  18,  37,  83,  23,  73,  21,  27,  35,  87,   7,  33,\n",
       "         79,  28,  29,  42,  75,  31,  28,  26,  17, 211,  19,  31,  94,\n",
       "         36,  26,  43,  24,  50,  40,  20,  42,  39, 169,   8,  53,  18,\n",
       "         37,  84,  26,  90,  78,  18,  53,  25,  28,  40,  16,  36,  24,\n",
       "         44,  32,  22,  59, 140,  57,  62,  29,  49,  48,  45,  20,  45,\n",
       "         47,  47,  57, 136,  29,  18,  62,  70,  14,  45,  38,  49,  74,\n",
       "         37,  23,  16,  34,  38,  19,  18,  16,  88,  32,  78,  49,  88,\n",
       "         26,  44,  16,  31,  30,  52, 137, 114,  33,  26,  22,  24, 172,\n",
       "         32,  28,  90,  15,  27,  91, 108,  52,   9,  11,  45,  24,  37,\n",
       "         99,  19,  24, 107,  48,  70,  22,  85, 111, 178,  30,  38, 118,\n",
       "         85,  10,  33,   8,  22,  29,  19,  28,  21, 177,  24,  55,  30,\n",
       "         17, 135,  27,  22,  31,  34,  20,  33,  34, 142,  23,  75,  45,\n",
       "         32,  21,  21,  15,  31,  32,  30,  10, 158, 148,   9,  45,  19,\n",
       "         55,  24,  47,  66,  16,  86,  55,  48,  53,  19,  21,  39,  22,\n",
       "         15,  20,  84,  29,  38,  77,  28,  79, 187,  57,  23,  61,  23,\n",
       "         74,  41,  55,  32,  79,  32,  30,  54,   7,  50,  16,  21,  25,\n",
       "         51,  31,  14,  16,  51,  35,  36,  16,  50,  56,  59,  47,  34,\n",
       "        140,  37,  38,  20,  56,  46,  65,  58,   8,  62,  10,  71,  17,\n",
       "         25,  28, 119,  48,  20, 104,  20,   7,  19, 140,  25,  61, 128,\n",
       "         94,  22,  49,  86,  45,  19,  80,  41,  32,  81,  92,  26,  29,\n",
       "         57,  18,  22,  16,  16,  28,  18,  83,  55,  15,  35,  18,  42,\n",
       "         25,  30,  53,  32,  69,  23,  27,  25,  45,  57, 102,  16,  46],\n",
       "       dtype=int64)>,\n",
       " <tf.Tensor: shape=(585,), dtype=int64, numpy=\n",
       " array([ 16,  12,  10,  17,  18,  15,   5,  27,   8,  18,  38,  29,  11,\n",
       "          6,  30,  54,  46,  75,  12,  10,  16,  13,  11,   5,  28,  13,\n",
       "         14,  14,  12,  32,  63,   7,  39,   8,  15,  18,  27,  54,  26,\n",
       "          5,   8,  10,  25,  21,  29,  16,  32,  17,  29,   8,  13,   9,\n",
       "         26,  13,  21,  17,  14,   7,  23,  31,  16,  16,  20,  14,  17,\n",
       "         51,  10,  27,  25,  15,  73,  16,  15,  34,  49,  33,  46,  19,\n",
       "         56,  26,  24,  21,  14,  41,  14,  19,   8,  22,  19,  14,  35,\n",
       "         15,  16,  17,  30,  41,  16,  36,  13,  28,  36,  16,  58,   8,\n",
       "         24,  64,  12,  11,  14,  10,  59,  51,  21,  15,   6,  13,  10,\n",
       "         10,  15,  29,  15,  86,  15,  27,  33,  43,  22,  18,  16,  10,\n",
       "         36,  12,  19,  48,  31,  27,   6,  46,  71,  11,  24,  24,   5,\n",
       "         22,  73,  19,  29,  58,  18,  17,  18,  30,  11,  59,  29,  42,\n",
       "         19,  19,  40,  15,  28,  21,   8,  13,  34,  48,   6,  18,  23,\n",
       "         27,  10,  34,  44,  53,  28,  32,  46,   5,  23,   9,  15,  25,\n",
       "         18,  12,  50,  14,  38,  29,  38,  15,  17,   9,  30,  16,  24,\n",
       "         13,  24,  26,  14,  10,  11,  40,  16,  17,  43,   8,  48,   6,\n",
       "         59,  13,  19,  15,  45,  10,   7,  21,  37,  11,  34,  16,  14,\n",
       "         41,   8,  13,  30,   9,   5,  11, 134,  30,  27,  42,  17,  85,\n",
       "         28,   7,  26,  38,  28,  41,  15,  32,  12,  59,  16,  46,   5,\n",
       "         22,  14,  65,  18,  25,   7,  17,  12,  54,  25,  12,  14,  15,\n",
       "          5,  18,   8,  27,  17,  18,   9,  14,  15,   9,  20,  35,  17,\n",
       "         45,  13,  37,  21,  14,  24,  28,  16,  22,  12,  19,   9,  33,\n",
       "         13,  29,   8,  19,  83,  28,  15,  18,  54,  25,  41,   8,  13,\n",
       "         29,  16,  15,  17,  61,  13,  28,   9,  15,  18,  35,   6,  16,\n",
       "         43,  16,  20,  24,  43,  16,  19,  16,   9, 123,  11,  17,  43,\n",
       "         17,  33,  22,  17,  29,  11,  13,  27,  22,  90,   5,  31,   7,\n",
       "         20,  47,  10,  62,  34,   9,  28,  16,  17,  16,  21,  15,  15,\n",
       "         22,  17,  13,  29,  60,  23,  28,  12,  29,  19,  22,  15,  25,\n",
       "         26,  30,  29,  58,  22,  11,  35,  41,  12,  25,  21,  24,  33,\n",
       "         27,  12,  17,  16,  20,   9,  10,  10,  46,  18,  42,  21,  49,\n",
       "         13,  23,  12,  16,  20,  21,  64,  50,  19,  17,   9,  11,  94,\n",
       "         16,  16,  41,  12,  13,  51,  75,  19,   8,   8,  30,  15,  23,\n",
       "         45,  11,  16,  40,  22,  33,  10,  58,  53,  88,  15,  27,  59,\n",
       "         44,   6,  16,   5,  13,  11,  16,  20,  13,  73,  14,  21,  12,\n",
       "         12,  61,  15,  13,  15,  19,  12,  20,  13,  89,  10,  39,  26,\n",
       "         16,  11,   8,  10,  19,  20,  19,   5,  88,  65,   5,  20,   7,\n",
       "         32,  15,  19,  32,  11,  43,  27,  20,  32,  11,  14,  24,  13,\n",
       "         10,  12,  31,  15,  18,  42,  13,  50,  75,  37,  12,  31,  11,\n",
       "         29,  18,  33,  19,  32,  14,  13,  27,   7,  25,  11,  11,  11,\n",
       "         18,  16,   7,   9,  16,  14,  20,   8,  26,  26,  23,  18,  20,\n",
       "         72,  16,  15,  14,  18,  21,  36,  35,   4,  24,   7,  25,  11,\n",
       "         15,  19,  50,  33,  13,  55,  12,   4,  12,  75,  13,  28,  75,\n",
       "         47,  14,  19,  30,  21,  13,  29,  22,  18,  36,  39,  15,  16,\n",
       "         27,  10,  11,   8,  10,  21,  15,  34,  28,   7,  16,   9,  17,\n",
       "         11,  16,  41,  16,  31,  12,  15,  12,  26,  30,  49,  16,  18],\n",
       "       dtype=int64)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd13a516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_lengths = np.concatenate(lengths)\n",
    "\n",
    "plt.hist(all_lengths, np.linspace(0, 500, 101))\n",
    "plt.ylim(plt.ylim())\n",
    "max_length = max(all_lengths)\n",
    "plt.plot([max_length, max_length], plt.ylim())\n",
    "plt.title(f'Max tokens per example: {max_length}');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa415c85",
   "metadata": {},
   "source": [
    "### Setting Input Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aaaa32af",
   "metadata": {},
   "source": [
    "*Defining max_tokens*<br>\n",
    ">max_tokens: Here max num of words for each batch size \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33a948f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76c13dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_pairs(pt, en):\n",
    "    #here pt and en are pt_examples[i] and en_examples[i]\n",
    "    pt = tokenizers.pt.tokenize(pt)\n",
    "    # Convert from ragged to dense, padding with zeros.\n",
    "    pt = pt.to_tensor()\n",
    "\n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    # Convert from ragged to dense, padding with zeros.\n",
    "    en = en.to_tensor()\n",
    "    return pt, en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dafc158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading the Dataset\n",
    "## useing Tensorflow datasets\n",
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02c4f892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt\n",
      " [[  2  88 120 ...   0   0   0]\n",
      " [  2 175 153 ...   0   0   0]\n",
      " [  2 101 105 ...   0   0   0]\n",
      " ...\n",
      " [  2 103 770 ...   0   0   0]\n",
      " [  2 133  14 ...   0   0   0]\n",
      " [  2  91 301 ...   0   0   0]] \n",
      "\n",
      " en\n",
      "\n",
      " [[  2 110  13 ...   0   0   0]\n",
      " [  2  45 628 ...   0   0   0]\n",
      " [  2  87 140 ...   0   0   0]\n",
      " ...\n",
      " [  2  77  71 ...   0   0   0]\n",
      " [  2 110  13 ...   0   0   0]\n",
      " [  2  99 474 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "## example\n",
    "##pt_example, and en_example are from row number \"Downloading Dataset 51 number\"\n",
    "pt,en=tokenize_pairs(pt_examples,en_examples)\n",
    "print('pt\\n {} \\n\\n en\\n\\n {}'.format(pt,en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7faad84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt.shape: (585, 147)\n",
      "en.shape: (585, 134)\n"
     ]
    }
   ],
   "source": [
    "print('pt.shape: {}\\nen.shape: {}'.format(pt.shape,en.shape))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04e5f81b",
   "metadata": {},
   "source": [
    "*bool function to filter out inputs with num_tokens*\n",
    "<br>tokenize pair are feeded to this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88e6a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_tokens(pt, en):\n",
    "    ##Here pt and en are tokenize value of pt_examples and en_examples\n",
    "    num_tokens = tf.maximum(tf.shape(pt)[1],tf.shape(en)[1])\n",
    "    return num_tokens < MAX_TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14661fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(False, shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "### Example of above function \n",
    "bool_tensor=filter_max_tokens(pt,en)\n",
    "print(bool_tensor)\n",
    "## meaning num_tokens is not less than the max tokens "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88bbaf5e",
   "metadata": {},
   "source": [
    "**Example of tf.maximum**\n",
    "<code>\n",
    "    x = tf.constant([-5., -1., 0., 0.])\n",
    "    y = tf.constant([-3.])\n",
    "    c=tf.math.maximum(x, y)\n",
    "    print(c)\n",
    "</code>    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "270ee05b",
   "metadata": {},
   "source": [
    "Here's a simple input pipeline that processes, shuffles and batches the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5ad4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca7d77df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(ds):\n",
    "    return (\n",
    "      ds\n",
    "      .cache()\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)## Define above\n",
    "      .filter(filter_max_tokens) #Define above\n",
    "      .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "\n",
    "train_batches = make_batches(train_examples)\n",
    "val_batches = make_batches(val_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6ad489e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 69)\n",
      "(64, 74)\n",
      "(64, 104)\n",
      "(64, 61)\n",
      "(64, 74)\n"
     ]
    }
   ],
   "source": [
    "## Here we can observe that each batch size still have variable length\n",
    "\n",
    "\n",
    "## Question: During the training process how do they handle different sequence length?\n",
    "for element in train_batches.take(5):\n",
    "    print(element[0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dbcc216",
   "metadata": {},
   "source": [
    "### Positional Encoding \n",
    "\n",
    ">>look into *An Attention is all we need* paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dddd48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60a5d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f36c66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20, 36), dtype=float32, numpy=\n",
       "array([[[ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "        [ 8.41470957e-01,  5.40302277e-01,  5.64216733e-01,\n",
       "          8.25626731e-01,  3.51695180e-01,  9.36114550e-01,\n",
       "          2.13780671e-01,  9.76881683e-01,  1.28796190e-01,\n",
       "          9.91671085e-01,  7.73490295e-02,  9.97004092e-01,\n",
       "          4.63992245e-02,  9.98923004e-01,  2.78220028e-02,\n",
       "          9.99612868e-01,  1.66802313e-02,  9.99860883e-01,\n",
       "          9.99983307e-03,  9.99949992e-01,  5.99480653e-03,\n",
       "          9.99982059e-01,  3.59380594e-03,  9.99993563e-01,\n",
       "          2.15443294e-03,  9.99997675e-01,  1.29154930e-03,\n",
       "          9.99999166e-01,  7.74263579e-04,  9.99999702e-01,\n",
       "          4.64158860e-04,  9.99999881e-01,  2.78255931e-04,\n",
       "          9.99999940e-01,  1.66810059e-04,  1.00000000e+00],\n",
       "        [ 9.09297407e-01, -4.16146845e-01,  9.31664824e-01,\n",
       "          3.63318950e-01,  6.58454001e-01,  7.52620995e-01,\n",
       "          4.17676836e-01,  9.08595681e-01,  2.55446911e-01,\n",
       "          9.66823101e-01,  1.54234603e-01,  9.88034248e-01,\n",
       "          9.26984996e-02,  9.95694220e-01,  5.56224659e-02,\n",
       "          9.98451889e-01,  3.33558209e-02,  9.99443531e-01,\n",
       "          1.99986659e-02,  9.99800026e-01,  1.19893979e-02,\n",
       "          9.99928117e-01,  7.18756532e-03,  9.99974191e-01,\n",
       "          4.30885609e-03,  9.99990702e-01,  2.58309650e-03,\n",
       "          9.99996662e-01,  1.54852669e-03,  9.99998808e-01,\n",
       "          9.28317662e-04,  9.99999583e-01,  5.56511863e-04,\n",
       "          9.99999821e-01,  3.33620090e-04,  9.99999940e-01],\n",
       "        [ 1.41120002e-01, -9.89992499e-01,  9.74197984e-01,\n",
       "         -2.25695044e-01,  8.81081522e-01,  4.72964376e-01,\n",
       "          6.02261007e-01,  7.98299193e-01,  3.77842456e-01,\n",
       "          9.25869882e-01,  2.30196014e-01,  9.73144293e-01,\n",
       "          1.38798103e-01,  9.90320683e-01,  8.33798647e-02,\n",
       "          9.96517837e-01,  5.00221327e-02,  9.98748124e-01,\n",
       "          2.99955010e-02,  9.99550045e-01,  1.79835577e-02,\n",
       "          9.99838293e-01,  1.07812323e-02,  9.99941885e-01,\n",
       "          6.46325899e-03,  9.99979138e-01,  3.87463928e-03,\n",
       "          9.99992490e-01,  2.32278905e-03,  9.99997318e-01,\n",
       "          1.39247614e-03,  9.99999046e-01,  8.34767707e-04,\n",
       "          9.99999642e-01,  5.00430120e-04,  9.99999881e-01],\n",
       "        [-7.56802499e-01, -6.53643608e-01,  6.76982999e-01,\n",
       "         -7.35998690e-01,  9.91132557e-01,  1.32876709e-01,\n",
       "          7.58998692e-01,  6.51092112e-01,  4.93943959e-01,\n",
       "          8.69493723e-01,  3.04778129e-01,  9.52423394e-01,\n",
       "          1.84598729e-01,  9.82813954e-01,  1.11072712e-01,\n",
       "          9.93812263e-01,  6.66745231e-02,  9.97774780e-01,\n",
       "          3.99893336e-02,  9.99200106e-01,  2.39770729e-02,\n",
       "          9.99712527e-01,  1.43747600e-02,  9.99896705e-01,\n",
       "          8.61763209e-03,  9.99962866e-01,  5.16617578e-03,\n",
       "          9.99986649e-01,  3.09704989e-03,  9.99995232e-01,\n",
       "          1.85663451e-03,  9.99998271e-01,  1.11302349e-03,\n",
       "          9.99999404e-01,  6.67240180e-04,  9.99999762e-01],\n",
       "        [-9.58924294e-01,  2.83662200e-01,  1.43672481e-01,\n",
       "         -9.89625275e-01,  9.74545717e-01, -2.24188745e-01,\n",
       "          8.80642831e-01,  4.73780721e-01,  6.01817429e-01,\n",
       "          7.98633695e-01,  3.77534062e-01,  9.25995708e-01,\n",
       "          2.30001718e-01,  9.73190248e-01,  1.38679564e-01,\n",
       "          9.90337312e-01,  8.33083615e-02,  9.96523798e-01,\n",
       "          4.99791689e-02,  9.98750269e-01,  2.99697239e-02,\n",
       "          9.99550819e-01,  1.79681014e-02,  9.99838531e-01,\n",
       "          1.07719647e-02,  9.99942005e-01,  6.45770365e-03,\n",
       "          9.99979138e-01,  3.87130864e-03,  9.99992490e-01,\n",
       "          2.32079229e-03,  9.99997318e-01,  1.39127928e-03,\n",
       "          9.99999046e-01,  8.34050181e-04,  9.99999642e-01],\n",
       "        [-2.79415488e-01,  9.60170269e-01, -4.39743310e-01,\n",
       "         -8.98123503e-01,  8.33440363e-01, -5.52609384e-01,\n",
       "          9.61569011e-01,  2.74563283e-01,  6.99665904e-01,\n",
       "          7.14470148e-01,  4.48027879e-01,  8.94019604e-01,\n",
       "          2.74909258e-01,  9.61470187e-01,  1.66179046e-01,\n",
       "          9.86095607e-01,  9.99190211e-02,  9.94995594e-01,\n",
       "          5.99640049e-02,  9.98200536e-01,  3.59613001e-02,\n",
       "          9.99353170e-01,  2.15612110e-02,  9.99767542e-01,\n",
       "          1.29262479e-02,  9.99916434e-01,  7.74922036e-03,\n",
       "          9.99969959e-01,  4.64556552e-03,  9.99989212e-01,\n",
       "          2.78494973e-03,  9.99996126e-01,  1.66953483e-03,\n",
       "          9.99998629e-01,  1.00086012e-03,  9.99999523e-01],\n",
       "        [ 6.56986594e-01,  7.53902256e-01, -8.69800150e-01,\n",
       "         -4.93404210e-01,  5.85845590e-01, -8.10422659e-01,\n",
       "          9.98035491e-01,  6.26509860e-02,  7.85859525e-01,\n",
       "          6.18405104e-01,  5.15837193e-01,  8.56686652e-01,\n",
       "          3.19224656e-01,  9.47679043e-01,  1.93549871e-01,\n",
       "          9.81090426e-01,  1.16501875e-01,  9.93190467e-01,\n",
       "          6.99428469e-02,  9.97551024e-01,  4.19515818e-02,\n",
       "          9.99119639e-01,  2.51540430e-02,  9.99683559e-01,\n",
       "          1.50804715e-02,  9.99886274e-01,  9.04072449e-03,\n",
       "          9.99959111e-01,  5.41981915e-03,  9.99985337e-01,\n",
       "          3.24910646e-03,  9.99994695e-01,  1.94779038e-03,\n",
       "          9.99998093e-01,  1.16767013e-03,  9.99999344e-01],\n",
       "        [ 9.89358246e-01, -1.45500034e-01, -9.96517122e-01,\n",
       "          8.33880752e-02,  2.63396859e-01, -9.64687586e-01,\n",
       "          9.88356173e-01, -1.52158096e-01,  8.58962357e-01,\n",
       "          5.12038708e-01,  5.80555618e-01,  8.14220548e-01,\n",
       "          3.62852424e-01,  9.31846619e-01,  2.20770851e-01,\n",
       "          9.75325704e-01,  1.33052319e-01,  9.91109014e-01,\n",
       "          7.99146965e-02,  9.96801734e-01,  4.79403585e-02,\n",
       "          9.98850226e-01,  2.87465490e-02,  9.99586761e-01,\n",
       "          1.72346234e-02,  9.99851465e-01,  1.03322137e-02,\n",
       "          9.99946594e-01,  6.19406998e-03,  9.99980807e-01,\n",
       "          3.71326250e-03,  9.99993086e-01,  2.22604559e-03,\n",
       "          9.99997497e-01,  1.33448001e-03,  9.99999106e-01],\n",
       "        [ 4.12118495e-01, -9.11130250e-01, -7.75702238e-01,\n",
       "          6.31099045e-01, -9.27063376e-02, -9.95693505e-01,\n",
       "          9.32978570e-01, -3.59931886e-01,  9.17756796e-01,\n",
       "          3.97142917e-01,  6.41795516e-01,  7.66875803e-01,\n",
       "          4.05698568e-01,  9.14006948e-01,  2.47820899e-01,\n",
       "          9.68805850e-01,  1.49565727e-01,  9.88751769e-01,\n",
       "          8.98785517e-02,  9.95952725e-01,  5.39274104e-02,\n",
       "          9.98544872e-01,  3.23386826e-02,  9.99476969e-01,\n",
       "          1.93886980e-02,  9.99812007e-01,  1.16236852e-02,\n",
       "          9.99932468e-01,  6.96831662e-03,  9.99975741e-01,\n",
       "          4.17741761e-03,  9.99991298e-01,  2.50430079e-03,\n",
       "          9.99996841e-01,  1.50128989e-03,  9.99998868e-01],\n",
       "        [-5.44021130e-01, -8.39071512e-01, -2.84363836e-01,\n",
       "          9.58716452e-01, -4.36964363e-01, -8.99478793e-01,\n",
       "          8.34463179e-01, -5.51063657e-01,  9.61263359e-01,\n",
       "          2.75631577e-01,  6.99189842e-01,  7.14936078e-01,\n",
       "          4.47670847e-01,  8.94198418e-01,  2.74679095e-01,\n",
       "          9.61535931e-01,  1.66037530e-01,  9.86119449e-01,\n",
       "          9.98334140e-02,  9.95004177e-01,  5.99125251e-02,\n",
       "          9.98203635e-01,  3.59304026e-02,  9.99354303e-01,\n",
       "          2.15426795e-02,  9.99767959e-01,  1.29151372e-02,\n",
       "          9.99916613e-01,  7.74255954e-03,  9.99970019e-01,\n",
       "          4.64157201e-03,  9.99989212e-01,  2.78255576e-03,\n",
       "          9.99996126e-01,  1.66809978e-03,  9.99998629e-01],\n",
       "        [-9.99990225e-01,  4.42569796e-03,  3.06145489e-01,\n",
       "          9.51984763e-01, -7.25391090e-01, -6.88336968e-01,\n",
       "          6.97365046e-01, -7.16716111e-01,  9.88757372e-01,\n",
       "          1.49528801e-01,  7.52394736e-01,  6.58712506e-01,\n",
       "          4.88678783e-01,  8.72463763e-01,  3.01324606e-01,\n",
       "          9.53521609e-01,  1.82463139e-01,  9.83212709e-01,\n",
       "          1.09778300e-01,  9.93956089e-01,  6.58954829e-02,\n",
       "          9.97826517e-01,  3.95216532e-02,  9.99218702e-01,\n",
       "          2.36965641e-02,  9.99719203e-01,  1.42065687e-02,\n",
       "          9.99899089e-01,  8.51679780e-03,  9.99963760e-01,\n",
       "          5.10572549e-03,  9.99986947e-01,  3.06081050e-03,\n",
       "          9.99995291e-01,  1.83490955e-03,  9.99998331e-01],\n",
       "        [-5.36572933e-01,  8.43853951e-01,  7.89887607e-01,\n",
       "          6.13251626e-01, -9.21133935e-01, -3.89245719e-01,\n",
       "          5.28023124e-01, -8.49229991e-01,  9.99780834e-01,\n",
       "          2.09351983e-02,  8.01091373e-01,  5.98542035e-01,\n",
       "          5.28634131e-01,  8.48849773e-01,  3.27736855e-01,\n",
       "          9.44769025e-01,  1.98837966e-01,  9.80032384e-01,\n",
       "          1.19712204e-01,  9.92808640e-01,  7.18760788e-02,\n",
       "          9.97413576e-01,  4.31123972e-02,  9.99070227e-01,\n",
       "          2.58503370e-02,  9.99665797e-01,  1.54979751e-02,\n",
       "          9.99879897e-01,  9.29103047e-03,  9.99956846e-01,\n",
       "          5.56987757e-03,  9.99984503e-01,  3.33906501e-03,\n",
       "          9.99994397e-01,  2.00171932e-03,  9.99997973e-01],\n",
       "        [ 4.20167029e-01,  9.07446802e-01,  9.98159170e-01,\n",
       "          6.06491379e-02, -9.99182761e-01, -4.04202044e-02,\n",
       "          3.34267169e-01, -9.42478359e-01,  9.94150102e-01,\n",
       "         -1.08007133e-01,  8.44988048e-01,  5.34785211e-01,\n",
       "          5.67450762e-01,  8.23407352e-01,  3.53895366e-01,\n",
       "          9.35285032e-01,  2.15157464e-01,  9.76579368e-01,\n",
       "          1.29634142e-01,  9.91561890e-01,  7.78540894e-02,\n",
       "          9.96964753e-01,  4.67025824e-02,  9.98908818e-01,\n",
       "          2.80039888e-02,  9.99607801e-01,  1.67893562e-02,\n",
       "          9.99859035e-01,  1.00652575e-02,  9.99949336e-01,\n",
       "          6.03402872e-03,  9.99981821e-01,  3.61731928e-03,\n",
       "          9.99993443e-01,  2.16852897e-03,  9.99997675e-01],\n",
       "        [ 9.90607381e-01,  1.36737213e-01,  8.58326137e-01,\n",
       "         -5.13104558e-01, -9.49565172e-01,  3.13569844e-01,\n",
       "          1.25055820e-01, -9.92149711e-01,  9.71958995e-01,\n",
       "         -2.35150307e-01,  8.83821607e-01,  4.67824042e-01,\n",
       "          6.05045021e-01,  7.96191216e-01,  3.79779875e-01,\n",
       "          9.25076902e-01,  2.31417105e-01,  9.72854614e-01,\n",
       "          1.39543116e-01,  9.90216017e-01,  8.38292986e-02,\n",
       "          9.96480107e-01,  5.02921678e-02,  9.98734534e-01,\n",
       "          3.01575121e-02,  9.99545157e-01,  1.80807095e-02,\n",
       "          9.99836504e-01,  1.08394790e-02,  9.99941230e-01,\n",
       "          6.49817847e-03,  9.99978900e-01,  3.89557332e-03,\n",
       "          9.99992430e-01,  2.33533862e-03,  9.99997258e-01],\n",
       "        [ 6.50287867e-01, -7.59687901e-01,  4.19154823e-01,\n",
       "         -9.07914758e-01, -7.78620780e-01,  6.27494752e-01,\n",
       "         -8.99376869e-02, -9.95947421e-01,  9.33577180e-01,\n",
       "         -3.58376384e-01,  9.17359531e-01,  3.98059726e-01,\n",
       "          6.41336024e-01,  7.67260134e-01,  4.05370325e-01,\n",
       "          9.14152563e-01,  2.47612342e-01,  9.68859196e-01,\n",
       "          1.49438128e-01,  9.88771081e-01,  8.98014978e-02,\n",
       "          9.95959699e-01,  5.38811013e-02,  9.98547375e-01,\n",
       "          3.23108956e-02,  9.99477863e-01,  1.93720330e-02,\n",
       "          9.99812365e-01,  1.16136940e-02,  9.99932587e-01,\n",
       "          6.96232682e-03,  9.99975741e-01,  4.17382689e-03,\n",
       "          9.99991298e-01,  2.50214827e-03,  9.99996841e-01],\n",
       "        [-2.87903309e-01, -9.57659483e-01, -1.66195303e-01,\n",
       "         -9.86092865e-01, -5.08191347e-01,  8.61244202e-01,\n",
       "         -3.00772786e-01, -9.53695834e-01,  8.79643977e-01,\n",
       "         -4.75632668e-01,  9.45400715e-01,  3.25910300e-01,\n",
       "          6.76245570e-01,  7.36676276e-01,  4.30646986e-01,\n",
       "          9.02520478e-01,  2.63738692e-01,  9.64594185e-01,\n",
       "          1.59318209e-01,  9.87227261e-01,  9.57704708e-02,\n",
       "          9.95403469e-01,  5.74693382e-02,  9.98347282e-01,\n",
       "          3.44641283e-02,  9.99405921e-01,  2.06633247e-02,\n",
       "          9.99786496e-01,  1.23879025e-02,  9.99923289e-01,\n",
       "          7.42647378e-03,  9.99972403e-01,  4.45208047e-03,\n",
       "          9.99990106e-01,  2.66895769e-03,  9.99996424e-01],\n",
       "        [-9.61397469e-01, -2.75163352e-01, -6.93585396e-01,\n",
       "         -7.20374465e-01, -1.72829896e-01,  9.84951675e-01,\n",
       "         -4.97701138e-01, -8.67348611e-01,  8.11057806e-01,\n",
       "         -5.84965944e-01,  9.67777193e-01,  2.51808077e-01,\n",
       "          7.09698439e-01,  7.04505563e-01,  4.55590189e-01,\n",
       "          8.90189648e-01,  2.79791653e-01,  9.60060716e-01,\n",
       "          1.69182345e-01,  9.85584795e-01,  1.01736002e-01,\n",
       "          9.94811416e-01,  6.10568337e-02,  9.98134315e-01,\n",
       "          3.66172008e-02,  9.99329388e-01,  2.19545811e-02,\n",
       "          9.99758959e-01,  1.31621026e-02,  9.99913394e-01,\n",
       "          7.89061934e-03,  9.99968886e-01,  4.73033357e-03,\n",
       "          9.99988794e-01,  2.83576711e-03,  9.99996006e-01],\n",
       "        [-7.50987232e-01,  6.60316706e-01, -9.79089916e-01,\n",
       "         -2.03427911e-01,  1.84614182e-01,  9.82811093e-01,\n",
       "         -6.71617508e-01, -7.40898073e-01,  7.28961229e-01,\n",
       "         -6.84554994e-01,  9.84354913e-01,  1.76197037e-01,\n",
       "          7.41622627e-01,  6.70817316e-01,  4.80180681e-01,\n",
       "          8.77169609e-01,  2.95766771e-01,  9.55260158e-01,\n",
       "          1.79029569e-01,  9.83843684e-01,  1.07697874e-01,\n",
       "          9.94183660e-01,  6.46435395e-02,  9.97908413e-01,\n",
       "          3.87701057e-02,  9.99248147e-01,  2.32458003e-02,\n",
       "          9.99729753e-01,  1.39362952e-02,  9.99902904e-01,\n",
       "          8.35476257e-03,  9.99965072e-01,  5.00858575e-03,\n",
       "          9.99987483e-01,  3.00257653e-03,  9.99995470e-01],\n",
       "        [ 1.49877205e-01,  9.88704622e-01, -9.23140228e-01,\n",
       "          3.84463400e-01,  5.18469930e-01,  8.55095863e-01,\n",
       "         -8.14480484e-01, -5.80190897e-01,  6.34721696e-01,\n",
       "         -7.72740841e-01,  9.95034516e-01,  9.95302647e-02,\n",
       "          7.71949291e-01,  6.35684133e-01,  5.04399419e-01,\n",
       "          8.63470435e-01,  3.11659575e-01,  9.50193822e-01,\n",
       "          1.88858896e-01,  9.82004225e-01,  1.13655880e-01,\n",
       "          9.93520200e-01,  6.82294145e-02,  9.97669637e-01,\n",
       "          4.09228280e-02,  9.99162316e-01,  2.45369803e-02,\n",
       "          9.99698937e-01,  1.47104794e-02,  9.99891818e-01,\n",
       "          8.81890487e-03,  9.99961138e-01,  5.28683839e-03,\n",
       "          9.99986053e-01,  3.16938572e-03,  9.99994993e-01]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_encoding(20,36)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c6412ce",
   "metadata": {},
   "source": [
    "### Masking\n",
    ">Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise.\n",
    "\n",
    "*Note: We don't need masking skeleton based Posed based Action Recognition.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d4070f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84b32943",
   "metadata": {},
   "source": [
    "*Similar function in array*\n",
    "<code>\n",
    "    def create_padding_mask(seq):\n",
    "        seq=np.where(seq!=0,0,1)\n",
    "        return seq\n",
    "</code>    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb2bd843",
   "metadata": {},
   "source": [
    "*Masking Example*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "267dfd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8edd658d",
   "metadata": {},
   "source": [
    "### look ahead mask\n",
    ">The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.<br>This means that to predict the third token, only the first and second token will be used. Similarly to predict the fourth token, only the first, second and the third tokens will be used and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6065f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea1f6357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "\n",
    "temp = create_look_ahead_mask(x.shape[1]) \n",
    "#Value with 1 are masked \n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02a921ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f9e4bd8",
   "metadata": {},
   "source": [
    "### Building Transfomrer from scratch\n",
    "i. Multi-Headed Attention Layer <br>\n",
    "1. Linear Layer <br>\n",
    "2. Scaler Dot Product Attention <br>\n",
    "3. Final Linear Layer<br> \n",
    "\n",
    "ii. Encoder <br>\n",
    "iii. Decoder <br>\n",
    "iv. Tranformer Model <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3efe9fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead)\n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "    ## shape is determined by simple matrix multiplication rule \n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    #dk is the square root dimension of keys\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "        \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f754518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## here d_model is feature dimension as well as dimension of the k\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,*, d_model, num_heads): ##(self,*,d_model=dimension of k,num_heads)\n",
    "        \n",
    "        ##  d_model refer to the dimension of the q,v,k\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model) ## Must Define dense layer separately for all because Dense() always expect same shape but q,v,k may have different shape\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "#     Split the last dimension into (num_heads, depth).\n",
    "#     Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "#         #because of this split the computational time is same \n",
    "#         #even when the number of heads is increased\n",
    "        \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # q.shape= (batch_size, seq_len, d_model) ;Change the last dimesnion to d_model\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model) \n",
    "        ## this must assume the d_model and feature length is same \n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148187ee",
   "metadata": {},
   "source": [
    "Let us see how masking affects the MHA . First, go back and observe `scaled_dot_product()` function and look how the masking is applied in there.  In that function, the result of matrix multiplication is added\n",
    "to mask * (1e-9). The size of mat_mul of `Q` and `k` is *num_tokens by num_tokens*. If confuse, re-read the [Readme.md file](Readme.md).  Let us say, out sentence have tokens of 3 tokens.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddfa0f9",
   "metadata": {},
   "source": [
    "### how look ahead mask works? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8751a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: \n",
      " tf.Tensor(\n",
      "[[ 0.9424385   0.44913104 -0.10896361]\n",
      " [-1.4825398   1.2624447  -0.5394922 ]\n",
      " [ 1.12513    -1.0096041  -0.731005  ]], shape=(3, 3), dtype=float32)\n",
      "\n",
      "look_ahead_mask :\n",
      " tf.Tensor(\n",
      "[[0. 1. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]], shape=(3, 3), dtype=float32)\n",
      "Adding \n",
      "masked_logits: \n",
      " tf.Tensor(\n",
      "[[ 9.4243848e-01 -1.0000000e+09 -1.0000000e+09]\n",
      " [-1.4825398e+00  1.2624447e+00 -1.0000000e+09]\n",
      " [ 1.1251301e+00 -1.0096041e+00 -7.3100501e-01]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Let us see how look-ahead mask works\n",
    "\n",
    "logits=tf.random.normal(shape=(3,3))\n",
    "print('logits: \\n',logits)\n",
    "\n",
    "look_ahead_mask=create_look_ahead_mask(size=3)\n",
    "print('\\nlook_ahead_mask :\\n', look_ahead_mask)\n",
    "\n",
    "print('Adding ')\n",
    "logits +=(look_ahead_mask*-1e9)\n",
    "\n",
    "print('masked_logits: \\n',logits)\n",
    "\n",
    "attention_weight= tf.nn.softmax(logits, axis=-1) \n",
    "\n",
    "## In the attention weight matrix we can see that in first row, the attention score for 2nd and and thirst token is 0. That means it is not attenting the future tokens \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8f88c16",
   "metadata": {},
   "source": [
    "*Testing the Above MultiHeadedAttention()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91a3a824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([63, 43, 512]), TensorShape([63, 8, 43, 43]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((63,43,64))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebacc06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([63, 43, 64])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1abcc4a6",
   "metadata": {},
   "source": [
    "### Point wise feed forward network\n",
    ">Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c989348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8878d5d3",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Each encoder layer consists of sublayers:\n",
    "1. Multi-head Attention\n",
    "2. Point wise feed forward networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6ef7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,*, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # att_ouptput.shape=(batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        ##d_model must be equal to feature_dimension otherwise error in addition x + attn_output\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22c6f116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(d_model=512, num_heads=8, dff=2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4539e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,*, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        ## To embed to d_model\n",
    "        ## test code in below cell\n",
    "        self.pos_encoding = positional_encoding(MAX_TOKENS, self.d_model)# Positional encoding for sequence length up to MAX TOKENS\n",
    "\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model=d_model, num_heads=num_heads, dff=dff, rate=rate)\n",
    "            for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        \n",
    "        x += self.pos_encoding[:, :seq_len, :] #Slices out the shape not in after embedding\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11d6b3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos_emb.shape:  (1, 128, 512)\n",
      "After Embedding: x.shape  (64, 62, 512)\n",
      "After additing positional information: x.shape  (64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "#try the below code to understand more about embedding and positional \n",
    "emb=tf.keras.layers.Embedding(8500, 512)\n",
    "pos=positional_encoding(MAX_TOKENS,512)\n",
    "print('Pos_emb.shape: ',pos.shape)\n",
    "\n",
    "x=tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200) #input\n",
    "seq_len=x.shape[1]\n",
    "x=emb(x)\n",
    "print('After Embedding: x.shape ',x.shape)\n",
    "x+=pos[:,:seq_len,:]\n",
    "print('After additing positional information: x.shape ',x.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ea02f4a",
   "metadata": {},
   "source": [
    "<code> #Python\n",
    "emb=tf.keras.layers.Embedding(8500, 512)\n",
    "pos=positional_encoding(MAX_TOKENS,512)\n",
    "print('Pos_emb.shape: ',pos.shape)\n",
    "Pos_emb.shape:  (1, 128, 512)\n",
    "</code>    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "066220f3",
   "metadata": {},
   "source": [
    "<code> #Python\n",
    "x=tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200) #input\n",
    "x=emb(x)\n",
    "print('After Embedding: x.shape ',x.shape)\n",
    "</code>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0898ed2d",
   "metadata": {},
   "source": [
    "<code> #Python\n",
    "x *= tf.math.sqrt(tf.cast(512, tf.float32))\n",
    "print('x.shape: ',x.shape)\n",
    "</code>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90f31b05",
   "metadata": {},
   "source": [
    "<code> #Python\n",
    "pos=pos[:,:62,:] # 62 =tf.shape(x)[1] \n",
    "print('Pos_emb.shape: ',pos.shape)\n",
    "</code>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bdcdd87",
   "metadata": {},
   "source": [
    "<code>\n",
    "print(x.shape)=TensorShape([64, 62, 512])\n",
    "</code>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7f77dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 69, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, input_vocab_size=8500)\n",
    "temp_input = tf.random.uniform((64, 69), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "\n",
    "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fe2d6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos_emb.shape:  (1, 128, 512)\n"
     ]
    }
   ],
   "source": [
    "emb=tf.keras.layers.Embedding(8500, 512)\n",
    "pos=positional_encoding(MAX_TOKENS,512)\n",
    "print('Pos_emb.shape: ',pos.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "905ddb1a",
   "metadata": {},
   "source": [
    "## Decoder layer\n",
    "Each decoder layer consists of sublayers: <br>\n",
    "1. Masked multi-head attention (with look ahead mask and padding mask) \n",
    "2. *** Multi-head attention (with padding mask). V (value) and K (key) receive the encoder output as inputs. Q (query) receives the output from the masked multi-head attention sublayer.  ***\n",
    "3. Point wise feed forward networks.\n",
    "<br> <br>\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is LayerNorm(x + Sublayer(x)). The normalization is done on the d_model (last) axis.\n",
    "\n",
    ">As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output.<b> In other words, the decoder predicts the next token by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab3d1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,*, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,\n",
    "               look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask) ## v,k,q order  \n",
    "        # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  ## v and k are from encoder \n",
    "        # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b95b0373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output,\n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30779629",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,*, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "                   rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(MAX_TOKENS, d_model)\n",
    "\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model=d_model, num_heads=num_heads, dff=dff, rate=rate)\n",
    "            for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,\n",
    "               look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d7f3e32",
   "metadata": {},
   "source": [
    "### Creating a Transformer Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a095b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,*, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                   target_vocab_size, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                               num_heads=num_heads, dff=dff,\n",
    "                               input_vocab_size=input_vocab_size, rate=rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                               num_heads=num_heads, dff=dff,\n",
    "                               target_vocab_size=target_vocab_size, rate=rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        # Keras models prefer if you pass all your inputs in the first argument\n",
    "        inp, tar = inputs\n",
    "\n",
    "        padding_mask, look_ahead_mask = self.create_masks(inp, tar)\n",
    "\n",
    "        enc_output = self.encoder(inp, training, padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights\n",
    "\n",
    "    def create_masks(self, inp, tar):\n",
    "        # Encoder padding mask (Used in the 2nd attention block in the decoder too.)\n",
    "        padding_mask = create_padding_mask(inp)\n",
    "\n",
    "        # Used in the 1st attention block in the decoder.\n",
    "        # It is used to pad and mask future tokens in the input received by\n",
    "        # the decoder.\n",
    "        look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "        dec_target_padding_mask = create_padding_mask(tar)\n",
    "        look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "        return padding_mask, look_ahead_mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37af343b",
   "metadata": {},
   "source": [
    "### Setting the HyperParameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "651dcb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_attention_heads = 8\n",
    "dropout_rate = 0.1\n",
    "num_heads=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db6ba603",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_attention_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n",
    "    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c71a447b",
   "metadata": {},
   "source": [
    "### Test the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b7130c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_vocab_size: 7765 and target_vocab_size: 7010\n"
     ]
    }
   ],
   "source": [
    "input_vocab_size=tokenizers.pt.get_vocab_size().numpy()\n",
    "target_vocab_size=tokenizers.en.get_vocab_size().numpy()\n",
    "print('input_vocab_size: {} and target_vocab_size: {}'.format(input_vocab_size,target_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c37d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.constant([[1,2,3, 4, 0, 0, 0]])\n",
    "target = tf.constant([[1,2,3, 0]])\n",
    "\n",
    "x, attention = transformer((input, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99522e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 7])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ca5c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 7010)\n",
      "(1, 8, 4, 4)\n",
      "(1, 8, 4, 7)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(attention['decoder_layer1_block1'].shape)\n",
    "print(attention['decoder_layer4_block2'].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b6b9d1e",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b714cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This learning rate is according to the paper \"Attention is all we need!\"\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fedc524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14440408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added  \n"
     ]
    }
   ],
   "source": [
    "### Added for testing\n",
    "print(\"Added  \")\n",
    "## Add this to Asus Now\n",
    "## Added in Asus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e252117",
   "metadata": {},
   "source": [
    "## Loss and metrics\n",
    "\n",
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "faf2b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "048b3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "\n",
    "  \"\"\"\n",
    "  pred will have a shape of Batch_SIZE,NUM_TOKENS(Sequences),TARGET_VOCAB_SIZE\n",
    "  tf.argmax(pred, axis=2); will have a shape of Batch_SIZE,NUM_TOKENS(Sequences); this shape is same as that of real.shape\n",
    "  \"\"\";\n",
    "  accuracies = tf.equal(real, tf.argmax(pred, axis=2)) ## return arr of bool(True if real_tokens == pred_tokens)\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))# Return arr of bool(True if real does not have 0)\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "731190c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1=tf.Variable([1,2,3,4,5,6,0])\n",
    "arr2=tf.Variable([1,16,18,12,5,6,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8aeb17f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=bool, numpy=array([ True, False, False, False,  True,  True,  True])>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.equal(arr1,arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1fa99859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=bool, numpy=array([ True,  True,  True,  True,  True,  True, False])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.logical_not(tf.equal(arr1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "330a7c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16,), dtype=int64, numpy=array([3, 0, 2, 1, 8, 7, 2, 8, 1, 6, 6, 6, 1, 3, 6, 0], dtype=int64)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(tf.random.normal(shape=(16,10)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e9eda89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41cd7203",
   "metadata": {},
   "source": [
    "## Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b60f4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n",
    "    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9d7e696",
   "metadata": {},
   "source": [
    "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every n epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2cd839d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint_path = './checkpoints/train'\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print('Latest checkpoint restored!!')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00070409",
   "metadata": {},
   "source": [
    "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
    "\n",
    "For example, `sentence = 'SOS A lion in the jungle is sleeping EOS'` becomes:\n",
    "\n",
    "* `tar_inp =  'SOS A lion in the jungle is sleeping'`\n",
    "* `tar_real = 'A lion in the jungle is sleeping EOS'`\n",
    "\n",
    "A transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next.\n",
    "\n",
    "During training this example uses teacher-forcing (like in the [text generation tutorial](https://www.tensorflow.org/text/tutorials/text_generation)). Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
    "\n",
    "As the model predicts each token, *self-attention* allows it to look at the previous tokens in the input sequence to better predict the next token.\n",
    "\n",
    "To prevent the model from peeking at the expected output the model uses a look-ahead mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c025033",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "83eaeef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]  # why except the last token in each token? The last token is \"END\" ; This is done because the training is shifter ri\n",
    "  tar_real = tar[:, 1:] # Why except the first token\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer([inp, tar_inp],\n",
    "                                 training = True)\n",
    "    \n",
    "    # We notice that the transformer is feeded with tar_input(containing SOS and excluding EOS). As a result in the predicted word start from first word after sos and end with EOS. \n",
    "    # Thus the target loss_function as ground truth value we exclude the SOS, Because the prediction is also right shifted. \n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e3329d0",
   "metadata": {},
   "source": [
    "Portuguese is used as the input language and English is the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d15d390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.8830 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 7.1259 Accuracy 0.0454\n",
      "Epoch 1 Batch 100 Loss 6.6771 Accuracy 0.0550\n",
      "Epoch 1 Batch 150 Loss 6.4771 Accuracy 0.0727\n",
      "Epoch 1 Batch 200 Loss 6.3148 Accuracy 0.0896\n",
      "Epoch 1 Batch 250 Loss 6.1753 Accuracy 0.1050\n",
      "Epoch 1 Batch 300 Loss 6.0567 Accuracy 0.1189\n",
      "Epoch 1 Batch 350 Loss 5.9527 Accuracy 0.1301\n",
      "Epoch 1 Batch 400 Loss 5.8609 Accuracy 0.1394\n",
      "Epoch 1 Batch 450 Loss 5.7843 Accuracy 0.1476\n",
      "Epoch 1 Batch 500 Loss 5.7170 Accuracy 0.1546\n",
      "Epoch 1 Batch 550 Loss 5.6566 Accuracy 0.1609\n",
      "Epoch 1 Batch 600 Loss 5.6012 Accuracy 0.1665\n",
      "Epoch 1 Batch 650 Loss 5.5548 Accuracy 0.1715\n",
      "Epoch 1 Loss 5.5114 Accuracy 0.1760\n",
      "Time taken for 1 epoch: 121.28 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 4.8689 Accuracy 0.2413\n",
      "Epoch 2 Batch 50 Loss 4.8685 Accuracy 0.2407\n",
      "Epoch 2 Batch 100 Loss 4.8520 Accuracy 0.2431\n",
      "Epoch 2 Batch 150 Loss 4.8338 Accuracy 0.2449\n",
      "Epoch 2 Batch 200 Loss 4.8183 Accuracy 0.2459\n",
      "Epoch 2 Batch 250 Loss 4.8057 Accuracy 0.2472\n",
      "Epoch 2 Batch 300 Loss 4.7925 Accuracy 0.2485\n",
      "Epoch 2 Batch 350 Loss 4.7801 Accuracy 0.2494\n",
      "Epoch 2 Batch 400 Loss 4.7662 Accuracy 0.2507\n",
      "Epoch 2 Batch 450 Loss 4.7540 Accuracy 0.2518\n",
      "Epoch 2 Batch 500 Loss 4.7410 Accuracy 0.2531\n",
      "Epoch 2 Batch 550 Loss 4.7329 Accuracy 0.2539\n",
      "Epoch 2 Batch 600 Loss 4.7211 Accuracy 0.2550\n",
      "Epoch 2 Batch 650 Loss 4.7115 Accuracy 0.2560\n",
      "Epoch 2 Loss 4.7023 Accuracy 0.2570\n",
      "Time taken for 1 epoch: 100.15 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 4.4586 Accuracy 0.2752\n",
      "Epoch 3 Batch 50 Loss 4.5031 Accuracy 0.2713\n",
      "Epoch 3 Batch 100 Loss 4.4903 Accuracy 0.2731\n",
      "Epoch 3 Batch 150 Loss 4.4833 Accuracy 0.2745\n",
      "Epoch 3 Batch 200 Loss 4.4799 Accuracy 0.2750\n",
      "Epoch 3 Batch 250 Loss 4.4771 Accuracy 0.2756\n",
      "Epoch 3 Batch 300 Loss 4.4720 Accuracy 0.2767\n",
      "Epoch 3 Batch 350 Loss 4.4648 Accuracy 0.2778\n",
      "Epoch 3 Batch 400 Loss 4.4600 Accuracy 0.2784\n",
      "Epoch 3 Batch 450 Loss 4.4524 Accuracy 0.2794\n",
      "Epoch 3 Batch 500 Loss 4.4464 Accuracy 0.2800\n",
      "Epoch 3 Batch 550 Loss 4.4398 Accuracy 0.2809\n",
      "Epoch 3 Batch 600 Loss 4.4335 Accuracy 0.2814\n",
      "Epoch 3 Batch 650 Loss 4.4272 Accuracy 0.2818\n",
      "Epoch 3 Batch 700 Loss 4.4203 Accuracy 0.2825\n",
      "Epoch 3 Loss 4.4210 Accuracy 0.2824\n",
      "Time taken for 1 epoch: 96.39 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 4.0819 Accuracy 0.3175\n",
      "Epoch 4 Batch 50 Loss 4.2873 Accuracy 0.2926\n",
      "Epoch 4 Batch 100 Loss 4.2799 Accuracy 0.2951\n",
      "Epoch 4 Batch 150 Loss 4.2759 Accuracy 0.2948\n",
      "Epoch 4 Batch 200 Loss 4.2707 Accuracy 0.2955\n",
      "Epoch 4 Batch 250 Loss 4.2628 Accuracy 0.2965\n",
      "Epoch 4 Batch 300 Loss 4.2597 Accuracy 0.2966\n",
      "Epoch 4 Batch 350 Loss 4.2548 Accuracy 0.2970\n",
      "Epoch 4 Batch 400 Loss 4.2506 Accuracy 0.2974\n",
      "Epoch 4 Batch 450 Loss 4.2465 Accuracy 0.2977\n",
      "Epoch 4 Batch 500 Loss 4.2422 Accuracy 0.2983\n",
      "Epoch 4 Batch 550 Loss 4.2370 Accuracy 0.2990\n",
      "Epoch 4 Batch 600 Loss 4.2310 Accuracy 0.2995\n",
      "Epoch 4 Batch 650 Loss 4.2239 Accuracy 0.3002\n",
      "Epoch 4 Loss 4.2177 Accuracy 0.3009\n",
      "Time taken for 1 epoch: 90.90 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 4.2995 Accuracy 0.2926\n",
      "Epoch 5 Batch 50 Loss 4.1150 Accuracy 0.3092\n",
      "Epoch 5 Batch 100 Loss 4.0945 Accuracy 0.3114\n",
      "Epoch 5 Batch 150 Loss 4.0866 Accuracy 0.3121\n",
      "Epoch 5 Batch 200 Loss 4.0804 Accuracy 0.3131\n",
      "Epoch 5 Batch 250 Loss 4.0724 Accuracy 0.3145\n",
      "Epoch 5 Batch 300 Loss 4.0659 Accuracy 0.3154\n",
      "Epoch 5 Batch 350 Loss 4.0655 Accuracy 0.3155\n",
      "Epoch 5 Batch 400 Loss 4.0593 Accuracy 0.3165\n",
      "Epoch 5 Batch 450 Loss 4.0501 Accuracy 0.3176\n",
      "Epoch 5 Batch 500 Loss 4.0446 Accuracy 0.3182\n",
      "Epoch 5 Batch 550 Loss 4.0399 Accuracy 0.3190\n",
      "Epoch 5 Batch 600 Loss 4.0307 Accuracy 0.3201\n",
      "Epoch 5 Batch 650 Loss 4.0241 Accuracy 0.3209\n",
      "Epoch 5 Batch 700 Loss 4.0179 Accuracy 0.3219\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-9\n",
      "Epoch 5 Loss 4.0174 Accuracy 0.3220\n",
      "Time taken for 1 epoch: 91.67 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 3.7645 Accuracy 0.3499\n",
      "Epoch 6 Batch 50 Loss 3.8614 Accuracy 0.3380\n",
      "Epoch 6 Batch 100 Loss 3.8618 Accuracy 0.3381\n",
      "Epoch 6 Batch 150 Loss 3.8577 Accuracy 0.3386\n",
      "Epoch 6 Batch 200 Loss 3.8499 Accuracy 0.3394\n",
      "Epoch 6 Batch 250 Loss 3.8368 Accuracy 0.3417\n",
      "Epoch 6 Batch 300 Loss 3.8262 Accuracy 0.3435\n",
      "Epoch 6 Batch 350 Loss 3.8158 Accuracy 0.3450\n",
      "Epoch 6 Batch 400 Loss 3.8064 Accuracy 0.3464\n",
      "Epoch 6 Batch 450 Loss 3.8003 Accuracy 0.3474\n",
      "Epoch 6 Batch 500 Loss 3.7913 Accuracy 0.3487\n",
      "Epoch 6 Batch 550 Loss 3.7835 Accuracy 0.3498\n",
      "Epoch 6 Batch 600 Loss 3.7785 Accuracy 0.3506\n",
      "Epoch 6 Batch 650 Loss 3.7704 Accuracy 0.3517\n",
      "Epoch 6 Loss 3.7632 Accuracy 0.3528\n",
      "Time taken for 1 epoch: 91.58 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 3.7415 Accuracy 0.3496\n",
      "Epoch 7 Batch 50 Loss 3.5872 Accuracy 0.3710\n",
      "Epoch 7 Batch 100 Loss 3.5703 Accuracy 0.3742\n",
      "Epoch 7 Batch 150 Loss 3.5590 Accuracy 0.3762\n",
      "Epoch 7 Batch 200 Loss 3.5468 Accuracy 0.3782\n",
      "Epoch 7 Batch 250 Loss 3.5440 Accuracy 0.3784\n",
      "Epoch 7 Batch 300 Loss 3.5387 Accuracy 0.3796\n",
      "Epoch 7 Batch 350 Loss 3.5327 Accuracy 0.3809\n",
      "Epoch 7 Batch 400 Loss 3.5306 Accuracy 0.3818\n",
      "Epoch 7 Batch 450 Loss 3.5235 Accuracy 0.3830\n",
      "Epoch 7 Batch 500 Loss 3.5170 Accuracy 0.3841\n",
      "Epoch 7 Batch 550 Loss 3.5103 Accuracy 0.3851\n",
      "Epoch 7 Batch 600 Loss 3.5021 Accuracy 0.3862\n",
      "Epoch 7 Batch 650 Loss 3.4968 Accuracy 0.3871\n",
      "Epoch 7 Loss 3.4911 Accuracy 0.3881\n",
      "Time taken for 1 epoch: 90.60 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 3.1955 Accuracy 0.4190\n",
      "Epoch 8 Batch 50 Loss 3.3038 Accuracy 0.4107\n",
      "Epoch 8 Batch 100 Loss 3.3020 Accuracy 0.4115\n",
      "Epoch 8 Batch 150 Loss 3.3044 Accuracy 0.4115\n",
      "Epoch 8 Batch 200 Loss 3.2955 Accuracy 0.4135\n",
      "Epoch 8 Batch 250 Loss 3.2893 Accuracy 0.4148\n",
      "Epoch 8 Batch 300 Loss 3.2827 Accuracy 0.4160\n",
      "Epoch 8 Batch 350 Loss 3.2781 Accuracy 0.4166\n",
      "Epoch 8 Batch 400 Loss 3.2699 Accuracy 0.4177\n",
      "Epoch 8 Batch 450 Loss 3.2616 Accuracy 0.4189\n",
      "Epoch 8 Batch 500 Loss 3.2559 Accuracy 0.4198\n",
      "Epoch 8 Batch 550 Loss 3.2543 Accuracy 0.4201\n",
      "Epoch 8 Batch 600 Loss 3.2500 Accuracy 0.4210\n",
      "Epoch 8 Batch 650 Loss 3.2490 Accuracy 0.4214\n",
      "Epoch 8 Batch 700 Loss 3.2449 Accuracy 0.4220\n",
      "Epoch 8 Loss 3.2441 Accuracy 0.4221\n",
      "Time taken for 1 epoch: 94.21 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 3.2352 Accuracy 0.4234\n",
      "Epoch 9 Batch 50 Loss 3.0799 Accuracy 0.4416\n",
      "Epoch 9 Batch 100 Loss 3.0551 Accuracy 0.4458\n",
      "Epoch 9 Batch 150 Loss 3.0647 Accuracy 0.4452\n",
      "Epoch 9 Batch 200 Loss 3.0633 Accuracy 0.4454\n",
      "Epoch 9 Batch 250 Loss 3.0654 Accuracy 0.4457\n",
      "Epoch 9 Batch 300 Loss 3.0645 Accuracy 0.4460\n",
      "Epoch 9 Batch 350 Loss 3.0576 Accuracy 0.4471\n",
      "Epoch 9 Batch 400 Loss 3.0523 Accuracy 0.4479\n",
      "Epoch 9 Batch 450 Loss 3.0459 Accuracy 0.4488\n",
      "Epoch 9 Batch 500 Loss 3.0475 Accuracy 0.4486\n",
      "Epoch 9 Batch 550 Loss 3.0453 Accuracy 0.4491\n",
      "Epoch 9 Batch 600 Loss 3.0404 Accuracy 0.4496\n",
      "Epoch 9 Batch 650 Loss 3.0363 Accuracy 0.4503\n",
      "Epoch 9 Batch 700 Loss 3.0354 Accuracy 0.4506\n",
      "Epoch 9 Loss 3.0363 Accuracy 0.4505\n",
      "Time taken for 1 epoch: 93.86 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 3.1673 Accuracy 0.4485\n",
      "Epoch 10 Batch 50 Loss 2.8950 Accuracy 0.4683\n",
      "Epoch 10 Batch 100 Loss 2.8818 Accuracy 0.4698\n",
      "Epoch 10 Batch 150 Loss 2.8754 Accuracy 0.4706\n",
      "Epoch 10 Batch 200 Loss 2.8732 Accuracy 0.4715\n",
      "Epoch 10 Batch 250 Loss 2.8717 Accuracy 0.4721\n",
      "Epoch 10 Batch 300 Loss 2.8705 Accuracy 0.4723\n",
      "Epoch 10 Batch 350 Loss 2.8715 Accuracy 0.4722\n",
      "Epoch 10 Batch 400 Loss 2.8702 Accuracy 0.4724\n",
      "Epoch 10 Batch 450 Loss 2.8688 Accuracy 0.4725\n",
      "Epoch 10 Batch 500 Loss 2.8649 Accuracy 0.4734\n",
      "Epoch 10 Batch 550 Loss 2.8624 Accuracy 0.4740\n",
      "Epoch 10 Batch 600 Loss 2.8613 Accuracy 0.4742\n",
      "Epoch 10 Batch 650 Loss 2.8577 Accuracy 0.4748\n",
      "Epoch 10 Batch 700 Loss 2.8542 Accuracy 0.4753\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train\\ckpt-10\n",
      "Epoch 10 Loss 2.8535 Accuracy 0.4754\n",
      "Time taken for 1 epoch: 93.49 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 2.6018 Accuracy 0.5161\n",
      "Epoch 11 Batch 50 Loss 2.7092 Accuracy 0.4918\n",
      "Epoch 11 Batch 100 Loss 2.6974 Accuracy 0.4947\n",
      "Epoch 11 Batch 150 Loss 2.6969 Accuracy 0.4951\n",
      "Epoch 11 Batch 200 Loss 2.6972 Accuracy 0.4958\n",
      "Epoch 11 Batch 250 Loss 2.7019 Accuracy 0.4956\n",
      "Epoch 11 Batch 300 Loss 2.7039 Accuracy 0.4957\n",
      "Epoch 11 Batch 350 Loss 2.7039 Accuracy 0.4957\n",
      "Epoch 11 Batch 400 Loss 2.7006 Accuracy 0.4964\n",
      "Epoch 11 Batch 450 Loss 2.6986 Accuracy 0.4966\n",
      "Epoch 11 Batch 500 Loss 2.6977 Accuracy 0.4967\n",
      "Epoch 11 Batch 550 Loss 2.6966 Accuracy 0.4969\n",
      "Epoch 11 Batch 600 Loss 2.6957 Accuracy 0.4969\n",
      "Epoch 11 Batch 650 Loss 2.6942 Accuracy 0.4973\n",
      "Epoch 11 Loss 2.6905 Accuracy 0.4978\n",
      "Time taken for 1 epoch: 92.36 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 2.5657 Accuracy 0.5153\n",
      "Epoch 12 Batch 50 Loss 2.5905 Accuracy 0.5096\n",
      "Epoch 12 Batch 100 Loss 2.5668 Accuracy 0.5131\n",
      "Epoch 12 Batch 150 Loss 2.5566 Accuracy 0.5155\n",
      "Epoch 12 Batch 200 Loss 2.5541 Accuracy 0.5167\n",
      "Epoch 12 Batch 250 Loss 2.5552 Accuracy 0.5164\n",
      "Epoch 12 Batch 300 Loss 2.5561 Accuracy 0.5163\n",
      "Epoch 12 Batch 350 Loss 2.5567 Accuracy 0.5165\n",
      "Epoch 12 Batch 400 Loss 2.5576 Accuracy 0.5162\n",
      "Epoch 12 Batch 450 Loss 2.5558 Accuracy 0.5166\n",
      "Epoch 12 Batch 500 Loss 2.5566 Accuracy 0.5164\n",
      "Epoch 12 Batch 550 Loss 2.5582 Accuracy 0.5163\n",
      "Epoch 12 Batch 600 Loss 2.5563 Accuracy 0.5167\n",
      "Epoch 12 Batch 650 Loss 2.5548 Accuracy 0.5170\n",
      "Epoch 12 Loss 2.5550 Accuracy 0.5171\n",
      "Time taken for 1 epoch: 92.30 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 2.6004 Accuracy 0.4981\n",
      "Epoch 13 Batch 50 Loss 2.4605 Accuracy 0.5280\n",
      "Epoch 13 Batch 100 Loss 2.4432 Accuracy 0.5306\n",
      "Epoch 13 Batch 150 Loss 2.4392 Accuracy 0.5314\n",
      "Epoch 13 Batch 200 Loss 2.4388 Accuracy 0.5315\n",
      "Epoch 13 Batch 250 Loss 2.4360 Accuracy 0.5325\n",
      "Epoch 13 Batch 300 Loss 2.4361 Accuracy 0.5323\n",
      "Epoch 13 Batch 350 Loss 2.4353 Accuracy 0.5330\n",
      "Epoch 13 Batch 400 Loss 2.4334 Accuracy 0.5334\n",
      "Epoch 13 Batch 450 Loss 2.4352 Accuracy 0.5332\n",
      "Epoch 13 Batch 500 Loss 2.4308 Accuracy 0.5340\n",
      "Epoch 13 Batch 550 Loss 2.4306 Accuracy 0.5342\n",
      "Epoch 13 Batch 600 Loss 2.4333 Accuracy 0.5338\n",
      "Epoch 13 Batch 650 Loss 2.4346 Accuracy 0.5337\n",
      "Epoch 13 Loss 2.4367 Accuracy 0.5335\n",
      "Time taken for 1 epoch: 92.28 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 2.3816 Accuracy 0.5273\n",
      "Epoch 14 Batch 50 Loss 2.3390 Accuracy 0.5469\n",
      "Epoch 14 Batch 100 Loss 2.3367 Accuracy 0.5463\n",
      "Epoch 14 Batch 150 Loss 2.3300 Accuracy 0.5471\n",
      "Epoch 14 Batch 200 Loss 2.3301 Accuracy 0.5467\n",
      "Epoch 14 Batch 250 Loss 2.3294 Accuracy 0.5475\n",
      "Epoch 14 Batch 300 Loss 2.3344 Accuracy 0.5462\n",
      "Epoch 14 Batch 350 Loss 2.3276 Accuracy 0.5475\n",
      "Epoch 14 Batch 400 Loss 2.3258 Accuracy 0.5480\n",
      "Epoch 14 Batch 450 Loss 2.3262 Accuracy 0.5481\n",
      "Epoch 14 Batch 500 Loss 2.3299 Accuracy 0.5478\n",
      "Epoch 14 Batch 550 Loss 2.3303 Accuracy 0.5477\n",
      "Epoch 14 Batch 600 Loss 2.3316 Accuracy 0.5476\n",
      "Epoch 14 Batch 650 Loss 2.3335 Accuracy 0.5475\n",
      "Epoch 14 Loss 2.3354 Accuracy 0.5472\n",
      "Time taken for 1 epoch: 91.12 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 2.0242 Accuracy 0.5967\n",
      "Epoch 15 Batch 50 Loss 2.2113 Accuracy 0.5668\n",
      "Epoch 15 Batch 100 Loss 2.2172 Accuracy 0.5648\n",
      "Epoch 15 Batch 150 Loss 2.2259 Accuracy 0.5629\n",
      "Epoch 15 Batch 200 Loss 2.2331 Accuracy 0.5620\n",
      "Epoch 15 Batch 250 Loss 2.2314 Accuracy 0.5625\n",
      "Epoch 15 Batch 300 Loss 2.2273 Accuracy 0.5633\n",
      "Epoch 15 Batch 350 Loss 2.2308 Accuracy 0.5625\n",
      "Epoch 15 Batch 400 Loss 2.2299 Accuracy 0.5628\n",
      "Epoch 15 Batch 450 Loss 2.2301 Accuracy 0.5629\n",
      "Epoch 15 Batch 500 Loss 2.2315 Accuracy 0.5628\n",
      "Epoch 15 Batch 550 Loss 2.2360 Accuracy 0.5621\n",
      "Epoch 15 Batch 600 Loss 2.2356 Accuracy 0.5621\n",
      "Epoch 15 Batch 650 Loss 2.2370 Accuracy 0.5619\n",
      "Epoch 15 Batch 700 Loss 2.2409 Accuracy 0.5612\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train\\ckpt-11\n",
      "Epoch 15 Loss 2.2407 Accuracy 0.5613\n",
      "Time taken for 1 epoch: 91.97 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 2.1858 Accuracy 0.5710\n",
      "Epoch 16 Batch 50 Loss 2.1233 Accuracy 0.5779\n",
      "Epoch 16 Batch 100 Loss 2.1363 Accuracy 0.5746\n",
      "Epoch 16 Batch 150 Loss 2.1501 Accuracy 0.5726\n",
      "Epoch 16 Batch 200 Loss 2.1523 Accuracy 0.5727\n",
      "Epoch 16 Batch 250 Loss 2.1521 Accuracy 0.5727\n",
      "Epoch 16 Batch 300 Loss 2.1524 Accuracy 0.5730\n",
      "Epoch 16 Batch 350 Loss 2.1555 Accuracy 0.5725\n",
      "Epoch 16 Batch 400 Loss 2.1523 Accuracy 0.5734\n",
      "Epoch 16 Batch 450 Loss 2.1535 Accuracy 0.5734\n",
      "Epoch 16 Batch 500 Loss 2.1532 Accuracy 0.5736\n",
      "Epoch 16 Batch 550 Loss 2.1557 Accuracy 0.5732\n",
      "Epoch 16 Batch 600 Loss 2.1556 Accuracy 0.5733\n",
      "Epoch 16 Batch 650 Loss 2.1587 Accuracy 0.5730\n",
      "Epoch 16 Batch 700 Loss 2.1619 Accuracy 0.5726\n",
      "Epoch 16 Loss 2.1619 Accuracy 0.5726\n",
      "Time taken for 1 epoch: 100.45 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 2.1346 Accuracy 0.5724\n",
      "Epoch 17 Batch 50 Loss 2.0496 Accuracy 0.5873\n",
      "Epoch 17 Batch 100 Loss 2.0556 Accuracy 0.5869\n",
      "Epoch 17 Batch 150 Loss 2.0657 Accuracy 0.5855\n",
      "Epoch 17 Batch 200 Loss 2.0725 Accuracy 0.5847\n",
      "Epoch 17 Batch 250 Loss 2.0719 Accuracy 0.5853\n",
      "Epoch 17 Batch 300 Loss 2.0719 Accuracy 0.5855\n",
      "Epoch 17 Batch 350 Loss 2.0711 Accuracy 0.5857\n",
      "Epoch 17 Batch 400 Loss 2.0729 Accuracy 0.5851\n",
      "Epoch 17 Batch 450 Loss 2.0754 Accuracy 0.5847\n",
      "Epoch 17 Batch 500 Loss 2.0765 Accuracy 0.5846\n",
      "Epoch 17 Batch 550 Loss 2.0774 Accuracy 0.5844\n",
      "Epoch 17 Batch 600 Loss 2.0818 Accuracy 0.5839\n",
      "Epoch 17 Batch 650 Loss 2.0817 Accuracy 0.5841\n",
      "Epoch 17 Batch 700 Loss 2.0839 Accuracy 0.5838\n",
      "Epoch 17 Loss 2.0839 Accuracy 0.5838\n",
      "Time taken for 1 epoch: 91.23 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 1.8902 Accuracy 0.6063\n",
      "Epoch 18 Batch 50 Loss 2.0111 Accuracy 0.5913\n",
      "Epoch 18 Batch 100 Loss 2.0051 Accuracy 0.5937\n",
      "Epoch 18 Batch 150 Loss 2.0058 Accuracy 0.5941\n",
      "Epoch 18 Batch 200 Loss 2.0037 Accuracy 0.5941\n",
      "Epoch 18 Batch 250 Loss 2.0038 Accuracy 0.5944\n",
      "Epoch 18 Batch 300 Loss 2.0060 Accuracy 0.5938\n",
      "Epoch 18 Batch 350 Loss 2.0039 Accuracy 0.5944\n",
      "Epoch 18 Batch 400 Loss 2.0051 Accuracy 0.5942\n",
      "Epoch 18 Batch 450 Loss 2.0083 Accuracy 0.5940\n",
      "Epoch 18 Batch 500 Loss 2.0092 Accuracy 0.5939\n",
      "Epoch 18 Batch 550 Loss 2.0126 Accuracy 0.5937\n",
      "Epoch 18 Batch 600 Loss 2.0152 Accuracy 0.5932\n",
      "Epoch 18 Batch 650 Loss 2.0185 Accuracy 0.5931\n",
      "Epoch 18 Loss 2.0203 Accuracy 0.5927\n",
      "Time taken for 1 epoch: 91.68 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 1.8791 Accuracy 0.6212\n",
      "Epoch 19 Batch 50 Loss 1.9174 Accuracy 0.6079\n",
      "Epoch 19 Batch 100 Loss 1.9101 Accuracy 0.6096\n",
      "Epoch 19 Batch 150 Loss 1.9133 Accuracy 0.6087\n",
      "Epoch 19 Batch 200 Loss 1.9287 Accuracy 0.6070\n",
      "Epoch 19 Batch 250 Loss 1.9312 Accuracy 0.6063\n",
      "Epoch 19 Batch 300 Loss 1.9395 Accuracy 0.6046\n",
      "Epoch 19 Batch 350 Loss 1.9438 Accuracy 0.6039\n",
      "Epoch 19 Batch 400 Loss 1.9461 Accuracy 0.6038\n",
      "Epoch 19 Batch 450 Loss 1.9494 Accuracy 0.6030\n",
      "Epoch 19 Batch 500 Loss 1.9495 Accuracy 0.6028\n",
      "Epoch 19 Batch 550 Loss 1.9502 Accuracy 0.6027\n",
      "Epoch 19 Batch 600 Loss 1.9539 Accuracy 0.6022\n",
      "Epoch 19 Batch 650 Loss 1.9577 Accuracy 0.6017\n",
      "Epoch 19 Loss 1.9578 Accuracy 0.6020\n",
      "Time taken for 1 epoch: 93.12 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 1.9537 Accuracy 0.5953\n",
      "Epoch 20 Batch 50 Loss 1.8670 Accuracy 0.6124\n",
      "Epoch 20 Batch 100 Loss 1.8640 Accuracy 0.6142\n",
      "Epoch 20 Batch 150 Loss 1.8620 Accuracy 0.6156\n",
      "Epoch 20 Batch 200 Loss 1.8719 Accuracy 0.6139\n",
      "Epoch 20 Batch 250 Loss 1.8807 Accuracy 0.6127\n",
      "Epoch 20 Batch 300 Loss 1.8862 Accuracy 0.6115\n",
      "Epoch 20 Batch 350 Loss 1.8869 Accuracy 0.6114\n",
      "Epoch 20 Batch 400 Loss 1.8917 Accuracy 0.6110\n",
      "Epoch 20 Batch 450 Loss 1.8941 Accuracy 0.6109\n",
      "Epoch 20 Batch 500 Loss 1.8980 Accuracy 0.6104\n",
      "Epoch 20 Batch 550 Loss 1.9001 Accuracy 0.6100\n",
      "Epoch 20 Batch 600 Loss 1.9031 Accuracy 0.6096\n",
      "Epoch 20 Batch 650 Loss 1.9035 Accuracy 0.6097\n",
      "Epoch 20 Batch 700 Loss 1.9039 Accuracy 0.6097\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train\\ckpt-12\n",
      "Epoch 20 Loss 1.9039 Accuracy 0.6097\n",
      "Time taken for 1 epoch: 91.30 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 1.8863 Accuracy 0.6155\n",
      "Epoch 21 Batch 50 Loss 1.8333 Accuracy 0.6187\n",
      "Epoch 21 Batch 100 Loss 1.8373 Accuracy 0.6195\n",
      "Epoch 21 Batch 150 Loss 1.8325 Accuracy 0.6204\n",
      "Epoch 21 Batch 200 Loss 1.8371 Accuracy 0.6196\n",
      "Epoch 21 Batch 250 Loss 1.8348 Accuracy 0.6197\n",
      "Epoch 21 Batch 300 Loss 1.8417 Accuracy 0.6187\n",
      "Epoch 21 Batch 350 Loss 1.8451 Accuracy 0.6184\n",
      "Epoch 21 Batch 400 Loss 1.8508 Accuracy 0.6177\n",
      "Epoch 21 Batch 450 Loss 1.8500 Accuracy 0.6181\n",
      "Epoch 21 Batch 500 Loss 1.8509 Accuracy 0.6179\n",
      "Epoch 21 Batch 550 Loss 1.8512 Accuracy 0.6180\n",
      "Epoch 21 Batch 600 Loss 1.8545 Accuracy 0.6174\n",
      "Epoch 21 Batch 650 Loss 1.8581 Accuracy 0.6169\n",
      "Epoch 21 Batch 700 Loss 1.8596 Accuracy 0.6168\n",
      "Epoch 21 Loss 1.8606 Accuracy 0.6167\n",
      "Time taken for 1 epoch: 91.41 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 1.6331 Accuracy 0.6630\n",
      "Epoch 22 Batch 50 Loss 1.7515 Accuracy 0.6311\n",
      "Epoch 22 Batch 100 Loss 1.7702 Accuracy 0.6298\n",
      "Epoch 22 Batch 150 Loss 1.7687 Accuracy 0.6306\n",
      "Epoch 22 Batch 200 Loss 1.7722 Accuracy 0.6298\n",
      "Epoch 22 Batch 250 Loss 1.7819 Accuracy 0.6286\n",
      "Epoch 22 Batch 300 Loss 1.7915 Accuracy 0.6270\n",
      "Epoch 22 Batch 350 Loss 1.7966 Accuracy 0.6259\n",
      "Epoch 22 Batch 400 Loss 1.7989 Accuracy 0.6256\n",
      "Epoch 22 Batch 450 Loss 1.8001 Accuracy 0.6258\n",
      "Epoch 22 Batch 500 Loss 1.8029 Accuracy 0.6252\n",
      "Epoch 22 Batch 550 Loss 1.8026 Accuracy 0.6253\n",
      "Epoch 22 Batch 600 Loss 1.8053 Accuracy 0.6247\n",
      "Epoch 22 Batch 650 Loss 1.8075 Accuracy 0.6245\n",
      "Epoch 22 Loss 1.8096 Accuracy 0.6243\n",
      "Time taken for 1 epoch: 88.94 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 1.7418 Accuracy 0.6422\n",
      "Epoch 23 Batch 50 Loss 1.7375 Accuracy 0.6358\n",
      "Epoch 23 Batch 100 Loss 1.7375 Accuracy 0.6354\n",
      "Epoch 23 Batch 150 Loss 1.7533 Accuracy 0.6323\n",
      "Epoch 23 Batch 200 Loss 1.7497 Accuracy 0.6327\n",
      "Epoch 23 Batch 250 Loss 1.7508 Accuracy 0.6327\n",
      "Epoch 23 Batch 300 Loss 1.7554 Accuracy 0.6317\n",
      "Epoch 23 Batch 350 Loss 1.7565 Accuracy 0.6314\n",
      "Epoch 23 Batch 400 Loss 1.7579 Accuracy 0.6312\n",
      "Epoch 23 Batch 450 Loss 1.7598 Accuracy 0.6310\n",
      "Epoch 23 Batch 500 Loss 1.7624 Accuracy 0.6306\n",
      "Epoch 23 Batch 550 Loss 1.7645 Accuracy 0.6305\n",
      "Epoch 23 Batch 600 Loss 1.7682 Accuracy 0.6300\n",
      "Epoch 23 Batch 650 Loss 1.7706 Accuracy 0.6295\n",
      "Epoch 23 Batch 700 Loss 1.7739 Accuracy 0.6292\n",
      "Epoch 23 Loss 1.7738 Accuracy 0.6291\n",
      "Time taken for 1 epoch: 91.25 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 1.6792 Accuracy 0.6499\n",
      "Epoch 24 Batch 50 Loss 1.6827 Accuracy 0.6437\n",
      "Epoch 24 Batch 100 Loss 1.6907 Accuracy 0.6416\n",
      "Epoch 24 Batch 150 Loss 1.6980 Accuracy 0.6408\n",
      "Epoch 24 Batch 200 Loss 1.7036 Accuracy 0.6396\n",
      "Epoch 24 Batch 250 Loss 1.7089 Accuracy 0.6390\n",
      "Epoch 24 Batch 300 Loss 1.7081 Accuracy 0.6393\n",
      "Epoch 24 Batch 350 Loss 1.7105 Accuracy 0.6389\n",
      "Epoch 24 Batch 400 Loss 1.7154 Accuracy 0.6380\n",
      "Epoch 24 Batch 450 Loss 1.7191 Accuracy 0.6375\n",
      "Epoch 24 Batch 500 Loss 1.7216 Accuracy 0.6371\n",
      "Epoch 24 Batch 550 Loss 1.7246 Accuracy 0.6367\n",
      "Epoch 24 Batch 600 Loss 1.7277 Accuracy 0.6363\n",
      "Epoch 24 Batch 650 Loss 1.7301 Accuracy 0.6361\n",
      "Epoch 24 Loss 1.7319 Accuracy 0.6358\n",
      "Time taken for 1 epoch: 91.07 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 1.6307 Accuracy 0.6381\n",
      "Epoch 25 Batch 50 Loss 1.6594 Accuracy 0.6443\n",
      "Epoch 25 Batch 100 Loss 1.6652 Accuracy 0.6448\n",
      "Epoch 25 Batch 150 Loss 1.6628 Accuracy 0.6457\n",
      "Epoch 25 Batch 200 Loss 1.6693 Accuracy 0.6450\n",
      "Epoch 25 Batch 250 Loss 1.6688 Accuracy 0.6451\n",
      "Epoch 25 Batch 300 Loss 1.6746 Accuracy 0.6443\n",
      "Epoch 25 Batch 350 Loss 1.6770 Accuracy 0.6438\n",
      "Epoch 25 Batch 400 Loss 1.6806 Accuracy 0.6431\n",
      "Epoch 25 Batch 450 Loss 1.6825 Accuracy 0.6426\n",
      "Epoch 25 Batch 500 Loss 1.6856 Accuracy 0.6423\n",
      "Epoch 25 Batch 550 Loss 1.6923 Accuracy 0.6412\n",
      "Epoch 25 Batch 600 Loss 1.6936 Accuracy 0.6411\n",
      "Epoch 25 Batch 650 Loss 1.6979 Accuracy 0.6403\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/train\\ckpt-13\n",
      "Epoch 25 Loss 1.7010 Accuracy 0.6400\n",
      "Time taken for 1 epoch: 91.70 secs\n",
      "\n",
      "Epoch 26 Batch 0 Loss 1.6902 Accuracy 0.6384\n",
      "Epoch 26 Batch 50 Loss 1.6442 Accuracy 0.6464\n",
      "Epoch 26 Batch 100 Loss 1.6268 Accuracy 0.6501\n",
      "Epoch 26 Batch 150 Loss 1.6332 Accuracy 0.6499\n",
      "Epoch 26 Batch 200 Loss 1.6365 Accuracy 0.6495\n",
      "Epoch 26 Batch 250 Loss 1.6391 Accuracy 0.6490\n",
      "Epoch 26 Batch 300 Loss 1.6415 Accuracy 0.6485\n",
      "Epoch 26 Batch 350 Loss 1.6462 Accuracy 0.6478\n",
      "Epoch 26 Batch 400 Loss 1.6497 Accuracy 0.6472\n",
      "Epoch 26 Batch 450 Loss 1.6508 Accuracy 0.6472\n",
      "Epoch 26 Batch 500 Loss 1.6522 Accuracy 0.6470\n",
      "Epoch 26 Batch 550 Loss 1.6571 Accuracy 0.6463\n",
      "Epoch 26 Batch 600 Loss 1.6596 Accuracy 0.6457\n",
      "Epoch 26 Batch 650 Loss 1.6634 Accuracy 0.6451\n",
      "Epoch 26 Batch 700 Loss 1.6641 Accuracy 0.6451\n",
      "Epoch 26 Loss 1.6637 Accuracy 0.6452\n",
      "Time taken for 1 epoch: 93.28 secs\n",
      "\n",
      "Epoch 27 Batch 0 Loss 1.4718 Accuracy 0.6703\n",
      "Epoch 27 Batch 50 Loss 1.5889 Accuracy 0.6590\n",
      "Epoch 27 Batch 100 Loss 1.5827 Accuracy 0.6589\n",
      "Epoch 27 Batch 150 Loss 1.5940 Accuracy 0.6566\n",
      "Epoch 27 Batch 200 Loss 1.5956 Accuracy 0.6566\n",
      "Epoch 27 Batch 250 Loss 1.5995 Accuracy 0.6561\n",
      "Epoch 27 Batch 300 Loss 1.6001 Accuracy 0.6561\n",
      "Epoch 27 Batch 350 Loss 1.6049 Accuracy 0.6554\n",
      "Epoch 27 Batch 400 Loss 1.6121 Accuracy 0.6543\n",
      "Epoch 27 Batch 450 Loss 1.6172 Accuracy 0.6534\n",
      "Epoch 27 Batch 500 Loss 1.6208 Accuracy 0.6530\n",
      "Epoch 27 Batch 550 Loss 1.6248 Accuracy 0.6523\n",
      "Epoch 27 Batch 600 Loss 1.6274 Accuracy 0.6517\n",
      "Epoch 27 Batch 650 Loss 1.6302 Accuracy 0.6512\n",
      "Epoch 27 Batch 700 Loss 1.6336 Accuracy 0.6508\n",
      "Epoch 27 Loss 1.6353 Accuracy 0.6506\n",
      "Time taken for 1 epoch: 95.59 secs\n",
      "\n",
      "Epoch 28 Batch 0 Loss 1.4298 Accuracy 0.6913\n",
      "Epoch 28 Batch 50 Loss 1.5501 Accuracy 0.6651\n",
      "Epoch 28 Batch 100 Loss 1.5528 Accuracy 0.6640\n",
      "Epoch 28 Batch 150 Loss 1.5605 Accuracy 0.6624\n",
      "Epoch 28 Batch 200 Loss 1.5655 Accuracy 0.6618\n",
      "Epoch 28 Batch 250 Loss 1.5694 Accuracy 0.6608\n",
      "Epoch 28 Batch 300 Loss 1.5739 Accuracy 0.6599\n",
      "Epoch 28 Batch 350 Loss 1.5756 Accuracy 0.6597\n",
      "Epoch 28 Batch 400 Loss 1.5806 Accuracy 0.6588\n",
      "Epoch 28 Batch 450 Loss 1.5823 Accuracy 0.6584\n",
      "Epoch 28 Batch 500 Loss 1.5883 Accuracy 0.6573\n",
      "Epoch 28 Batch 550 Loss 1.5920 Accuracy 0.6566\n",
      "Epoch 28 Batch 600 Loss 1.5948 Accuracy 0.6564\n",
      "Epoch 28 Batch 650 Loss 1.5967 Accuracy 0.6561\n",
      "Epoch 28 Batch 700 Loss 1.5997 Accuracy 0.6557\n",
      "Epoch 28 Loss 1.5995 Accuracy 0.6558\n",
      "Time taken for 1 epoch: 94.58 secs\n",
      "\n",
      "Epoch 29 Batch 0 Loss 1.4200 Accuracy 0.6846\n",
      "Epoch 29 Batch 50 Loss 1.5096 Accuracy 0.6699\n",
      "Epoch 29 Batch 100 Loss 1.5191 Accuracy 0.6694\n",
      "Epoch 29 Batch 150 Loss 1.5253 Accuracy 0.6676\n",
      "Epoch 29 Batch 200 Loss 1.5313 Accuracy 0.6664\n",
      "Epoch 29 Batch 250 Loss 1.5384 Accuracy 0.6649\n",
      "Epoch 29 Batch 300 Loss 1.5476 Accuracy 0.6636\n",
      "Epoch 29 Batch 350 Loss 1.5496 Accuracy 0.6630\n",
      "Epoch 29 Batch 400 Loss 1.5557 Accuracy 0.6621\n",
      "Epoch 29 Batch 450 Loss 1.5571 Accuracy 0.6621\n",
      "Epoch 29 Batch 500 Loss 1.5609 Accuracy 0.6617\n",
      "Epoch 29 Batch 550 Loss 1.5641 Accuracy 0.6611\n",
      "Epoch 29 Batch 600 Loss 1.5669 Accuracy 0.6608\n",
      "Epoch 29 Batch 650 Loss 1.5703 Accuracy 0.6603\n",
      "Epoch 29 Loss 1.5740 Accuracy 0.6598\n",
      "Time taken for 1 epoch: 97.75 secs\n",
      "\n",
      "Epoch 30 Batch 0 Loss 1.4895 Accuracy 0.6693\n",
      "Epoch 30 Batch 50 Loss 1.5188 Accuracy 0.6686\n",
      "Epoch 30 Batch 100 Loss 1.5137 Accuracy 0.6686\n",
      "Epoch 30 Batch 150 Loss 1.5156 Accuracy 0.6692\n",
      "Epoch 30 Batch 200 Loss 1.5165 Accuracy 0.6688\n",
      "Epoch 30 Batch 250 Loss 1.5223 Accuracy 0.6683\n",
      "Epoch 30 Batch 300 Loss 1.5274 Accuracy 0.6671\n",
      "Epoch 30 Batch 350 Loss 1.5286 Accuracy 0.6668\n",
      "Epoch 30 Batch 400 Loss 1.5302 Accuracy 0.6665\n",
      "Epoch 30 Batch 450 Loss 1.5315 Accuracy 0.6663\n",
      "Epoch 30 Batch 500 Loss 1.5343 Accuracy 0.6658\n",
      "Epoch 30 Batch 550 Loss 1.5394 Accuracy 0.6649\n",
      "Epoch 30 Batch 600 Loss 1.5416 Accuracy 0.6646\n",
      "Epoch 30 Batch 650 Loss 1.5475 Accuracy 0.6638\n",
      "Epoch 30 Batch 700 Loss 1.5487 Accuracy 0.6636\n",
      "Saving checkpoint for epoch 30 at ./checkpoints/train\\ckpt-14\n",
      "Epoch 30 Loss 1.5487 Accuracy 0.6636\n",
      "Time taken for 1 epoch: 97.80 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "\n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_batches):\n",
    "    train_step(inp, tar)\n",
    "\n",
    "    if batch % 50 == 0:\n",
    "      print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
    "\n",
    "  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a586d8c",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df1e5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "  def __init__(self, tokenizers, transformer):\n",
    "    self.tokenizers = tokenizers\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
    "    # input sentence is portuguese, hence adding the start and end token\n",
    "    assert isinstance(sentence, tf.Tensor)\n",
    "    if len(sentence.shape) == 0:\n",
    "      sentence = sentence[tf.newaxis]\n",
    "\n",
    "    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
    "\n",
    "    encoder_input = sentence\n",
    "\n",
    "    # As the output language is english, initialize the output with the\n",
    "    # english start token.\n",
    "    start_end = self.tokenizers.en.tokenize([''])[0]\n",
    "    start = start_end[0][tf.newaxis]\n",
    "    end = start_end[1][tf.newaxis]\n",
    "\n",
    "    # `tf.TensorArray` is required here (instead of a python list) so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(max_length):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions, _ = self.transformer([encoder_input, output], training=False)\n",
    "\n",
    "      # select the last token from the seq_len dimension\n",
    "      predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size) # Why we select output from the last token? \n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # concatentate the predicted_id to the output which is given to the decoder\n",
    "      # as its input.\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    # output.shape (1, tokens)\n",
    "    text = tokenizers.en.detokenize(output)[0]  # shape: ()\n",
    "\n",
    "    tokens = tokenizers.en.lookup(output)[0]\n",
    "\n",
    "    # `tf.function` prevents us from using the attention_weights that were\n",
    "    # calculated on the last iteration of the loop. So recalculate them outside\n",
    "    # the loop.\n",
    "    _, attention_weights = self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "\n",
    "    return text, tokens, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "924246b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator=Translator(tokenizers=tokenizers,transformer=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5be3a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_translation(sentence, tokens, ground_truth):\n",
    "  print(f'{\"Input:\":15s}: {sentence}')\n",
    "  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
    "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7186ac06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : este é um problema que temos que resolver.\n",
      "Prediction     : this is a problem that we have to solve .\n",
      "Ground truth   : this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "sentence = 'este é um problema que temos que resolver.'\n",
    "ground_truth = 'this is a problem we have to solve .'\n",
    "\n",
    "translated_text, translated_tokens, attention_weights = translator(\n",
    "    tf.constant(sentence),)\n",
    "print_translation(sentence, translated_text, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee8a522c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b'this is a problem that we have to solve .'>,\n",
       " <tf.Tensor: shape=(12,), dtype=string, numpy=\n",
       " array([b'[START]', b'this', b'is', b'a', b'problem', b'that', b'we',\n",
       "        b'have', b'to', b'solve', b'.', b'[END]'], dtype=object)>,\n",
       " {'decoder_layer1_block1': <tf.Tensor: shape=(1, 8, 11, 11), dtype=float32, numpy=\n",
       "  array([[[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.94390976e-01, 2.05609024e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.43100190e-01, 5.37872463e-02, 1.03112571e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.04320490e-01, 8.45594108e-02, 4.98268232e-02,\n",
       "            1.61293179e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.80363631e-01, 1.36234000e-01, 6.45374805e-02,\n",
       "            5.75968809e-02, 1.61268041e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.13109812e-01, 7.78007731e-02, 8.02488178e-02,\n",
       "            3.74981642e-01, 1.05781652e-01, 2.48077333e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.34382594e-01, 1.30213812e-01, 8.39152858e-02,\n",
       "            5.49710691e-02, 7.50770420e-02, 1.86562881e-01,\n",
       "            1.34877384e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.01757938e-01, 2.51422040e-02, 2.45469771e-02,\n",
       "            5.90984104e-03, 8.51636380e-02, 1.76577806e-01,\n",
       "            4.17906344e-01, 6.29952326e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.62976518e-01, 4.65059690e-02, 6.94207996e-02,\n",
       "            1.28234513e-02, 9.81796999e-03, 3.23752575e-02,\n",
       "            1.98419586e-01, 1.78827435e-01, 2.88832992e-01,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.73164237e-02, 3.27570960e-02, 6.13521412e-02,\n",
       "            4.05969322e-02, 1.35416742e-02, 3.55206765e-02,\n",
       "            1.54805660e-01, 6.15226850e-02, 4.04328495e-01,\n",
       "            1.08258203e-01, 0.00000000e+00],\n",
       "           [1.46052748e-01, 2.56053973e-02, 1.91450380e-02,\n",
       "            1.63542666e-02, 3.95726338e-02, 4.84601781e-02,\n",
       "            1.10209160e-01, 3.38011533e-02, 1.25845492e-01,\n",
       "            1.74831986e-01, 2.60121971e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.15709507e-01, 2.84290463e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.88603079e-01, 3.19655627e-01, 9.17412564e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.82956684e-01, 1.01921707e-01, 4.04696226e-01,\n",
       "            1.10425338e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.55591810e-01, 8.67450088e-02, 6.64881766e-02,\n",
       "            3.04993503e-02, 6.06756769e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.21736082e-02, 7.64528941e-03, 6.26089200e-02,\n",
       "            4.72001545e-02, 7.52703369e-01, 4.76686098e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.45299801e-01, 6.68049753e-02, 5.10602854e-02,\n",
       "            7.19197243e-02, 6.07159697e-02, 1.25279784e-01,\n",
       "            3.78919452e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.98545411e-01, 1.72977559e-02, 2.51669940e-02,\n",
       "            5.50660444e-03, 7.44481757e-02, 1.83241621e-01,\n",
       "            3.10740948e-01, 1.85052454e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.47067994e-01, 1.56755634e-02, 1.05104819e-02,\n",
       "            6.16994081e-03, 6.88280687e-02, 1.53773595e-02,\n",
       "            6.69979006e-02, 6.49066567e-01, 2.03060433e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.47370166e-02, 1.81108844e-02, 4.79140133e-03,\n",
       "            1.30624929e-02, 4.60473308e-03, 1.74614526e-02,\n",
       "            5.36299385e-02, 9.88207161e-02, 3.03892251e-02,\n",
       "            7.04392195e-01, 0.00000000e+00],\n",
       "           [3.87831181e-01, 9.05891657e-02, 1.79419927e-02,\n",
       "            3.70000415e-02, 1.55754900e-02, 4.96387668e-02,\n",
       "            4.91350219e-02, 3.19578126e-02, 8.66236091e-02,\n",
       "            2.74553187e-02, 2.06251547e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.96096563e-01, 2.03903437e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.93836355e-01, 4.22915183e-02, 1.63872063e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.59700736e-01, 2.45925095e-02, 4.67183143e-01,\n",
       "            3.48523706e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.24710655e-01, 6.03558645e-02, 8.26504976e-02,\n",
       "            4.81832251e-02, 2.84099758e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [9.56173986e-02, 1.41520398e-02, 2.54953116e-01,\n",
       "            3.35427970e-01, 1.95561707e-01, 1.04287848e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.10050321e-01, 7.27543533e-02, 2.85088029e-02,\n",
       "            1.63030595e-01, 2.26406872e-01, 3.03971678e-01,\n",
       "            9.52773914e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.12534893e-01, 1.31669706e-02, 1.23495664e-02,\n",
       "            9.46675614e-02, 9.44541544e-02, 1.63147554e-01,\n",
       "            1.35858893e-01, 7.38203749e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.90764502e-01, 4.97451648e-02, 1.13315918e-02,\n",
       "            3.34356911e-02, 2.74140358e-01, 6.59508705e-02,\n",
       "            1.52977571e-01, 8.51657242e-02, 1.36488482e-01,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.96079892e-01, 9.17166248e-02, 1.01804174e-02,\n",
       "            2.78867241e-02, 6.70406967e-02, 1.01917662e-01,\n",
       "            3.38188075e-02, 1.08490763e-02, 7.51147121e-02,\n",
       "            8.53953958e-02, 0.00000000e+00],\n",
       "           [1.08595870e-01, 5.21764643e-02, 5.50310463e-02,\n",
       "            1.40930757e-01, 3.13087436e-03, 5.66563904e-02,\n",
       "            3.35373953e-02, 3.61805335e-02, 1.07071780e-01,\n",
       "            1.56643644e-01, 2.50045240e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [9.08482730e-01, 9.15172249e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.67639470e-01, 1.05665572e-01, 3.26694906e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.43377107e-01, 4.93650511e-02, 2.59718448e-01,\n",
       "            2.47539431e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.92784083e-01, 9.09628645e-02, 2.13393778e-01,\n",
       "            1.82879508e-01, 1.99797302e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.55062258e-01, 6.12248331e-02, 1.82655737e-01,\n",
       "            5.22889018e-01, 1.91591457e-02, 5.90089746e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.98901728e-01, 9.38346609e-02, 2.29416206e-01,\n",
       "            2.77299672e-01, 4.68099304e-02, 9.29733515e-02,\n",
       "            6.07644394e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.11631766e-01, 8.88981111e-03, 2.09431648e-02,\n",
       "            4.22144718e-02, 3.97844195e-01, 2.29211420e-01,\n",
       "            1.47353128e-01, 4.19119783e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.22008801e-01, 9.74549949e-02, 2.18919501e-01,\n",
       "            8.85214284e-02, 1.23751067e-01, 1.33777559e-01,\n",
       "            3.32469977e-02, 1.09585069e-01, 7.27347210e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.07336819e-01, 4.72323820e-02, 1.05051525e-01,\n",
       "            2.45051384e-02, 1.25813549e-02, 4.38079759e-02,\n",
       "            7.59195760e-02, 1.95949301e-01, 1.66743934e-01,\n",
       "            2.20872000e-01, 0.00000000e+00],\n",
       "           [7.76053146e-02, 1.06846981e-01, 1.12569183e-01,\n",
       "            1.75189480e-01, 2.41661314e-02, 6.24654740e-02,\n",
       "            6.18677549e-02, 7.54811764e-02, 7.51479343e-02,\n",
       "            1.29534930e-01, 9.91256908e-02]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [9.63603616e-01, 3.63963954e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.45688403e-01, 6.39932901e-02, 9.03183743e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.73264778e-01, 6.62795305e-02, 2.89297193e-01,\n",
       "            7.11585060e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.40461445e-01, 2.08912283e-01, 6.86956849e-03,\n",
       "            1.20874181e-01, 2.28826366e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.58525550e-01, 3.92453000e-02, 1.39288157e-01,\n",
       "            3.95920455e-01, 1.25526294e-01, 4.14942205e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.41814604e-01, 2.73865014e-02, 5.40199988e-02,\n",
       "            6.29078746e-02, 3.52628618e-01, 1.26378238e-01,\n",
       "            2.34864175e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.75583720e-01, 1.14410305e-02, 2.69895396e-03,\n",
       "            2.99819000e-03, 2.45111033e-01, 1.20833293e-02,\n",
       "            1.82181243e-02, 3.18657234e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.32564321e-01, 4.87392209e-03, 6.38898015e-02,\n",
       "            9.91856586e-03, 6.59342483e-02, 5.56569220e-03,\n",
       "            2.37220049e-01, 4.41353917e-01, 3.86795811e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.53410339e-01, 5.05110808e-02, 1.44720487e-02,\n",
       "            1.05464617e-02, 5.40599134e-03, 2.60486733e-02,\n",
       "            5.37651367e-02, 1.40830517e-01, 2.65544236e-01,\n",
       "            1.79465503e-01, 0.00000000e+00],\n",
       "           [1.06469944e-01, 1.77171770e-02, 2.72867270e-02,\n",
       "            1.27378963e-02, 8.01989622e-03, 8.58823210e-03,\n",
       "            4.10504900e-02, 7.62725696e-02, 6.31206036e-02,\n",
       "            2.55380958e-01, 3.83355498e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.79939198e-01, 1.20060846e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.72173977e-01, 1.39844388e-01, 1.87981665e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.94069105e-01, 1.10037625e-01, 3.18985194e-01,\n",
       "            1.76908076e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.45838067e-01, 1.56602666e-01, 2.13784710e-01,\n",
       "            1.04467116e-01, 3.79307479e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.85471609e-01, 9.95732099e-02, 3.79366502e-02,\n",
       "            1.47638619e-01, 4.99414414e-01, 2.99655236e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.89380184e-01, 5.19052185e-02, 8.70507210e-02,\n",
       "            7.10043907e-02, 2.01934993e-01, 1.00820743e-01,\n",
       "            2.97903717e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [9.79747623e-02, 2.37601679e-02, 2.90481802e-02,\n",
       "            2.30146106e-02, 1.44125205e-02, 1.17031805e-01,\n",
       "            6.54608369e-01, 4.01496068e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.56242937e-01, 1.08325526e-01, 3.66902240e-02,\n",
       "            1.73745677e-01, 5.48564903e-02, 6.00642338e-02,\n",
       "            2.49263525e-01, 9.37908664e-02, 6.70205653e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.02307746e-02, 3.91642302e-02, 2.27457378e-02,\n",
       "            9.66907069e-02, 5.22689559e-02, 4.12149020e-02,\n",
       "            9.16847512e-02, 6.54498190e-02, 1.05604738e-01,\n",
       "            4.14945334e-01, 0.00000000e+00],\n",
       "           [5.19816130e-02, 5.11104576e-02, 2.92233322e-02,\n",
       "            5.45429327e-02, 3.88506278e-02, 1.30775645e-02,\n",
       "            1.93737708e-02, 6.76864162e-02, 3.55579592e-02,\n",
       "            5.48557997e-01, 9.00373533e-02]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [9.45152998e-01, 5.48469834e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.95741093e-01, 3.21043015e-01, 8.32158849e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.02411675e-01, 1.19640872e-01, 4.02056575e-01,\n",
       "            1.75890923e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.58604789e-01, 2.05215886e-01, 3.78509611e-02,\n",
       "            3.09699416e-01, 8.86289254e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.75961721e-01, 3.34142186e-02, 1.02884308e-01,\n",
       "            9.73978713e-02, 2.60367841e-01, 1.29974037e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.00298125e-01, 1.18624112e-02, 3.08533348e-02,\n",
       "            6.20021559e-02, 1.09805547e-01, 1.46192670e-01,\n",
       "            3.38985771e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.94667548e-01, 2.50711758e-02, 1.02297850e-02,\n",
       "            1.88772827e-02, 1.07966894e-02, 1.30457267e-01,\n",
       "            5.93306005e-01, 1.65942349e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.21165940e-01, 3.10915653e-02, 3.01793348e-02,\n",
       "            4.76166308e-02, 4.71720239e-03, 5.37931323e-02,\n",
       "            1.17331415e-01, 2.67989010e-01, 2.26115689e-01,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.63222799e-02, 2.33227033e-02, 8.32813419e-03,\n",
       "            2.42640581e-02, 3.43328371e-04, 6.53182715e-03,\n",
       "            5.66687770e-02, 1.56585518e-02, 7.75245130e-01,\n",
       "            1.33152651e-02, 0.00000000e+00],\n",
       "           [4.56960462e-02, 5.94015494e-02, 3.88564169e-02,\n",
       "            1.72339883e-02, 3.61143192e-03, 1.13881929e-02,\n",
       "            5.89405885e-03, 5.25211915e-02, 9.73306522e-02,\n",
       "            3.95596713e-01, 2.72469729e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.35316694e-01, 2.64683336e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.32724652e-01, 5.20628452e-01, 2.46646881e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.99092430e-01, 2.33975932e-01, 1.18228473e-01,\n",
       "            1.48703068e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.80975378e-01, 3.09598837e-02, 1.76073909e-01,\n",
       "            1.72385387e-02, 9.47523192e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.88959196e-01, 5.75525053e-02, 2.82795846e-01,\n",
       "            5.91897778e-02, 6.39069229e-02, 3.47595721e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.81757256e-01, 1.94094684e-02, 1.19274780e-01,\n",
       "            3.79812084e-02, 9.15707946e-02, 9.30983722e-02,\n",
       "            4.56908196e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.80693030e-01, 3.66921835e-02, 8.01818892e-02,\n",
       "            5.46934605e-02, 4.37738858e-02, 1.20938726e-01,\n",
       "            4.59552318e-01, 2.34745983e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.28380910e-01, 1.28163947e-02, 5.16902171e-02,\n",
       "            1.65223032e-02, 1.22710261e-02, 1.72667746e-02,\n",
       "            1.57549337e-01, 3.52301598e-01, 2.51201510e-01,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.75506455e-01, 5.48691042e-02, 3.18154544e-02,\n",
       "            1.86365917e-02, 4.31049094e-02, 2.45843530e-02,\n",
       "            5.01146279e-02, 8.75405073e-02, 1.70548826e-01,\n",
       "            4.32791486e-02, 0.00000000e+00],\n",
       "           [5.07015958e-02, 7.53466636e-02, 8.26976597e-02,\n",
       "            9.84638184e-02, 8.37496370e-02, 4.27844003e-02,\n",
       "            9.20507833e-02, 1.68261573e-01, 8.59065801e-02,\n",
       "            1.08278401e-01, 1.11758865e-01]]]], dtype=float32)>,\n",
       "  'decoder_layer1_block2': <tf.Tensor: shape=(1, 8, 11, 11), dtype=float32, numpy=\n",
       "  array([[[[0.01691602, 0.05432417, 0.0506168 , 0.08499616, 0.16923112,\n",
       "            0.05926926, 0.217691  , 0.06227189, 0.14888541, 0.09281286,\n",
       "            0.04298528],\n",
       "           [0.18197289, 0.02360745, 0.0683531 , 0.05730944, 0.08186786,\n",
       "            0.02615047, 0.11171797, 0.03217403, 0.07402298, 0.2099502 ,\n",
       "            0.13287362],\n",
       "           [0.1400099 , 0.05939964, 0.08067741, 0.05164222, 0.06275153,\n",
       "            0.12099522, 0.07813651, 0.13222843, 0.11128289, 0.06510463,\n",
       "            0.09777164],\n",
       "           [0.27658966, 0.03485614, 0.03046541, 0.02975666, 0.02677534,\n",
       "            0.01943534, 0.05813488, 0.04028925, 0.08649679, 0.16166803,\n",
       "            0.23553252],\n",
       "           [0.11798505, 0.11702287, 0.04265098, 0.13373752, 0.01589434,\n",
       "            0.0496297 , 0.05283698, 0.0943577 , 0.06545409, 0.18440716,\n",
       "            0.12602359],\n",
       "           [0.283515  , 0.08136353, 0.04645584, 0.04445592, 0.01571218,\n",
       "            0.0261612 , 0.03581047, 0.05335055, 0.06624372, 0.12625018,\n",
       "            0.22068146],\n",
       "           [0.16069908, 0.10670111, 0.05210722, 0.03709228, 0.02752736,\n",
       "            0.06161098, 0.07383601, 0.10924453, 0.06633213, 0.11577353,\n",
       "            0.18907578],\n",
       "           [0.37701178, 0.09786605, 0.05983332, 0.03221255, 0.01982256,\n",
       "            0.03735195, 0.04365816, 0.05596593, 0.02907086, 0.0938805 ,\n",
       "            0.15332633],\n",
       "           [0.32338017, 0.18009913, 0.02946888, 0.04181708, 0.00597296,\n",
       "            0.02115084, 0.0349711 , 0.04584177, 0.0357937 , 0.10220592,\n",
       "            0.1792984 ],\n",
       "           [0.24471189, 0.20597598, 0.02242341, 0.06007829, 0.00313939,\n",
       "            0.01970438, 0.01801816, 0.0498217 , 0.02361812, 0.1949901 ,\n",
       "            0.15751858],\n",
       "           [0.26109886, 0.07331715, 0.03576089, 0.0809306 , 0.02051981,\n",
       "            0.10232583, 0.07467572, 0.15147424, 0.05684138, 0.06165213,\n",
       "            0.08140348]],\n",
       "  \n",
       "          [[0.03710367, 0.07033966, 0.04930002, 0.06610447, 0.08475983,\n",
       "            0.13795432, 0.08990407, 0.1586985 , 0.2084818 , 0.05101888,\n",
       "            0.04633476],\n",
       "           [0.15129249, 0.07267813, 0.06409254, 0.06898875, 0.0848163 ,\n",
       "            0.0614748 , 0.06622694, 0.05835224, 0.07704551, 0.19040032,\n",
       "            0.10463198],\n",
       "           [0.06517931, 0.02459725, 0.02413594, 0.04245319, 0.05055217,\n",
       "            0.07937378, 0.02832478, 0.11242291, 0.05344012, 0.33123764,\n",
       "            0.18828294],\n",
       "           [0.1067953 , 0.11524946, 0.07090468, 0.07096632, 0.03585742,\n",
       "            0.06553028, 0.05084808, 0.07418377, 0.08612884, 0.12995827,\n",
       "            0.19357763],\n",
       "           [0.08557758, 0.04610668, 0.06060709, 0.0314745 , 0.02554196,\n",
       "            0.05224645, 0.05900174, 0.07036772, 0.04480306, 0.37567335,\n",
       "            0.14859986],\n",
       "           [0.19526787, 0.05219597, 0.08940239, 0.04081338, 0.08961301,\n",
       "            0.04016144, 0.02553341, 0.04068568, 0.03614068, 0.21425392,\n",
       "            0.17593227],\n",
       "           [0.10367328, 0.04803593, 0.10658089, 0.08130179, 0.1337186 ,\n",
       "            0.0424811 , 0.0229312 , 0.07349449, 0.09503603, 0.14829406,\n",
       "            0.14445263],\n",
       "           [0.11107731, 0.11300141, 0.09253543, 0.06311391, 0.17388171,\n",
       "            0.09064366, 0.03040811, 0.09345878, 0.05880605, 0.09153215,\n",
       "            0.08154149],\n",
       "           [0.20841484, 0.12136552, 0.09904758, 0.12170602, 0.08581447,\n",
       "            0.0631981 , 0.02564514, 0.06793403, 0.0735147 , 0.06750664,\n",
       "            0.06585297],\n",
       "           [0.06458389, 0.1605672 , 0.1324873 , 0.06787746, 0.04147198,\n",
       "            0.14450991, 0.09257899, 0.14795963, 0.04740742, 0.03555572,\n",
       "            0.06500055],\n",
       "           [0.22479346, 0.18867663, 0.10849167, 0.11728616, 0.15332367,\n",
       "            0.0559813 , 0.0276841 , 0.02927634, 0.03225426, 0.01523798,\n",
       "            0.04699449]],\n",
       "  \n",
       "          [[0.02989413, 0.03390279, 0.01732193, 0.01741708, 0.09343889,\n",
       "            0.02782794, 0.12624623, 0.05219736, 0.11491675, 0.17700493,\n",
       "            0.30983198],\n",
       "           [0.01994209, 0.0135868 , 0.00580919, 0.00394524, 0.04548973,\n",
       "            0.13796647, 0.1148871 , 0.13720712, 0.23967803, 0.14003608,\n",
       "            0.14145218],\n",
       "           [0.08410921, 0.02551067, 0.04266689, 0.03291702, 0.04510621,\n",
       "            0.07778267, 0.23159328, 0.09519852, 0.24542896, 0.05802088,\n",
       "            0.06166569],\n",
       "           [0.00913407, 0.01096771, 0.00328716, 0.00170724, 0.02373062,\n",
       "            0.09714301, 0.02457369, 0.10062078, 0.1401884 , 0.30655545,\n",
       "            0.28209192],\n",
       "           [0.08349147, 0.04545058, 0.13687468, 0.07352703, 0.18544775,\n",
       "            0.02916709, 0.07341029, 0.02620581, 0.21701069, 0.0664503 ,\n",
       "            0.06296432],\n",
       "           [0.10162289, 0.06270862, 0.10619957, 0.05884919, 0.15102987,\n",
       "            0.05080222, 0.03160692, 0.04967338, 0.26771477, 0.04586824,\n",
       "            0.07392436],\n",
       "           [0.08794829, 0.09914541, 0.2781065 , 0.19235915, 0.18851325,\n",
       "            0.00539668, 0.04973014, 0.00876831, 0.04001696, 0.02177178,\n",
       "            0.02824347],\n",
       "           [0.09553755, 0.07036915, 0.09062539, 0.06597039, 0.21783279,\n",
       "            0.07746215, 0.02037875, 0.08517946, 0.05056186, 0.12071735,\n",
       "            0.10536519],\n",
       "           [0.08407007, 0.06456326, 0.0892168 , 0.05874429, 0.2963798 ,\n",
       "            0.02883241, 0.03618911, 0.04360079, 0.10391311, 0.0906487 ,\n",
       "            0.10384159],\n",
       "           [0.06380259, 0.08977229, 0.20910962, 0.13590448, 0.16130906,\n",
       "            0.03087208, 0.05157595, 0.03533027, 0.11136281, 0.0708745 ,\n",
       "            0.0400864 ],\n",
       "           [0.13018091, 0.20899975, 0.08767065, 0.1511884 , 0.12324841,\n",
       "            0.05434879, 0.02309243, 0.04464801, 0.1079971 , 0.03819781,\n",
       "            0.03042772]],\n",
       "  \n",
       "          [[0.14384025, 0.05253059, 0.09214532, 0.18080127, 0.09723002,\n",
       "            0.08134916, 0.16261187, 0.04139973, 0.04640581, 0.04154074,\n",
       "            0.06014514],\n",
       "           [0.07368621, 0.04465611, 0.238341  , 0.31462094, 0.06236914,\n",
       "            0.03096378, 0.11945699, 0.0158725 , 0.07526249, 0.00836967,\n",
       "            0.0164011 ],\n",
       "           [0.12497515, 0.02702664, 0.04780662, 0.296934  , 0.08689931,\n",
       "            0.09178694, 0.20722783, 0.03562275, 0.0455336 , 0.01151192,\n",
       "            0.02467521],\n",
       "           [0.09489486, 0.03245991, 0.09881084, 0.10850729, 0.11031914,\n",
       "            0.09634407, 0.14079471, 0.08111771, 0.1823087 , 0.02827211,\n",
       "            0.02617068],\n",
       "           [0.03187239, 0.04744539, 0.10536513, 0.07416546, 0.08041966,\n",
       "            0.03465182, 0.06729433, 0.03439683, 0.16054231, 0.19716753,\n",
       "            0.1666792 ],\n",
       "           [0.08098949, 0.01019447, 0.09033363, 0.1349793 , 0.13803001,\n",
       "            0.05414929, 0.14339055, 0.03756784, 0.08804274, 0.08029781,\n",
       "            0.14202484],\n",
       "           [0.05924226, 0.02958346, 0.07679087, 0.05408966, 0.14815928,\n",
       "            0.05409588, 0.1363601 , 0.04994424, 0.11919752, 0.16495416,\n",
       "            0.10758258],\n",
       "           [0.04856853, 0.03970623, 0.04169895, 0.09509407, 0.0466743 ,\n",
       "            0.05291834, 0.23183563, 0.05844432, 0.13269784, 0.11498562,\n",
       "            0.13737617],\n",
       "           [0.07664406, 0.02215427, 0.08143318, 0.03534529, 0.2307011 ,\n",
       "            0.04262129, 0.03287379, 0.05132099, 0.10520268, 0.22159031,\n",
       "            0.10011303],\n",
       "           [0.02977728, 0.03396426, 0.05306352, 0.0180653 , 0.06997115,\n",
       "            0.03797055, 0.05311199, 0.06962948, 0.18446204, 0.28105333,\n",
       "            0.1689311 ],\n",
       "           [0.03508331, 0.13256072, 0.05395832, 0.04056566, 0.03382983,\n",
       "            0.07788289, 0.10960461, 0.1263164 , 0.1088315 , 0.18753149,\n",
       "            0.09383529]],\n",
       "  \n",
       "          [[0.01421419, 0.01625598, 0.03874174, 0.0436497 , 0.05218127,\n",
       "            0.11471152, 0.3332709 , 0.07073846, 0.19500533, 0.03551252,\n",
       "            0.08571841],\n",
       "           [0.035119  , 0.01487399, 0.0308543 , 0.14688352, 0.02966031,\n",
       "            0.11657834, 0.45281985, 0.04442057, 0.03131979, 0.04175011,\n",
       "            0.05572021],\n",
       "           [0.04925325, 0.03378744, 0.02858557, 0.04534609, 0.0759781 ,\n",
       "            0.12776262, 0.07917364, 0.15468049, 0.2253459 , 0.08619829,\n",
       "            0.09388859],\n",
       "           [0.1247518 , 0.02157055, 0.02852307, 0.00776508, 0.13267846,\n",
       "            0.11112607, 0.081375  , 0.1417053 , 0.14047553, 0.11191566,\n",
       "            0.09811351],\n",
       "           [0.09991558, 0.11386359, 0.11126705, 0.12140036, 0.029754  ,\n",
       "            0.07677598, 0.09551068, 0.10068834, 0.04987474, 0.10615733,\n",
       "            0.09479237],\n",
       "           [0.14605205, 0.02241526, 0.02441961, 0.03357053, 0.02821391,\n",
       "            0.06776688, 0.17901918, 0.09610751, 0.14389023, 0.12937737,\n",
       "            0.12916751],\n",
       "           [0.19150369, 0.01780915, 0.0317664 , 0.01183327, 0.0676904 ,\n",
       "            0.15986101, 0.03112531, 0.32694274, 0.06027938, 0.0624177 ,\n",
       "            0.03877091],\n",
       "           [0.14724277, 0.04027224, 0.11443273, 0.02460104, 0.18468015,\n",
       "            0.11003798, 0.04369787, 0.12455168, 0.06496786, 0.08923179,\n",
       "            0.05628396],\n",
       "           [0.15890495, 0.01153504, 0.08625448, 0.07013031, 0.08439389,\n",
       "            0.14347294, 0.1578417 , 0.12438937, 0.03737158, 0.08236154,\n",
       "            0.04334418],\n",
       "           [0.15435073, 0.03500985, 0.05072491, 0.07801371, 0.10014473,\n",
       "            0.01954671, 0.03141555, 0.03718642, 0.19851716, 0.22078031,\n",
       "            0.07430985],\n",
       "           [0.20136607, 0.14708686, 0.09332398, 0.08126734, 0.03525882,\n",
       "            0.06917395, 0.04885881, 0.09444176, 0.07356004, 0.07311556,\n",
       "            0.08254674]],\n",
       "  \n",
       "          [[0.14483607, 0.39802313, 0.04222397, 0.04401953, 0.01913264,\n",
       "            0.11168832, 0.03543974, 0.1097395 , 0.03956036, 0.03078292,\n",
       "            0.02455387],\n",
       "           [0.1210374 , 0.03351999, 0.05474561, 0.05751806, 0.01698699,\n",
       "            0.08474221, 0.4278539 , 0.05936775, 0.01103157, 0.05960854,\n",
       "            0.07358801],\n",
       "           [0.08151451, 0.03915094, 0.05626338, 0.05072059, 0.06333016,\n",
       "            0.05839898, 0.33126685, 0.04274317, 0.01517173, 0.15797347,\n",
       "            0.10346621],\n",
       "           [0.05317328, 0.05361398, 0.07724543, 0.03555464, 0.04121456,\n",
       "            0.06175603, 0.2671974 , 0.07550623, 0.10522465, 0.1341618 ,\n",
       "            0.09535199],\n",
       "           [0.08014149, 0.08051408, 0.07377101, 0.09453814, 0.0829431 ,\n",
       "            0.0932223 , 0.19567056, 0.0589479 , 0.07270068, 0.08196004,\n",
       "            0.08559072],\n",
       "           [0.12575573, 0.02862393, 0.04400641, 0.11806957, 0.14185591,\n",
       "            0.08994185, 0.13834675, 0.06131396, 0.02251175, 0.10751578,\n",
       "            0.12205832],\n",
       "           [0.06013994, 0.0235293 , 0.1163251 , 0.09298081, 0.18101071,\n",
       "            0.06480321, 0.1172103 , 0.06879801, 0.1500101 , 0.0579741 ,\n",
       "            0.06721831],\n",
       "           [0.15630706, 0.04909215, 0.04731432, 0.07190253, 0.34209928,\n",
       "            0.0656824 , 0.04588987, 0.04389376, 0.0559792 , 0.08350662,\n",
       "            0.03833277],\n",
       "           [0.15636599, 0.12096321, 0.08846305, 0.07745974, 0.06050939,\n",
       "            0.10749741, 0.19808511, 0.07092931, 0.03345077, 0.04619129,\n",
       "            0.04008481],\n",
       "           [0.03748316, 0.18867262, 0.05252367, 0.08585974, 0.15389244,\n",
       "            0.05547939, 0.03823663, 0.06678554, 0.05023915, 0.18754567,\n",
       "            0.08328205],\n",
       "           [0.13863333, 0.23084454, 0.02650007, 0.05065136, 0.09777171,\n",
       "            0.06115841, 0.06240891, 0.03417011, 0.04777215, 0.17868645,\n",
       "            0.07140287]],\n",
       "  \n",
       "          [[0.01543199, 0.0148762 , 0.08238313, 0.12938169, 0.37098467,\n",
       "            0.05257461, 0.02294382, 0.04476886, 0.10250805, 0.12153509,\n",
       "            0.04261188],\n",
       "           [0.08948859, 0.02768529, 0.04140175, 0.07581624, 0.06419013,\n",
       "            0.04187305, 0.05779847, 0.06495181, 0.15583305, 0.19635011,\n",
       "            0.18461147],\n",
       "           [0.11278006, 0.12084841, 0.08050904, 0.03012889, 0.03646333,\n",
       "            0.11327022, 0.03557901, 0.07485689, 0.05011078, 0.16482486,\n",
       "            0.18062854],\n",
       "           [0.06871826, 0.45733696, 0.09831104, 0.02032866, 0.02335442,\n",
       "            0.06233878, 0.02494069, 0.05856483, 0.066033  , 0.0455476 ,\n",
       "            0.0745258 ],\n",
       "           [0.07889775, 0.08325955, 0.0265266 , 0.02135356, 0.04161362,\n",
       "            0.12795848, 0.09078275, 0.1112749 , 0.06553596, 0.13293585,\n",
       "            0.21986105],\n",
       "           [0.2582216 , 0.12362047, 0.0697116 , 0.14418834, 0.04136479,\n",
       "            0.04948938, 0.04859285, 0.05377408, 0.04380703, 0.05752105,\n",
       "            0.10970889],\n",
       "           [0.22155024, 0.16719718, 0.10530791, 0.03401116, 0.02397756,\n",
       "            0.03037617, 0.03735559, 0.06605195, 0.18367912, 0.0507647 ,\n",
       "            0.07972843],\n",
       "           [0.1996105 , 0.2451975 , 0.2170816 , 0.08457793, 0.07377175,\n",
       "            0.04398208, 0.03094682, 0.03164978, 0.0204937 , 0.02472075,\n",
       "            0.02796761],\n",
       "           [0.17323874, 0.05522162, 0.13076477, 0.1482808 , 0.09617979,\n",
       "            0.023017  , 0.09009161, 0.04717305, 0.09069964, 0.05840998,\n",
       "            0.08692293],\n",
       "           [0.07302105, 0.0250676 , 0.09199087, 0.17300875, 0.11546961,\n",
       "            0.09844059, 0.1686588 , 0.08485248, 0.02507829, 0.06382626,\n",
       "            0.08058568],\n",
       "           [0.0663293 , 0.33542415, 0.10418693, 0.01331063, 0.02116891,\n",
       "            0.07264746, 0.01727581, 0.04303393, 0.05154812, 0.1298849 ,\n",
       "            0.14518978]],\n",
       "  \n",
       "          [[0.02563878, 0.01423701, 0.06752028, 0.09104457, 0.15219903,\n",
       "            0.12092717, 0.04685695, 0.17678219, 0.10090304, 0.1298883 ,\n",
       "            0.07400263],\n",
       "           [0.02841054, 0.01037122, 0.02617034, 0.04439243, 0.02667495,\n",
       "            0.03340503, 0.04350943, 0.06552863, 0.14027055, 0.3531085 ,\n",
       "            0.2281583 ],\n",
       "           [0.09390213, 0.02043746, 0.02392839, 0.06650816, 0.08442947,\n",
       "            0.04881344, 0.05796036, 0.06612385, 0.43576086, 0.05820097,\n",
       "            0.04393497],\n",
       "           [0.17253889, 0.0456952 , 0.05472478, 0.07821258, 0.04432609,\n",
       "            0.08425073, 0.11846077, 0.09470118, 0.16210102, 0.06400496,\n",
       "            0.0809838 ],\n",
       "           [0.09371878, 0.10369036, 0.0439658 , 0.13206783, 0.06627624,\n",
       "            0.03865883, 0.07409793, 0.03899051, 0.26413804, 0.09006882,\n",
       "            0.0543269 ],\n",
       "           [0.10659207, 0.04817203, 0.0555986 , 0.12225562, 0.02674565,\n",
       "            0.02858597, 0.08192722, 0.03419204, 0.1820172 , 0.15608348,\n",
       "            0.15783015],\n",
       "           [0.3145905 , 0.1605394 , 0.08296313, 0.10330945, 0.03980982,\n",
       "            0.04462876, 0.08752537, 0.04460092, 0.03403529, 0.02895707,\n",
       "            0.05904027],\n",
       "           [0.41071635, 0.05569546, 0.02268473, 0.07439244, 0.02845293,\n",
       "            0.03044133, 0.04138262, 0.04957853, 0.08110066, 0.06976245,\n",
       "            0.13579246],\n",
       "           [0.13267241, 0.23812607, 0.10657885, 0.07715378, 0.02920017,\n",
       "            0.04088227, 0.06489504, 0.03775756, 0.01580034, 0.0999541 ,\n",
       "            0.15697937],\n",
       "           [0.08423746, 0.11407267, 0.0820413 , 0.13563685, 0.14032425,\n",
       "            0.0636908 , 0.0417511 , 0.06014261, 0.0441852 , 0.1145368 ,\n",
       "            0.11938093],\n",
       "           [0.09308583, 0.08809267, 0.05289305, 0.07945473, 0.13665612,\n",
       "            0.07505348, 0.08099544, 0.07442677, 0.03989732, 0.12790835,\n",
       "            0.15153624]]]], dtype=float32)>,\n",
       "  'decoder_layer2_block1': <tf.Tensor: shape=(1, 8, 11, 11), dtype=float32, numpy=\n",
       "  array([[[[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.65758264, 0.34241742, 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.49389902, 0.07007373, 0.43602732, 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.37260997, 0.17422076, 0.2614692 , 0.19170007, 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.63198894, 0.07750523, 0.09868948, 0.08954134, 0.10227494,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.47214884, 0.14697789, 0.08906434, 0.06042134, 0.1742294 ,\n",
       "            0.05715824, 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.14188729, 0.09374441, 0.05306858, 0.16513969, 0.11765733,\n",
       "            0.30862826, 0.11987443, 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.19659032, 0.07285158, 0.17780259, 0.15871827, 0.17835103,\n",
       "            0.06804229, 0.08734416, 0.06029979, 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.11710323, 0.07088599, 0.05784541, 0.16493048, 0.05105629,\n",
       "            0.15748012, 0.1233029 , 0.1789796 , 0.07841597, 0.        ,\n",
       "            0.        ],\n",
       "           [0.17259622, 0.14740358, 0.08278076, 0.06985555, 0.17244546,\n",
       "            0.08047958, 0.07180804, 0.05456072, 0.0661431 , 0.08192693,\n",
       "            0.        ],\n",
       "           [0.14449349, 0.12288345, 0.10163305, 0.05328555, 0.03717496,\n",
       "            0.10866366, 0.05698658, 0.09022747, 0.07298467, 0.09584717,\n",
       "            0.11582   ]],\n",
       "  \n",
       "          [[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.8511495 , 0.14885046, 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.7858836 , 0.03963053, 0.1744858 , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.6748557 , 0.07760024, 0.1204024 , 0.12714161, 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.251429  , 0.04321409, 0.22374585, 0.22516434, 0.2564467 ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.21428496, 0.06631252, 0.3006353 , 0.15149096, 0.04457202,\n",
       "            0.22270428, 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.1677272 , 0.12540248, 0.35418487, 0.08939698, 0.03824746,\n",
       "            0.13923329, 0.08580764, 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.33980897, 0.07184181, 0.04839052, 0.02920853, 0.07367196,\n",
       "            0.24808602, 0.09835622, 0.09063599, 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.22227366, 0.02395957, 0.20229268, 0.04752024, 0.02358631,\n",
       "            0.04651169, 0.09015414, 0.15339422, 0.19030751, 0.        ,\n",
       "            0.        ],\n",
       "           [0.46398416, 0.03957156, 0.05589975, 0.00928646, 0.059261  ,\n",
       "            0.10487555, 0.05336994, 0.03475048, 0.06592017, 0.11308091,\n",
       "            0.        ],\n",
       "           [0.10557638, 0.07535109, 0.04134755, 0.05527294, 0.03686333,\n",
       "            0.12211367, 0.2205249 , 0.03835426, 0.07153066, 0.10205148,\n",
       "            0.1310137 ]],\n",
       "  \n",
       "          [[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.57442117, 0.42557886, 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.07678834, 0.7806794 , 0.1425323 , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.39404818, 0.2081707 , 0.13420679, 0.26357436, 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.13663375, 0.50392705, 0.08306353, 0.20005032, 0.07632537,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.4771287 , 0.071353  , 0.03525117, 0.22059806, 0.03968231,\n",
       "            0.1559867 , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.41850814, 0.04030397, 0.08681139, 0.09309933, 0.08707891,\n",
       "            0.19338961, 0.08080864, 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.43423575, 0.06437676, 0.08019038, 0.08241303, 0.08888963,\n",
       "            0.05188997, 0.05085195, 0.14715253, 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.2532364 , 0.17015235, 0.10829954, 0.04391181, 0.1803923 ,\n",
       "            0.08734858, 0.05441813, 0.04348813, 0.05875282, 0.        ,\n",
       "            0.        ],\n",
       "           [0.17447464, 0.10100589, 0.13113676, 0.11135191, 0.07243873,\n",
       "            0.06488828, 0.1474762 , 0.05914965, 0.06569853, 0.07237942,\n",
       "            0.        ],\n",
       "           [0.17585255, 0.14778948, 0.04940129, 0.05264534, 0.05846062,\n",
       "            0.07241687, 0.03113067, 0.04253736, 0.01289276, 0.06763467,\n",
       "            0.28923845]],\n",
       "  \n",
       "          [[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.87427723, 0.1257228 , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.13005775, 0.8154025 , 0.05453971, 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.36900595, 0.3083896 , 0.18114267, 0.14146174, 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.43398127, 0.1448522 , 0.17660591, 0.17215303, 0.07240756,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.322196  , 0.06601287, 0.01273564, 0.1480526 , 0.27501345,\n",
       "            0.17598943, 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.22372618, 0.04174316, 0.06429053, 0.20606057, 0.11200958,\n",
       "            0.1499797 , 0.20219018, 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.22797325, 0.07954086, 0.03030987, 0.16312487, 0.144719  ,\n",
       "            0.11532764, 0.14079677, 0.09820775, 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.08393577, 0.02337957, 0.03606731, 0.15466386, 0.15216888,\n",
       "            0.12427629, 0.22436777, 0.15666263, 0.04447799, 0.        ,\n",
       "            0.        ],\n",
       "           [0.33661428, 0.06884786, 0.06491175, 0.07243712, 0.0752691 ,\n",
       "            0.09353467, 0.10749505, 0.05861429, 0.05691668, 0.06535909,\n",
       "            0.        ],\n",
       "           [0.31242627, 0.02462172, 0.02067862, 0.03764279, 0.05497877,\n",
       "            0.01544622, 0.05054389, 0.04646485, 0.079477  , 0.15010442,\n",
       "            0.20761544]],\n",
       "  \n",
       "          [[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.8663848 , 0.13361515, 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.79572767, 0.14895652, 0.05531589, 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.6733655 , 0.08357852, 0.1029692 , 0.14008684, 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.3441081 , 0.15563913, 0.05627447, 0.3877815 , 0.0561968 ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.13209586, 0.06755424, 0.08378736, 0.19976702, 0.3311879 ,\n",
       "            0.18560761, 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.05083916, 0.07098261, 0.05535303, 0.04842582, 0.40078124,\n",
       "            0.16221109, 0.21140711, 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.18032536, 0.03326381, 0.0348372 , 0.05564771, 0.17464194,\n",
       "            0.16467123, 0.24842839, 0.1081844 , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.16746275, 0.03934939, 0.01138333, 0.00636403, 0.26723668,\n",
       "            0.05084964, 0.01827367, 0.38750464, 0.05157587, 0.        ,\n",
       "            0.        ],\n",
       "           [0.15553132, 0.03777405, 0.01898603, 0.02108555, 0.06594881,\n",
       "            0.03119727, 0.03444092, 0.22786283, 0.03883298, 0.36834028,\n",
       "            0.        ],\n",
       "           [0.24452403, 0.12490269, 0.04868813, 0.1004199 , 0.05125454,\n",
       "            0.07414711, 0.04128287, 0.07079504, 0.03776997, 0.1401161 ,\n",
       "            0.06609959]],\n",
       "  \n",
       "          [[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.952615  , 0.04738493, 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.8049426 , 0.10906123, 0.08599612, 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.5868641 , 0.09797794, 0.22451377, 0.0906442 , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.32579687, 0.16452128, 0.19622795, 0.11793   , 0.19552393,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.39083752, 0.06228986, 0.12729773, 0.11840577, 0.1142308 ,\n",
       "            0.1869384 , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.25304648, 0.0813906 , 0.18890834, 0.06435733, 0.15693957,\n",
       "            0.14774658, 0.10761116, 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.16636382, 0.05452809, 0.1017209 , 0.06941878, 0.11740077,\n",
       "            0.1084866 , 0.16806248, 0.21401851, 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.23137079, 0.06227846, 0.07114712, 0.06755768, 0.12478812,\n",
       "            0.12422112, 0.09236191, 0.123171  , 0.10310377, 0.        ,\n",
       "            0.        ],\n",
       "           [0.16744469, 0.06349677, 0.11942551, 0.06017626, 0.1496992 ,\n",
       "            0.06033276, 0.06703266, 0.10227786, 0.08083145, 0.12928282,\n",
       "            0.        ],\n",
       "           [0.04934712, 0.07858701, 0.0904104 , 0.07330981, 0.13743767,\n",
       "            0.09631889, 0.1462812 , 0.07548509, 0.12812477, 0.07562742,\n",
       "            0.04907063]],\n",
       "  \n",
       "          [[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.36644658, 0.6335534 , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.53962773, 0.36692527, 0.09344703, 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.53311753, 0.17240144, 0.16211152, 0.13236952, 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.44884375, 0.08307243, 0.17439578, 0.24931403, 0.04437394,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.2748092 , 0.2377423 , 0.07057451, 0.32665828, 0.04080165,\n",
       "            0.04941403, 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.2572411 , 0.14717083, 0.14475115, 0.16644016, 0.07190011,\n",
       "            0.07477003, 0.13772662, 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.28422478, 0.20813438, 0.03182577, 0.2565609 , 0.07495483,\n",
       "            0.07246552, 0.0386833 , 0.03315059, 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.40950277, 0.0873801 , 0.0518956 , 0.10223116, 0.11032802,\n",
       "            0.05767837, 0.03736706, 0.06810676, 0.07551022, 0.        ,\n",
       "            0.        ],\n",
       "           [0.27083868, 0.03800764, 0.04848488, 0.10717748, 0.04203313,\n",
       "            0.02983588, 0.02600696, 0.10134718, 0.06999648, 0.26627168,\n",
       "            0.        ],\n",
       "           [0.15724838, 0.04869269, 0.07305586, 0.0403855 , 0.06161989,\n",
       "            0.04240522, 0.0547462 , 0.12308849, 0.1038307 , 0.15761156,\n",
       "            0.13731556]],\n",
       "  \n",
       "          [[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.26472968, 0.7352703 , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.0654943 , 0.4076884 , 0.52681726, 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.04945355, 0.09275357, 0.0307506 , 0.8270423 , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.08937331, 0.03329741, 0.66006416, 0.05555803, 0.16170709,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.07767727, 0.03036242, 0.82033896, 0.00689007, 0.02261495,\n",
       "            0.04211644, 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.12244423, 0.07927217, 0.2693888 , 0.08185908, 0.03526657,\n",
       "            0.16777332, 0.24399585, 0.        , 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.1322891 , 0.12510574, 0.13123149, 0.03691123, 0.03506545,\n",
       "            0.1589036 , 0.13942787, 0.24106556, 0.        , 0.        ,\n",
       "            0.        ],\n",
       "           [0.24641934, 0.10068939, 0.03220987, 0.069594  , 0.04041145,\n",
       "            0.1145469 , 0.11756103, 0.09034339, 0.18822464, 0.        ,\n",
       "            0.        ],\n",
       "           [0.04616075, 0.009337  , 0.01253803, 0.01422249, 0.0049588 ,\n",
       "            0.00802917, 0.03059516, 0.42303598, 0.22156222, 0.22956035,\n",
       "            0.        ],\n",
       "           [0.4339585 , 0.04777892, 0.01612055, 0.02886325, 0.01698111,\n",
       "            0.06379272, 0.03070276, 0.02292426, 0.01776987, 0.0852697 ,\n",
       "            0.23583834]]]], dtype=float32)>,\n",
       "  'decoder_layer2_block2': <tf.Tensor: shape=(1, 8, 11, 11), dtype=float32, numpy=\n",
       "  array([[[[1.92600954e-02, 2.88769156e-01, 1.20586358e-01,\n",
       "            1.97171584e-01, 9.51683894e-02, 1.54784499e-02,\n",
       "            5.09181097e-02, 9.21726227e-03, 1.36945751e-02,\n",
       "            1.55338064e-01, 3.43978889e-02],\n",
       "           [1.57848857e-02, 2.59997696e-02, 7.52025098e-02,\n",
       "            5.49041070e-02, 1.29279926e-01, 3.52522023e-02,\n",
       "            7.75224790e-02, 3.85220796e-02, 1.58944622e-01,\n",
       "            3.30254853e-01, 5.83326519e-02],\n",
       "           [1.20825171e-01, 6.11790828e-02, 4.31940705e-02,\n",
       "            6.31110519e-02, 7.19738975e-02, 8.43807906e-02,\n",
       "            2.16645990e-02, 6.88511506e-02, 2.40940213e-01,\n",
       "            1.39667884e-01, 8.42120796e-02],\n",
       "           [8.61387178e-02, 5.92756793e-02, 5.86883985e-02,\n",
       "            3.61222923e-02, 8.39889050e-02, 7.70888850e-02,\n",
       "            3.56496945e-02, 8.72658864e-02, 2.90199429e-01,\n",
       "            9.58202183e-02, 8.97619277e-02],\n",
       "           [6.28792718e-02, 1.52562428e-02, 1.73604470e-02,\n",
       "            3.14648226e-02, 1.50356963e-01, 1.45824984e-01,\n",
       "            8.81057754e-02, 9.96850878e-02, 1.94833636e-01,\n",
       "            1.25066981e-01, 6.91658184e-02],\n",
       "           [9.52599291e-03, 2.39649112e-03, 3.82838435e-02,\n",
       "            3.29448469e-02, 7.81352893e-02, 5.45310229e-02,\n",
       "            2.99749196e-01, 4.84812446e-02, 3.03658754e-01,\n",
       "            8.83237273e-02, 4.39696163e-02],\n",
       "           [3.60629782e-02, 4.44983132e-02, 5.29689416e-02,\n",
       "            3.06819268e-02, 2.27772482e-02, 5.34857213e-02,\n",
       "            3.98244672e-02, 1.04285412e-01, 4.38273638e-01,\n",
       "            8.05844218e-02, 9.65569615e-02],\n",
       "           [2.04177313e-02, 1.28218550e-02, 2.14896761e-02,\n",
       "            3.41835469e-02, 2.92365793e-02, 5.49014620e-02,\n",
       "            6.60327002e-02, 1.13030113e-01, 4.81259882e-01,\n",
       "            8.60545114e-02, 8.05719867e-02],\n",
       "           [5.96631207e-02, 5.28218150e-02, 3.41337994e-02,\n",
       "            6.49193302e-02, 3.59810852e-02, 8.44719484e-02,\n",
       "            7.88217857e-02, 1.33131370e-01, 2.13261813e-01,\n",
       "            1.46106169e-01, 9.66877714e-02],\n",
       "           [2.08113268e-02, 2.43281275e-02, 3.52498665e-02,\n",
       "            1.50315255e-01, 7.94243068e-02, 4.20668945e-02,\n",
       "            3.45971406e-01, 5.42656630e-02, 4.18188460e-02,\n",
       "            1.43202573e-01, 6.25457764e-02],\n",
       "           [2.04844289e-02, 2.97213681e-02, 5.17537296e-02,\n",
       "            1.31011739e-01, 1.14237949e-01, 1.69982776e-01,\n",
       "            1.62677348e-01, 9.71019566e-02, 4.66816649e-02,\n",
       "            1.36667669e-01, 3.96793820e-02]],\n",
       "  \n",
       "          [[1.14932038e-01, 2.95358896e-01, 3.52233231e-01,\n",
       "            1.07757546e-01, 6.70840591e-02, 1.06464522e-02,\n",
       "            2.32519731e-02, 3.38891242e-03, 4.83454298e-03,\n",
       "            1.06321014e-02, 9.88025963e-03],\n",
       "           [1.96772188e-01, 1.50297090e-01, 2.55067706e-01,\n",
       "            1.90137818e-01, 5.97305670e-02, 6.05350658e-02,\n",
       "            3.01980451e-02, 1.51144955e-02, 3.02338926e-03,\n",
       "            1.27117056e-02, 2.64119115e-02],\n",
       "           [1.05186716e-01, 5.89823276e-02, 8.05983692e-02,\n",
       "            1.61644503e-01, 1.24244176e-01, 2.36081034e-01,\n",
       "            8.21666867e-02, 7.17226043e-02, 1.94928069e-02,\n",
       "            2.94081736e-02, 3.04726325e-02],\n",
       "           [3.64297740e-02, 7.41869165e-03, 8.40978026e-02,\n",
       "            1.96571097e-01, 1.01711251e-01, 3.25115055e-01,\n",
       "            1.65181562e-01, 5.77312522e-02, 1.06703443e-02,\n",
       "            8.84682499e-03, 6.22628676e-03],\n",
       "           [8.73756856e-02, 4.29322198e-02, 1.59867313e-02,\n",
       "            2.39360407e-02, 5.83200417e-02, 9.42486618e-03,\n",
       "            2.63250060e-02, 1.65621731e-02, 3.11605632e-01,\n",
       "            2.10806891e-01, 1.96724728e-01],\n",
       "           [5.90811558e-02, 9.82475746e-03, 3.56802456e-02,\n",
       "            7.97664970e-02, 1.77341208e-01, 1.74629048e-01,\n",
       "            9.83402133e-02, 1.35324776e-01, 1.16664313e-01,\n",
       "            6.42684400e-02, 4.90793847e-02],\n",
       "           [2.49494147e-02, 3.87338898e-03, 2.81107537e-02,\n",
       "            1.05381399e-01, 1.53580889e-01, 5.23363277e-02,\n",
       "            1.31578639e-01, 4.95994389e-02, 4.07617331e-01,\n",
       "            3.63766998e-02, 6.59573171e-03],\n",
       "           [6.58677053e-03, 1.49259972e-03, 7.10675120e-03,\n",
       "            2.06254683e-02, 8.00423250e-02, 2.49621514e-02,\n",
       "            1.01472244e-01, 4.51513231e-02, 6.65288150e-01,\n",
       "            3.67985889e-02, 1.04735307e-02],\n",
       "           [1.41706215e-02, 1.25562139e-02, 2.30562538e-02,\n",
       "            3.80158722e-02, 1.74531519e-01, 2.49085203e-02,\n",
       "            1.07292742e-01, 3.96274105e-02, 4.82916325e-01,\n",
       "            6.65481687e-02, 1.63764022e-02],\n",
       "           [1.62865464e-02, 1.88137032e-02, 8.75166357e-02,\n",
       "            4.27714363e-02, 1.59012467e-01, 1.05594061e-02,\n",
       "            1.04532108e-01, 2.11226363e-02, 3.57346326e-01,\n",
       "            1.10022999e-01, 7.20156878e-02],\n",
       "           [9.10022948e-03, 4.89011072e-02, 5.48849776e-02,\n",
       "            1.75157096e-02, 9.31267720e-03, 7.40678608e-03,\n",
       "            8.92695598e-03, 1.77866202e-02, 2.35917661e-02,\n",
       "            2.71630257e-01, 5.30942857e-01]],\n",
       "  \n",
       "          [[1.17778718e-01, 5.90655804e-01, 2.68227667e-01,\n",
       "            2.27719825e-02, 5.00875351e-04, 6.25475950e-05,\n",
       "            1.14793306e-06, 6.62381694e-07, 1.46272143e-07,\n",
       "            1.51790033e-07, 2.58011539e-07],\n",
       "           [1.49853237e-03, 5.33988357e-01, 4.62231517e-01,\n",
       "            2.23394600e-03, 2.91591386e-05, 1.79643539e-05,\n",
       "            4.55307884e-07, 9.87852431e-08, 1.27803701e-09,\n",
       "            8.58740301e-11, 3.41971798e-11],\n",
       "           [2.39504769e-01, 5.20378817e-03, 5.78013182e-01,\n",
       "            1.71041667e-01, 5.13832783e-03, 1.04825175e-03,\n",
       "            4.89864251e-05, 1.07278788e-06, 1.34701290e-08,\n",
       "            1.03050757e-09, 1.79079807e-10],\n",
       "           [1.65808797e-02, 9.44733329e-04, 6.51260465e-02,\n",
       "            8.85635257e-01, 2.99556814e-02, 1.59990578e-03,\n",
       "            1.50879365e-04, 6.58878844e-06, 1.41013288e-07,\n",
       "            1.05849560e-08, 2.51362464e-09],\n",
       "           [1.54895231e-01, 6.26287801e-05, 2.48782262e-02,\n",
       "            1.20386347e-01, 1.08542189e-01, 5.81222534e-01,\n",
       "            5.02241123e-03, 4.93580615e-03, 3.19264873e-05,\n",
       "            1.77432121e-05, 4.98522058e-06],\n",
       "           [5.99278137e-04, 6.63905591e-03, 1.35108856e-02,\n",
       "            5.94840292e-03, 1.16226524e-01, 7.81405628e-01,\n",
       "            8.35242216e-03, 6.64698407e-02, 7.58055015e-04,\n",
       "            7.95038140e-05, 1.04403935e-05],\n",
       "           [6.23419532e-04, 4.29034262e-05, 3.66384105e-04,\n",
       "            2.82207178e-03, 8.56956467e-03, 4.66656834e-02,\n",
       "            6.17476583e-01, 4.78716865e-02, 2.14967385e-01,\n",
       "            3.98562402e-02, 2.07380932e-02],\n",
       "           [5.04425589e-06, 1.40010286e-07, 1.06876250e-05,\n",
       "            2.08864265e-04, 8.84867914e-04, 6.47082319e-03,\n",
       "            9.64824498e-01, 1.46193402e-02, 1.02366349e-02,\n",
       "            2.53516482e-03, 2.03876378e-04],\n",
       "           [5.02072647e-03, 2.29427140e-04, 1.40086189e-03,\n",
       "            1.15499357e-02, 2.14363158e-01, 5.26385978e-02,\n",
       "            3.82445335e-01, 4.29141074e-02, 2.40161225e-01,\n",
       "            4.09998074e-02, 8.27685837e-03],\n",
       "           [1.69231367e-04, 1.80512745e-06, 2.05565138e-05,\n",
       "            2.60386470e-04, 1.68907531e-02, 8.08209702e-02,\n",
       "            1.19321279e-01, 2.87036568e-01, 8.02971721e-02,\n",
       "            3.17741275e-01, 9.74399596e-02],\n",
       "           [1.51171962e-05, 5.42353007e-07, 3.56698979e-06,\n",
       "            3.78922523e-05, 2.14798655e-03, 9.12140182e-04,\n",
       "            2.80959357e-04, 7.07481243e-03, 4.08558827e-03,\n",
       "            4.37220842e-01, 5.48220515e-01]],\n",
       "  \n",
       "          [[1.26771376e-01, 1.95288211e-01, 6.21050358e-01,\n",
       "            5.49059547e-02, 1.44007546e-03, 3.26580077e-04,\n",
       "            1.90634964e-04, 1.01315818e-05, 7.97895791e-06,\n",
       "            3.01547925e-06, 5.77371566e-06],\n",
       "           [3.12524915e-01, 2.87351031e-02, 4.82288778e-01,\n",
       "            1.58411339e-01, 8.93454440e-03, 7.44892331e-03,\n",
       "            1.52033102e-03, 1.19705845e-04, 1.26767245e-05,\n",
       "            2.34154140e-06, 1.43321336e-06],\n",
       "           [4.10014451e-01, 8.08420498e-03, 9.72393677e-02,\n",
       "            1.72642529e-01, 1.45882636e-01, 1.44420087e-01,\n",
       "            1.27332248e-02, 7.32218754e-03, 1.47011864e-03,\n",
       "            1.60796480e-04, 3.04762507e-05],\n",
       "           [1.16583027e-01, 3.67698516e-03, 3.98824215e-02,\n",
       "            6.64737597e-02, 6.77819788e-01, 7.83706158e-02,\n",
       "            9.50576458e-03, 5.89366630e-03, 1.57189160e-03,\n",
       "            1.57821283e-04, 6.43685562e-05],\n",
       "           [1.19744524e-01, 2.16451031e-03, 5.30929826e-02,\n",
       "            1.14111140e-01, 9.71230268e-02, 4.66250777e-01,\n",
       "            9.08881873e-02, 4.93175946e-02, 6.19160431e-03,\n",
       "            8.83997767e-04, 2.31645638e-04],\n",
       "           [2.68958579e-03, 3.21778469e-04, 1.21467523e-02,\n",
       "            1.30938701e-02, 8.79629795e-03, 1.00442596e-01,\n",
       "            8.20177674e-01, 1.84080955e-02, 2.14984212e-02,\n",
       "            2.20992439e-03, 2.15059263e-04],\n",
       "           [2.88521335e-03, 8.10722937e-04, 1.59836803e-02,\n",
       "            9.47882235e-03, 3.32227238e-02, 2.45112076e-01,\n",
       "            4.64716673e-01, 1.17368475e-01, 8.09825808e-02,\n",
       "            2.15364341e-02, 7.90261663e-03],\n",
       "           [4.81111184e-03, 8.53154779e-05, 3.52004077e-03,\n",
       "            2.94916937e-03, 1.59312189e-02, 4.93608303e-02,\n",
       "            9.02008489e-02, 3.69912952e-01, 2.26983279e-01,\n",
       "            2.14008659e-01, 2.22365614e-02],\n",
       "           [8.17430730e-04, 2.26007644e-04, 3.32333939e-03,\n",
       "            2.80322693e-03, 4.25521331e-03, 1.07468270e-01,\n",
       "            3.19215745e-01, 2.89920628e-01, 1.80962503e-01,\n",
       "            7.41595700e-02, 1.68480370e-02],\n",
       "           [2.46619747e-04, 1.49606989e-04, 4.58859518e-04,\n",
       "            7.78332236e-04, 1.89977884e-03, 2.55436283e-02,\n",
       "            3.86612602e-02, 3.20090204e-01, 1.64022610e-01,\n",
       "            2.58873671e-01, 1.89275414e-01],\n",
       "           [1.09728368e-03, 8.99327220e-04, 3.96771915e-03,\n",
       "            5.28181298e-03, 1.58745665e-02, 3.66983823e-02,\n",
       "            3.11813086e-01, 1.08031377e-01, 2.50766814e-01,\n",
       "            1.28081337e-01, 1.37488320e-01]],\n",
       "  \n",
       "          [[2.83921450e-01, 7.37852529e-02, 1.09835565e-01,\n",
       "            9.38629434e-02, 1.73138469e-01, 3.93938348e-02,\n",
       "            4.31276709e-02, 1.61752664e-02, 2.41177306e-02,\n",
       "            1.08402632e-01, 3.42391357e-02],\n",
       "           [3.89735162e-01, 5.89422919e-02, 1.04205549e-01,\n",
       "            1.74058035e-01, 1.35669440e-01, 6.19901866e-02,\n",
       "            2.64431760e-02, 1.70436222e-02, 1.42652141e-02,\n",
       "            1.12221213e-02, 6.42523868e-03],\n",
       "           [3.14324051e-01, 4.59593013e-02, 1.81403697e-01,\n",
       "            1.22071654e-01, 1.43289700e-01, 1.30764201e-01,\n",
       "            2.80558355e-02, 1.78186819e-02, 7.45136151e-03,\n",
       "            4.71890904e-03, 4.14256984e-03],\n",
       "           [2.97750801e-01, 6.12806305e-02, 4.30959351e-02,\n",
       "            2.81707585e-01, 1.95623934e-01, 5.28796464e-02,\n",
       "            3.59111978e-03, 1.58279985e-02, 3.15686837e-02,\n",
       "            9.00761224e-03, 7.66596850e-03],\n",
       "           [3.24799180e-01, 1.06120497e-01, 6.06038310e-02,\n",
       "            1.16882361e-01, 9.51090157e-02, 1.84017196e-01,\n",
       "            3.80992666e-02, 3.83311473e-02, 1.89891346e-02,\n",
       "            1.03759794e-02, 6.67245407e-03],\n",
       "           [6.11019023e-02, 2.22723670e-02, 1.33440271e-01,\n",
       "            9.05979499e-02, 1.58128411e-01, 9.24431160e-02,\n",
       "            3.89599323e-01, 1.85905807e-02, 2.27023773e-02,\n",
       "            8.85497313e-03, 2.26865476e-03],\n",
       "           [2.31233332e-02, 2.89963875e-02, 1.35445476e-01,\n",
       "            1.25293911e-01, 2.12333843e-01, 4.11270037e-02,\n",
       "            2.88984746e-01, 2.79209241e-02, 7.62389377e-02,\n",
       "            2.71415580e-02, 1.33938910e-02],\n",
       "           [2.72881016e-02, 2.04908475e-02, 4.64130156e-02,\n",
       "            3.62783313e-01, 9.72834080e-02, 3.37308086e-02,\n",
       "            1.61106914e-01, 3.93706858e-02, 1.47705629e-01,\n",
       "            4.40372042e-02, 1.97901316e-02],\n",
       "           [3.65760364e-02, 4.21485268e-02, 3.88868265e-02,\n",
       "            7.54621625e-02, 1.19828992e-01, 9.03893784e-02,\n",
       "            7.77278543e-02, 1.20767355e-01, 2.71704882e-01,\n",
       "            5.93331121e-02, 6.71748966e-02],\n",
       "           [6.20586388e-02, 4.98929098e-02, 1.89161412e-02,\n",
       "            2.58723766e-01, 4.14873436e-02, 2.63283979e-02,\n",
       "            9.69203189e-02, 6.13116510e-02, 2.45122150e-01,\n",
       "            8.51577148e-02, 5.40809035e-02],\n",
       "           [1.17046917e-02, 6.22909889e-03, 1.23461066e-02,\n",
       "            2.73594540e-02, 5.79135045e-02, 2.85007525e-02,\n",
       "            1.84598029e-01, 4.94911894e-02, 1.62952706e-01,\n",
       "            3.13906223e-01, 1.44998282e-01]],\n",
       "  \n",
       "          [[2.90123582e-01, 1.86554715e-01, 1.92174181e-01,\n",
       "            1.02816850e-01, 3.59071866e-02, 1.35663539e-01,\n",
       "            3.71238105e-02, 1.15506053e-02, 1.14708941e-03,\n",
       "            4.59475769e-03, 2.34366464e-03],\n",
       "           [3.46689522e-01, 2.75771208e-02, 1.79313049e-01,\n",
       "            3.90563399e-01, 2.89654043e-02, 1.99440774e-02,\n",
       "            4.48199688e-03, 2.02023191e-03, 2.37040382e-04,\n",
       "            1.23498874e-04, 8.47083502e-05],\n",
       "           [2.19118029e-01, 4.16598246e-02, 2.08529592e-01,\n",
       "            3.48207206e-01, 5.11540808e-02, 1.28093868e-01,\n",
       "            9.85276769e-04, 2.20456743e-03, 3.34473698e-05,\n",
       "            7.09232745e-06, 7.00704595e-06],\n",
       "           [5.99857904e-02, 5.05937310e-03, 1.89495608e-02,\n",
       "            8.62242281e-01, 1.40345544e-02, 2.52245720e-02,\n",
       "            6.84846193e-03, 5.57827344e-03, 1.41776225e-03,\n",
       "            4.49198444e-04, 2.10199025e-04],\n",
       "           [1.55026108e-01, 2.24588346e-03, 6.20947406e-02,\n",
       "            4.47671592e-01, 1.22209430e-01, 1.41598091e-01,\n",
       "            5.68707548e-02, 8.62181094e-03, 3.33799608e-03,\n",
       "            2.55444465e-04, 6.81249876e-05],\n",
       "           [6.42979816e-02, 1.04518258e-03, 5.82840107e-02,\n",
       "            1.44094974e-01, 6.41708672e-02, 3.92451614e-01,\n",
       "            1.91576168e-01, 5.85932434e-02, 2.25563701e-02,\n",
       "            1.97771145e-03, 9.51940485e-04],\n",
       "           [1.47734834e-02, 2.25849194e-03, 2.10584588e-02,\n",
       "            5.93119264e-02, 1.87413856e-01, 2.84062356e-01,\n",
       "            9.66460556e-02, 1.40943557e-01, 1.60891384e-01,\n",
       "            2.18532719e-02, 1.07871592e-02],\n",
       "           [1.16193611e-02, 3.33790062e-03, 3.51289958e-02,\n",
       "            8.29186812e-02, 4.84987460e-02, 2.70716339e-01,\n",
       "            1.40032694e-01, 2.13053331e-01, 1.68328062e-01,\n",
       "            1.27853686e-02, 1.35805747e-02],\n",
       "           [1.87395595e-03, 1.37847062e-04, 8.86526366e-04,\n",
       "            2.09374423e-03, 5.89682274e-02, 6.75847352e-01,\n",
       "            4.79424652e-03, 2.27421016e-01, 2.18950938e-02,\n",
       "            3.16698337e-03, 2.91489717e-03],\n",
       "           [1.43941958e-03, 1.62936674e-04, 1.52671803e-03,\n",
       "            1.45330979e-03, 1.23281702e-02, 7.11958036e-02,\n",
       "            6.54414073e-02, 1.94731846e-01, 4.27344203e-01,\n",
       "            1.04604080e-01, 1.19772121e-01],\n",
       "           [6.83975592e-03, 4.75386856e-03, 6.39452180e-03,\n",
       "            6.76972140e-03, 5.42704109e-03, 2.38245919e-01,\n",
       "            7.64890835e-02, 4.01663512e-01, 9.42910090e-02,\n",
       "            9.87915024e-02, 6.03340268e-02]],\n",
       "  \n",
       "          [[5.06522041e-03, 1.89234801e-02, 6.84538158e-03,\n",
       "            1.30556999e-02, 7.01268204e-03, 1.05281651e-03,\n",
       "            6.86808780e-04, 8.47692136e-03, 8.66821874e-03,\n",
       "            4.75602031e-01, 4.54610646e-01],\n",
       "           [2.65106815e-03, 9.89769220e-01, 5.46041271e-03,\n",
       "            2.06565019e-03, 6.38488291e-06, 4.52833046e-05,\n",
       "            2.99351484e-07, 1.54477493e-06, 4.02975475e-09,\n",
       "            9.56879198e-09, 8.89466545e-09],\n",
       "           [2.75472756e-02, 9.11984185e-04, 8.85686994e-01,\n",
       "            8.57523680e-02, 6.75462388e-06, 1.79611252e-05,\n",
       "            7.66385565e-05, 6.21250464e-08, 3.20774324e-10,\n",
       "            3.32218075e-09, 2.92680258e-09],\n",
       "           [1.26737906e-02, 8.88778686e-06, 1.87809893e-03,\n",
       "            9.85306263e-01, 1.20450139e-04, 3.12117163e-06,\n",
       "            9.17504167e-06, 8.76125839e-08, 2.92171198e-09,\n",
       "            5.21084953e-09, 2.90625546e-09],\n",
       "           [6.19914085e-02, 2.55278992e-05, 3.06679576e-04,\n",
       "            4.85834898e-03, 9.31359947e-01, 1.10001024e-03,\n",
       "            3.18793551e-04, 1.91204617e-05, 1.58297262e-05,\n",
       "            3.88622084e-06, 3.89182702e-07],\n",
       "           [1.67083684e-02, 1.19617653e-04, 4.27572668e-04,\n",
       "            6.28439011e-04, 2.16884771e-03, 9.65352237e-01,\n",
       "            2.52610917e-04, 1.43395895e-02, 1.87110356e-06,\n",
       "            6.16953344e-07, 1.52833692e-07],\n",
       "           [1.30307721e-03, 1.00780126e-05, 1.39576837e-03,\n",
       "            2.50584353e-03, 7.97976181e-03, 1.02621578e-02,\n",
       "            9.75822091e-01, 3.22388631e-04, 3.95164971e-04,\n",
       "            2.03107197e-06, 1.72590671e-06],\n",
       "           [2.42860297e-05, 6.39356257e-09, 7.50955005e-05,\n",
       "            5.53750957e-04, 1.25875769e-04, 1.08849536e-05,\n",
       "            9.99135435e-01, 3.77728679e-06, 7.06572027e-05,\n",
       "            1.43166673e-07, 6.31339176e-08],\n",
       "           [3.37399822e-03, 3.81493265e-07, 3.03459074e-05,\n",
       "            1.30139652e-03, 2.93228216e-02, 8.64850059e-02,\n",
       "            6.36342689e-02, 3.81038450e-02, 7.77457833e-01,\n",
       "            1.22368321e-04, 1.67861697e-04],\n",
       "           [1.28815088e-07, 3.21048466e-10, 2.88316859e-09,\n",
       "            3.24688259e-08, 1.43211582e-04, 5.17646413e-06,\n",
       "            2.39932866e-04, 1.03063525e-04, 9.99423504e-01,\n",
       "            5.85593007e-05, 2.63658640e-05],\n",
       "           [1.35698181e-04, 1.17900385e-07, 4.78653783e-05,\n",
       "            2.66366478e-05, 6.33544505e-01, 5.53807826e-04,\n",
       "            1.04503636e-03, 8.71999306e-04, 3.61636892e-04,\n",
       "            3.61504704e-01, 1.90797378e-03]],\n",
       "  \n",
       "          [[2.35461727e-01, 1.63103223e-01, 4.24231857e-01,\n",
       "            1.48431137e-01, 1.61152557e-02, 1.15318056e-02,\n",
       "            9.11736803e-04, 1.78956339e-04, 9.64536503e-06,\n",
       "            2.01373405e-05, 4.48625133e-06],\n",
       "           [6.59276848e-05, 9.64115858e-01, 3.54368836e-02,\n",
       "            3.64150619e-04, 7.42663860e-06, 9.52615846e-06,\n",
       "            5.31763611e-08, 1.12442173e-07, 1.86217264e-10,\n",
       "            1.18309335e-10, 2.54070459e-10],\n",
       "           [2.82085920e-03, 1.35153218e-03, 9.95283306e-01,\n",
       "            5.02667564e-04, 3.04197110e-05, 9.06635250e-06,\n",
       "            2.16774765e-06, 2.49004852e-08, 3.63793856e-10,\n",
       "            2.28892502e-10, 4.40129981e-11],\n",
       "           [4.09380766e-03, 2.17576235e-05, 3.58168781e-03,\n",
       "            9.91512001e-01, 5.58357977e-04, 2.95650898e-05,\n",
       "            2.01700735e-04, 1.01274873e-06, 1.57024843e-07,\n",
       "            4.63463268e-09, 8.27106106e-10],\n",
       "           [3.20240948e-03, 5.25990288e-07, 1.07022701e-04,\n",
       "            2.75543891e-03, 9.93827760e-01, 9.67774613e-05,\n",
       "            1.69674138e-07, 6.79947880e-06, 2.91965148e-06,\n",
       "            1.30887628e-07, 1.77586390e-08],\n",
       "           [8.93737015e-04, 1.00077561e-03, 5.39263850e-03,\n",
       "            6.14423421e-04, 9.76721523e-04, 9.60459352e-01,\n",
       "            2.26665798e-04, 3.04277986e-02, 6.18423485e-07,\n",
       "            5.57203066e-06, 1.60787761e-06],\n",
       "           [1.67109087e-04, 1.72591206e-06, 5.01376999e-05,\n",
       "            1.14607748e-04, 1.12535763e-05, 1.42492098e-03,\n",
       "            9.97734189e-01, 1.40638120e-04, 3.38178477e-04,\n",
       "            8.37589414e-06, 8.83776920e-06],\n",
       "           [1.38484620e-06, 8.74035511e-09, 3.17274498e-06,\n",
       "            1.15153471e-05, 1.01051704e-07, 3.17308550e-05,\n",
       "            9.99431789e-01, 4.57571841e-05, 4.70670580e-04,\n",
       "            1.75204093e-06, 2.17721276e-06],\n",
       "           [4.77164797e-03, 5.41360407e-07, 1.10525820e-04,\n",
       "            1.51676778e-03, 1.73065357e-03, 1.35635249e-02,\n",
       "            5.71424901e-01, 3.09898444e-02, 3.32692772e-01,\n",
       "            2.43656375e-02, 1.88331995e-02],\n",
       "           [1.30544936e-06, 2.68024179e-11, 1.19223875e-08,\n",
       "            1.64680344e-07, 6.25905886e-05, 2.36999531e-05,\n",
       "            1.74516847e-03, 8.56768456e-04, 9.89587307e-01,\n",
       "            3.55104893e-03, 4.17191023e-03],\n",
       "           [1.11523086e-05, 8.15504819e-08, 4.24788141e-06,\n",
       "            2.36416668e-06, 5.12433611e-03, 1.90708633e-05,\n",
       "            2.83801751e-06, 2.16134911e-04, 3.36262368e-04,\n",
       "            9.71909046e-01, 2.23745201e-02]]]], dtype=float32)>,\n",
       "  'decoder_layer3_block1': <tf.Tensor: shape=(1, 8, 11, 11), dtype=float32, numpy=\n",
       "  array([[[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.53743613e-01, 1.46256417e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.72770119e-01, 8.10479447e-02, 3.46181899e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.66807389e-01, 4.43930142e-02, 1.59453079e-01,\n",
       "            2.29346439e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.52621770e-01, 6.71242457e-03, 8.82945657e-02,\n",
       "            7.71098211e-02, 7.52613917e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.46620828e-01, 2.39439253e-02, 7.80431032e-02,\n",
       "            1.95478305e-01, 2.54573435e-01, 1.01340368e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.72924459e-01, 1.79021135e-02, 5.05300388e-02,\n",
       "            2.97751099e-01, 3.38900506e-01, 1.01959690e-01,\n",
       "            2.00321246e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.75860775e-01, 1.28973005e-02, 2.89635733e-02,\n",
       "            1.35943100e-01, 8.35250095e-02, 1.50723070e-01,\n",
       "            1.97414663e-02, 9.23457742e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [9.93433669e-02, 4.73148935e-02, 2.14954279e-02,\n",
       "            1.35625869e-01, 2.76693255e-01, 7.25246593e-02,\n",
       "            2.08051056e-02, 2.94190824e-01, 3.20066139e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.54134715e-01, 3.80772315e-02, 3.38917710e-02,\n",
       "            4.15156037e-02, 3.86740975e-02, 1.90759867e-01,\n",
       "            1.08530484e-02, 5.01945615e-02, 1.63395986e-01,\n",
       "            1.78503051e-01, 0.00000000e+00],\n",
       "           [1.15698949e-01, 3.47596891e-02, 2.98815724e-02,\n",
       "            4.03332673e-02, 3.23797427e-02, 7.25411400e-02,\n",
       "            1.08305272e-02, 2.85788532e-02, 6.15011714e-02,\n",
       "            2.25471690e-01, 3.48023444e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.68911183e-01, 2.31088802e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.99635845e-01, 2.62454331e-01, 2.37909883e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.46285141e-01, 6.11282103e-02, 9.90616828e-02,\n",
       "            9.35249180e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.53139219e-01, 4.56729904e-02, 3.73588234e-01,\n",
       "            3.47518802e-01, 8.00807625e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.46225321e-01, 3.79186273e-02, 9.57240611e-02,\n",
       "            2.65754968e-01, 9.77638811e-02, 1.56613126e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.71711195e-01, 1.81361623e-02, 5.48006110e-02,\n",
       "            5.06395996e-02, 3.38868767e-01, 9.38558131e-02,\n",
       "            7.19877928e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.09545743e-01, 1.92472748e-02, 3.90868150e-02,\n",
       "            1.24918796e-01, 9.06455219e-02, 6.22768663e-02,\n",
       "            4.59067784e-02, 1.08372197e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.89095849e-01, 2.93375533e-02, 6.27519414e-02,\n",
       "            7.81570524e-02, 8.84638578e-02, 5.49452156e-02,\n",
       "            7.88929164e-02, 2.05902502e-01, 1.12453088e-01,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.87157050e-01, 2.08598878e-02, 2.69928221e-02,\n",
       "            9.04429629e-02, 3.40129435e-02, 5.71559891e-02,\n",
       "            7.42718950e-02, 6.14581332e-02, 1.63488895e-01,\n",
       "            2.84159392e-01, 0.00000000e+00],\n",
       "           [1.03279822e-01, 3.67362462e-02, 6.18562624e-02,\n",
       "            2.32370459e-02, 6.80038556e-02, 4.25037853e-02,\n",
       "            9.06644538e-02, 5.93081079e-02, 6.22280724e-02,\n",
       "            2.77885675e-01, 1.74296737e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.08790123e-01, 2.91209817e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.00803553e-02, 8.97180200e-01, 5.27394488e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.57720643e-01, 2.30180845e-01, 8.56352895e-02,\n",
       "            3.26463282e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.44892323e-01, 4.95405048e-02, 5.58679327e-02,\n",
       "            2.65045524e-01, 2.84653723e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.57800698e-01, 4.37089428e-02, 8.29134285e-02,\n",
       "            1.60820205e-02, 3.11784297e-02, 6.83164001e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.32759094e-01, 2.86013968e-02, 3.88847888e-02,\n",
       "            1.93815008e-02, 2.92186700e-02, 8.18303823e-02,\n",
       "            1.69324204e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.87237142e-02, 2.56615672e-02, 5.67976106e-03,\n",
       "            5.29807732e-02, 7.51904920e-02, 6.03803061e-02,\n",
       "            5.82442880e-02, 6.63139105e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.93758026e-01, 3.69695872e-02, 1.48810698e-02,\n",
       "            1.22230425e-01, 1.50863245e-01, 6.23454452e-02,\n",
       "            6.07284233e-02, 2.69249558e-01, 8.89742076e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.19001597e-01, 9.75371990e-03, 3.39798117e-03,\n",
       "            1.98582429e-02, 4.37112860e-02, 3.92419472e-02,\n",
       "            7.90142082e-03, 1.63369495e-02, 2.55284514e-02,\n",
       "            7.15268433e-01, 0.00000000e+00],\n",
       "           [1.55172408e-01, 2.84222625e-02, 6.76639006e-03,\n",
       "            7.90779945e-04, 2.22800523e-02, 3.65629941e-02,\n",
       "            1.89993810e-02, 1.16455499e-02, 2.96918470e-02,\n",
       "            2.47535720e-01, 4.42132622e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.40309322e-01, 1.59690693e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.13087797e-01, 9.43065733e-02, 1.92605644e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.17588067e-01, 5.63705079e-02, 6.21508136e-02,\n",
       "            1.63890570e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.67423022e-01, 3.60578373e-02, 1.25878602e-01,\n",
       "            1.59354568e-01, 2.11285964e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.05106753e-01, 4.57223095e-02, 6.69323951e-02,\n",
       "            2.12656096e-01, 1.84411049e-01, 8.51714090e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.48387766e-01, 5.98675795e-02, 5.03112674e-02,\n",
       "            9.93531272e-02, 1.46070763e-01, 4.89418171e-02,\n",
       "            4.70676310e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.55992907e-01, 1.73174199e-02, 2.15153471e-02,\n",
       "            5.36147952e-02, 1.00348033e-01, 4.27802503e-02,\n",
       "            2.95660961e-02, 2.78865159e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.98312116e-01, 1.37154646e-02, 1.36029730e-02,\n",
       "            5.46944663e-02, 8.19281563e-02, 3.16825733e-02,\n",
       "            1.89030282e-02, 2.42685631e-01, 4.44755554e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.22977924e-01, 4.68167514e-02, 2.64078844e-02,\n",
       "            2.15726532e-02, 6.57365546e-02, 3.02026030e-02,\n",
       "            4.44959663e-02, 6.75216466e-02, 5.31901382e-02,\n",
       "            2.21077904e-01, 0.00000000e+00],\n",
       "           [2.17514217e-01, 2.89444495e-02, 4.58887555e-02,\n",
       "            2.94252653e-02, 7.69660026e-02, 2.77002435e-02,\n",
       "            2.92829406e-02, 5.76972738e-02, 4.35229279e-02,\n",
       "            3.90968710e-01, 5.20892330e-02]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.73177278e-01, 4.26822692e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.62536484e-01, 3.83074820e-01, 1.54388726e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.82928371e-01, 1.28754541e-01, 1.86145976e-01,\n",
       "            3.02171141e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.44416490e-01, 1.30903438e-01, 6.64912164e-02,\n",
       "            2.72163332e-01, 2.86025524e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.94792792e-01, 4.69252989e-02, 9.91073474e-02,\n",
       "            2.39073217e-01, 3.13089490e-01, 1.07011892e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.59236103e-01, 2.15774328e-02, 1.03884913e-01,\n",
       "            2.41241366e-01, 3.90842885e-01, 4.44959551e-02,\n",
       "            3.87213007e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.63252020e-01, 6.36386797e-02, 2.92476565e-02,\n",
       "            1.36954501e-01, 2.70312876e-01, 1.14590690e-01,\n",
       "            1.51442001e-02, 1.06859386e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.59180105e-01, 5.78683242e-02, 4.26572524e-02,\n",
       "            7.44601637e-02, 1.42878130e-01, 1.09697104e-01,\n",
       "            4.95821312e-02, 2.61822402e-01, 1.01854384e-01,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.95227015e-01, 9.54755247e-02, 1.88339651e-02,\n",
       "            6.68083280e-02, 8.40477496e-02, 1.60013273e-01,\n",
       "            2.24715471e-02, 2.83323284e-02, 7.15038329e-02,\n",
       "            5.72864376e-02, 0.00000000e+00],\n",
       "           [3.26883718e-02, 3.06067690e-02, 6.78896755e-02,\n",
       "            6.89678788e-02, 3.36458348e-02, 5.35002276e-02,\n",
       "            5.23929950e-03, 2.18871515e-02, 3.37507948e-02,\n",
       "            4.15520929e-02, 6.10271871e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.90265226e-01, 1.09734774e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.44455138e-02, 1.03922203e-01, 8.11632335e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.66529536e-02, 1.09131619e-01, 2.03743905e-01,\n",
       "            6.20471537e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.85631412e-01, 2.11238470e-02, 1.67303294e-01,\n",
       "            2.42013142e-01, 1.83928296e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.90142885e-02, 4.44126576e-02, 2.56413013e-01,\n",
       "            4.64496613e-01, 7.62813613e-02, 8.93820971e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.30560827e-02, 1.11202873e-01, 8.64158422e-02,\n",
       "            1.51950538e-01, 2.41841748e-01, 1.06220156e-01,\n",
       "            2.89312780e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.55359286e-02, 6.93989312e-03, 1.19433135e-01,\n",
       "            6.68048143e-01, 1.35792345e-02, 6.86906697e-03,\n",
       "            8.66868999e-03, 9.09258276e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.54202369e-02, 4.89242114e-02, 7.96836838e-02,\n",
       "            3.41253668e-01, 2.29262933e-02, 1.71067715e-02,\n",
       "            3.29037607e-02, 3.11854690e-01, 9.99266952e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.46056810e-01, 4.71874811e-02, 8.55172426e-02,\n",
       "            2.55286723e-01, 1.06997518e-02, 2.31059212e-02,\n",
       "            8.22521560e-03, 7.28583559e-02, 1.13420010e-01,\n",
       "            1.37642413e-01, 0.00000000e+00],\n",
       "           [2.52837017e-02, 1.88627150e-02, 1.84682980e-02,\n",
       "            2.11511273e-02, 1.78983267e-02, 1.52223902e-02,\n",
       "            5.66427931e-02, 2.29024306e-01, 3.74193564e-02,\n",
       "            3.16542953e-01, 2.43484035e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.75638010e-02, 9.72436190e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [9.26553309e-01, 4.19068001e-02, 3.15398164e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [9.12125558e-02, 3.94437611e-02, 1.44881621e-01,\n",
       "            7.24462032e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.90626001e-02, 1.17407106e-01, 1.00543154e-02,\n",
       "            1.29204355e-02, 8.00555587e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.68972328e-01, 4.74565662e-02, 7.88774923e-04,\n",
       "            5.02376875e-04, 1.81765124e-01, 6.00514829e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.08032984e-02, 6.90322220e-02, 2.43564602e-03,\n",
       "            3.48537532e-03, 1.88998505e-01, 3.22328389e-01,\n",
       "            3.72916579e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.22566491e-02, 1.57062931e-03, 9.52856062e-05,\n",
       "            7.04879858e-05, 5.63960969e-01, 3.63085300e-01,\n",
       "            6.35756459e-03, 2.60313111e-03, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.97770283e-01, 1.08844675e-02, 2.52602017e-03,\n",
       "            7.03298720e-03, 2.49688774e-01, 3.23587418e-01,\n",
       "            8.93757716e-02, 9.21421051e-02, 2.69923098e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.12951612e-01, 8.50757118e-03, 9.40403203e-04,\n",
       "            1.01106870e-03, 2.39092648e-01, 1.85876563e-01,\n",
       "            1.77125819e-02, 1.02123711e-03, 9.29941074e-04,\n",
       "            3.19563635e-02, 0.00000000e+00],\n",
       "           [4.23605666e-02, 4.72520925e-02, 2.66751205e-03,\n",
       "            1.60924962e-03, 3.21131051e-02, 2.42587507e-01,\n",
       "            1.78335950e-01, 2.48052105e-02, 4.34558699e-03,\n",
       "            1.92058027e-01, 2.31865153e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.30530810e-01, 4.69469219e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.73318768e-01, 7.17312247e-02, 6.54949963e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.00534785e-01, 1.70784164e-02, 5.80666140e-02,\n",
       "            1.24320149e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.61978900e-01, 1.92334317e-03, 1.71286732e-01,\n",
       "            1.92926750e-01, 4.71884251e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.19527020e-01, 6.39547687e-03, 3.09380554e-02,\n",
       "            1.31733909e-01, 6.23519599e-01, 8.78859833e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.27103059e-02, 1.36399986e-02, 1.33264475e-02,\n",
       "            4.42807637e-02, 7.97476709e-01, 4.94143590e-02,\n",
       "            2.91513782e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.37240463e-02, 8.84301146e-04, 5.17299213e-03,\n",
       "            1.04934322e-02, 1.95504297e-02, 4.54660784e-03,\n",
       "            2.08537001e-02, 8.64774525e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.92556547e-03, 5.76384657e-04, 9.10922070e-04,\n",
       "            4.46330337e-03, 3.55384126e-02, 3.62027180e-03,\n",
       "            1.25144515e-02, 8.70575130e-01, 6.88755289e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.33730888e-02, 6.15361729e-04, 1.49198947e-03,\n",
       "            3.79266357e-03, 4.72751725e-03, 1.32234069e-03,\n",
       "            1.31400174e-03, 1.33981016e-02, 4.20510443e-03,\n",
       "            9.05759871e-01, 0.00000000e+00],\n",
       "           [3.24214220e-01, 1.92792434e-02, 1.68593787e-02,\n",
       "            3.35168652e-02, 1.29501447e-02, 9.04529821e-03,\n",
       "            1.64532550e-02, 5.52771892e-03, 1.73832718e-02,\n",
       "            1.41260084e-02, 5.30644596e-01]]]], dtype=float32)>,\n",
       "  'decoder_layer3_block2': <tf.Tensor: shape=(1, 8, 11, 11), dtype=float32, numpy=\n",
       "  array([[[[4.25585620e-02, 7.81148300e-02, 8.70712399e-01,\n",
       "            6.78230450e-03, 1.71185250e-03, 1.10152359e-04,\n",
       "            9.17860598e-06, 2.65206268e-07, 5.22311723e-08,\n",
       "            4.13346548e-08, 3.37351906e-07],\n",
       "           [5.90275694e-03, 5.83977671e-03, 9.87830341e-01,\n",
       "            3.86477215e-04, 3.61060956e-05, 3.85778685e-06,\n",
       "            6.30387660e-07, 1.52303037e-09, 9.99080749e-11,\n",
       "            1.03963081e-10, 9.77833786e-11],\n",
       "           [8.38605314e-03, 3.60914128e-04, 1.24529563e-03,\n",
       "            9.83288705e-01, 6.14187727e-03, 5.50467987e-04,\n",
       "            1.63546993e-05, 9.73106671e-06, 5.02683235e-07,\n",
       "            1.69181718e-08, 1.24714417e-08],\n",
       "           [5.58984978e-03, 2.53860399e-05, 1.34793005e-03,\n",
       "            7.81879544e-01, 1.98241755e-01, 1.18397065e-02,\n",
       "            5.51969977e-04, 5.18278102e-04, 4.80616018e-06,\n",
       "            5.52913207e-07, 1.04807825e-07],\n",
       "           [2.12203525e-03, 1.01880269e-05, 5.04443794e-03,\n",
       "            1.09904436e-02, 6.86969887e-03, 1.79021299e-01,\n",
       "            7.29083538e-01, 5.62161133e-02, 8.82291235e-03,\n",
       "            5.51568752e-04, 1.26774586e-03],\n",
       "           [1.03161847e-05, 5.91735215e-07, 1.65124133e-04,\n",
       "            1.07580388e-04, 1.57160139e-05, 7.83044752e-03,\n",
       "            9.77548540e-01, 1.10278735e-02, 2.93816882e-03,\n",
       "            2.77797546e-04, 7.78173780e-05],\n",
       "           [1.93797473e-06, 7.09455250e-08, 7.57141606e-06,\n",
       "            3.90917412e-05, 1.34862512e-05, 1.26286121e-02,\n",
       "            9.29091871e-01, 2.16753315e-02, 3.63118835e-02,\n",
       "            2.08457757e-04, 2.16809840e-05],\n",
       "           [9.14944849e-06, 6.98497047e-08, 2.42194631e-07,\n",
       "            3.36023339e-04, 3.63677791e-05, 1.36607629e-03,\n",
       "            2.37913616e-02, 3.53075057e-01, 5.32468915e-01,\n",
       "            5.29054031e-02, 3.60112861e-02],\n",
       "           [1.55098334e-07, 6.19157969e-09, 2.58456296e-08,\n",
       "            1.72141927e-06, 2.21672472e-05, 6.93613954e-04,\n",
       "            1.35920029e-02, 3.14271040e-02, 9.40550089e-01,\n",
       "            9.95062012e-03, 3.76248523e-03],\n",
       "           [9.45575175e-06, 2.55418286e-07, 5.32901765e-07,\n",
       "            4.36282789e-05, 2.55565974e-05, 8.47902920e-05,\n",
       "            1.81122345e-03, 4.96634841e-02, 6.65242672e-02,\n",
       "            2.15961665e-01, 6.65875196e-01],\n",
       "           [6.02087039e-06, 6.23593132e-06, 2.71780882e-05,\n",
       "            1.04356786e-06, 3.75326345e-05, 1.71089141e-05,\n",
       "            1.27091436e-04, 6.28213515e-04, 1.43832772e-03,\n",
       "            3.71185094e-02, 9.60592687e-01]],\n",
       "  \n",
       "          [[1.23148978e-01, 6.61451459e-01, 1.00891672e-01,\n",
       "            8.47018808e-02, 2.83389762e-02, 9.83051956e-04,\n",
       "            4.27437335e-04, 2.09835762e-05, 1.24176049e-05,\n",
       "            7.25945165e-06, 1.59273477e-05],\n",
       "           [9.05401632e-03, 4.80091609e-02, 9.40130234e-01,\n",
       "            2.33088527e-03, 4.18961223e-04, 2.30380883e-05,\n",
       "            3.36882113e-05, 9.06250364e-08, 2.20747012e-08,\n",
       "            1.18416370e-08, 1.24610198e-08],\n",
       "           [2.66314775e-01, 4.78752367e-02, 1.71515837e-01,\n",
       "            5.02948582e-01, 7.15448568e-03, 3.83515540e-03,\n",
       "            3.21319822e-04, 3.23487293e-05, 1.40864245e-06,\n",
       "            5.95343408e-07, 2.57179749e-07],\n",
       "           [1.64863169e-02, 6.13746757e-04, 1.37271388e-02,\n",
       "            1.56661764e-01, 7.61273801e-01, 4.33442146e-02,\n",
       "            5.52622275e-03, 1.73392543e-03, 5.51763922e-04,\n",
       "            5.99190025e-05, 2.11714832e-05],\n",
       "           [1.26620242e-03, 3.86237298e-06, 6.02968910e-04,\n",
       "            2.32049916e-02, 1.10550513e-02, 9.32782590e-01,\n",
       "            1.25963902e-02, 1.84598137e-02, 2.10569233e-05,\n",
       "            6.54682526e-06, 5.25868870e-07],\n",
       "           [2.85595743e-04, 7.25585851e-05, 1.01776666e-03,\n",
       "            5.92318131e-03, 9.41300578e-03, 1.34010777e-01,\n",
       "            7.55846798e-01, 4.27267104e-02, 4.67118360e-02,\n",
       "            3.58468341e-03, 4.07035637e-04],\n",
       "           [4.23316305e-05, 8.17165346e-06, 9.12220567e-05,\n",
       "            9.25907982e-04, 2.29561422e-03, 3.96058969e-02,\n",
       "            5.25507987e-01, 1.16998650e-01, 2.87804991e-01,\n",
       "            2.34115589e-02, 3.30764451e-03],\n",
       "           [2.56615254e-04, 1.00375082e-05, 1.56197581e-04,\n",
       "            4.68863454e-03, 2.28198618e-03, 8.71499404e-02,\n",
       "            1.64464101e-01, 5.20070374e-01, 1.77671120e-01,\n",
       "            3.77770439e-02, 5.47393970e-03],\n",
       "           [7.69718156e-07, 2.53094541e-08, 1.15971368e-07,\n",
       "            3.91710910e-06, 6.65640837e-05, 2.89878953e-04,\n",
       "            9.47466958e-03, 1.22994417e-02, 9.29477215e-01,\n",
       "            3.75182815e-02, 1.08690262e-02],\n",
       "           [3.24666071e-05, 6.31362354e-07, 3.48309499e-07,\n",
       "            2.71454104e-04, 2.48126383e-03, 1.84263487e-03,\n",
       "            1.17933168e-03, 1.16459318e-01, 3.52720618e-01,\n",
       "            3.10051262e-01, 2.14960709e-01],\n",
       "           [2.71444190e-02, 4.21895348e-02, 4.28773984e-02,\n",
       "            7.19921291e-02, 2.16364767e-02, 6.91324696e-02,\n",
       "            9.93321761e-02, 2.16214195e-01, 8.00768360e-02,\n",
       "            1.59891829e-01, 1.69512570e-01]],\n",
       "  \n",
       "          [[8.24881345e-02, 5.50991833e-01, 1.81835461e-02,\n",
       "            9.32762474e-02, 2.51493812e-01, 3.37345293e-03,\n",
       "            1.29782449e-04, 1.36551562e-05, 1.38816795e-05,\n",
       "            6.90912975e-06, 2.87253752e-05],\n",
       "           [3.14538777e-01, 5.98517321e-02, 2.97093004e-01,\n",
       "            3.03256720e-01, 2.46579256e-02, 4.48232837e-04,\n",
       "            1.38193616e-04, 4.01460466e-06, 1.00573079e-05,\n",
       "            7.54060750e-07, 6.60737498e-07],\n",
       "           [1.15757547e-02, 5.79627580e-04, 2.11313158e-01,\n",
       "            7.75303602e-01, 2.95602571e-04, 2.14441257e-04,\n",
       "            7.08267617e-04, 3.09086795e-06, 6.54918540e-06,\n",
       "            1.05740430e-08, 5.44448397e-09],\n",
       "           [1.13551533e-02, 8.21294438e-04, 2.33394057e-02,\n",
       "            2.02014729e-01, 7.16090977e-01, 4.09616195e-02,\n",
       "            1.98453339e-03, 2.24639499e-03, 1.14026794e-03,\n",
       "            3.33647076e-05, 1.21887442e-05],\n",
       "           [1.76945310e-02, 1.61946684e-06, 7.78148475e-04,\n",
       "            1.10274874e-01, 1.20563321e-02, 1.31778866e-01,\n",
       "            4.51484919e-01, 3.63090523e-02, 2.35217825e-01,\n",
       "            3.58893210e-03, 8.14815867e-04],\n",
       "           [1.33088062e-04, 2.08546766e-07, 7.41292170e-05,\n",
       "            1.22851552e-03, 3.86223895e-04, 2.69488548e-03,\n",
       "            8.61311734e-01, 4.76153009e-03, 1.28839627e-01,\n",
       "            4.69442835e-04, 1.00617573e-04],\n",
       "           [2.77857271e-05, 1.48992456e-07, 3.59883488e-05,\n",
       "            3.37031408e-04, 4.37310373e-04, 2.90492387e-03,\n",
       "            8.39389384e-01, 8.91560595e-03, 1.47612810e-01,\n",
       "            2.83069734e-04, 5.59866166e-05],\n",
       "           [1.07637516e-06, 6.16377838e-09, 5.32373519e-07,\n",
       "            1.03412465e-04, 1.30812521e-06, 1.71841530e-05,\n",
       "            1.31494459e-03, 4.76088841e-03, 9.91982758e-01,\n",
       "            1.30228384e-03, 5.15551015e-04],\n",
       "           [1.03373168e-05, 3.32426623e-07, 7.67057827e-06,\n",
       "            5.34411374e-05, 1.37820389e-04, 1.82304578e-03,\n",
       "            6.76375777e-02, 1.09053992e-01, 8.07038009e-01,\n",
       "            7.66342739e-03, 6.57439791e-03],\n",
       "           [1.60660306e-06, 2.03952712e-08, 2.91120266e-08,\n",
       "            2.52231371e-06, 5.48244589e-06, 8.44319147e-05,\n",
       "            8.12649305e-05, 5.91374598e-02, 1.68300733e-01,\n",
       "            2.92476386e-01, 4.79910105e-01],\n",
       "           [1.63762127e-06, 4.99126770e-07, 4.07645103e-07,\n",
       "            6.74005321e-07, 3.49261099e-05, 8.66861228e-06,\n",
       "            1.14661678e-04, 5.69685129e-04, 1.40152955e-02,\n",
       "            1.43785760e-01, 8.41467738e-01]],\n",
       "  \n",
       "          [[1.04893804e-01, 8.59875321e-01, 3.31942625e-02,\n",
       "            1.90214650e-03, 7.75309309e-05, 5.42320122e-05,\n",
       "            1.30996943e-06, 2.54735511e-07, 8.83250451e-08,\n",
       "            3.06236849e-08, 1.04465175e-06],\n",
       "           [2.41554826e-01, 3.83521885e-01, 3.22885126e-01,\n",
       "            4.88803424e-02, 2.43323436e-03, 6.74789306e-04,\n",
       "            4.15658033e-05, 5.55323277e-06, 1.39030760e-06,\n",
       "            3.10503111e-07, 9.20857531e-07],\n",
       "           [5.34281842e-02, 2.54378829e-04, 5.44322887e-03,\n",
       "            9.39902186e-01, 2.59977998e-04, 7.00913137e-04,\n",
       "            6.16434227e-06, 4.80544895e-06, 1.15063415e-07,\n",
       "            1.33391131e-09, 5.15701759e-10],\n",
       "           [2.48175417e-03, 1.46218290e-05, 3.08753573e-04,\n",
       "            8.88052285e-02, 8.98205519e-01, 9.58585273e-03,\n",
       "            1.17772579e-04, 4.48994193e-04, 2.93781286e-05,\n",
       "            1.63106074e-06, 5.49581046e-07],\n",
       "           [4.97195462e-04, 2.37403015e-07, 1.41747048e-04,\n",
       "            3.88467708e-03, 1.40819671e-02, 1.70532510e-01,\n",
       "            6.31813645e-01, 7.55501837e-02, 1.02363564e-01,\n",
       "            9.66698688e-04, 1.67611157e-04],\n",
       "           [5.58760948e-04, 6.11534369e-06, 9.14669712e-04,\n",
       "            4.96992143e-03, 4.18770869e-05, 6.96822535e-03,\n",
       "            9.38072562e-01, 9.86795314e-03, 3.84019986e-02,\n",
       "            1.49956453e-04, 4.79439586e-05],\n",
       "           [1.32577698e-04, 1.17033707e-07, 3.59613623e-05,\n",
       "            6.25029556e-04, 4.72590764e-04, 1.59737244e-02,\n",
       "            7.18556464e-01, 1.40470797e-02, 2.49686942e-01,\n",
       "            2.36507636e-04, 2.32965729e-04],\n",
       "           [5.76056618e-06, 1.89770000e-09, 1.13876382e-07,\n",
       "            2.80308413e-05, 1.25730512e-04, 2.83487811e-04,\n",
       "            1.68186184e-02, 2.91624926e-02, 9.33607101e-01,\n",
       "            1.36876088e-02, 6.28108764e-03],\n",
       "           [6.90627348e-06, 1.84763127e-09, 7.33121794e-08,\n",
       "            4.34646245e-06, 4.14475426e-06, 2.22458024e-04,\n",
       "            1.27639500e-02, 1.31462468e-02, 9.66145575e-01,\n",
       "            2.99513782e-03, 4.71124658e-03],\n",
       "           [1.76981672e-07, 1.24194512e-08, 1.19604024e-08,\n",
       "            9.55193791e-09, 9.32750572e-06, 7.20858361e-06,\n",
       "            1.87918340e-05, 3.00437468e-03, 1.11015672e-02,\n",
       "            4.34969246e-01, 5.50889254e-01],\n",
       "           [1.17263726e-05, 2.37746615e-04, 1.33635385e-05,\n",
       "            1.61734988e-06, 7.07107247e-05, 2.89586606e-05,\n",
       "            3.63849802e-04, 7.22601835e-04, 7.52511807e-03,\n",
       "            1.43344849e-01, 8.47679436e-01]],\n",
       "  \n",
       "          [[1.61889344e-02, 5.39449513e-01, 2.95714170e-01,\n",
       "            1.42067987e-02, 7.52936862e-03, 1.17417626e-01,\n",
       "            2.88109737e-03, 6.02091616e-03, 1.75027511e-04,\n",
       "            2.25867145e-04, 1.90668681e-04],\n",
       "           [6.24522604e-02, 7.36849606e-02, 5.78697562e-01,\n",
       "            2.18818691e-02, 1.05604000e-01, 1.27927110e-01,\n",
       "            2.53238380e-02, 3.71117168e-03, 9.53208655e-05,\n",
       "            3.12634802e-04, 3.09263414e-04],\n",
       "           [4.32892377e-03, 7.96287262e-04, 2.51754206e-02,\n",
       "            1.24609843e-01, 2.78033257e-01, 5.46707511e-01,\n",
       "            1.32171297e-03, 1.89385712e-02, 6.03682420e-05,\n",
       "            2.24032174e-05, 5.67251254e-06],\n",
       "           [4.48882201e-04, 7.73419888e-05, 1.70146476e-03,\n",
       "            2.74173077e-02, 1.36598393e-01, 7.16870725e-01,\n",
       "            2.13565100e-02, 9.33505967e-02, 1.80095062e-03,\n",
       "            3.27492569e-04, 5.04075142e-05],\n",
       "           [1.84772391e-04, 1.07269043e-05, 5.56893356e-05,\n",
       "            5.57482941e-04, 6.30429685e-02, 7.78042197e-01,\n",
       "            7.83493668e-02, 7.15921968e-02, 7.36514665e-03,\n",
       "            6.91442634e-04, 1.08005202e-04],\n",
       "           [1.10192930e-04, 5.84172130e-06, 1.40999124e-04,\n",
       "            7.92500505e-04, 1.98835228e-02, 6.73779622e-02,\n",
       "            6.29491210e-01, 1.49400324e-01, 6.81108460e-02,\n",
       "            5.14634140e-02, 1.32231489e-02],\n",
       "           [1.69334398e-05, 2.14316606e-06, 1.10613882e-05,\n",
       "            1.72538770e-04, 2.50403653e-03, 5.51483408e-02,\n",
       "            3.06588471e-01, 3.00788879e-01, 2.96929687e-01,\n",
       "            2.94089671e-02, 8.42888001e-03],\n",
       "           [2.04099633e-05, 7.90975355e-06, 1.33309240e-05,\n",
       "            2.91270524e-04, 2.49426952e-03, 3.19533460e-02,\n",
       "            4.03455198e-02, 4.96853828e-01, 2.70666242e-01,\n",
       "            1.11015119e-01, 4.63386849e-02],\n",
       "           [1.78609898e-05, 4.55382497e-06, 6.66459209e-06,\n",
       "            6.16184479e-05, 1.80381956e-03, 8.30127206e-03,\n",
       "            4.97001149e-02, 2.04877004e-01, 4.04724658e-01,\n",
       "            1.96324274e-01, 1.34178117e-01],\n",
       "           [7.69876897e-06, 9.35436128e-06, 3.23300264e-06,\n",
       "            3.23133063e-05, 9.16988938e-04, 1.48323085e-03,\n",
       "            3.78609635e-03, 7.03342408e-02, 1.01682119e-01,\n",
       "            4.19117481e-01, 4.02627230e-01],\n",
       "           [1.93525208e-04, 4.73058457e-03, 1.98074660e-04,\n",
       "            9.78242970e-05, 6.57392025e-04, 6.51590060e-04,\n",
       "            1.60163548e-03, 6.73018815e-03, 9.86725371e-03,\n",
       "            3.48506361e-01, 6.26765549e-01]],\n",
       "  \n",
       "          [[8.93283859e-02, 5.28417528e-01, 2.65292674e-01,\n",
       "            1.14636116e-01, 1.94324052e-03, 2.14863976e-04,\n",
       "            1.57449394e-04, 1.72371267e-06, 3.65402343e-06,\n",
       "            5.49594517e-07, 3.82450798e-06],\n",
       "           [1.07572861e-01, 9.43775550e-02, 6.75645113e-01,\n",
       "            1.20081298e-01, 2.01512408e-03, 2.02312411e-04,\n",
       "            1.04867140e-04, 4.06530091e-07, 3.07806715e-07,\n",
       "            2.94471416e-08, 4.94303229e-08],\n",
       "           [2.22207665e-01, 4.10930952e-03, 5.05391769e-02,\n",
       "            5.27838051e-01, 1.56691760e-01, 3.72801460e-02,\n",
       "            1.13057753e-03, 1.57313640e-04, 4.45133628e-05,\n",
       "            1.01837679e-06, 4.15158297e-07],\n",
       "           [1.71745836e-03, 8.90161027e-06, 3.95026337e-03,\n",
       "            2.89692893e-03, 2.20365331e-01, 7.23009169e-01,\n",
       "            2.86876410e-03, 4.44041640e-02, 6.81890117e-04,\n",
       "            5.42330999e-05, 4.30593536e-05],\n",
       "           [1.65749283e-04, 1.25397282e-05, 1.34544549e-04,\n",
       "            2.55600270e-03, 1.10753058e-02, 1.13518843e-02,\n",
       "            9.57607031e-01, 2.43869890e-03, 1.41510302e-02,\n",
       "            4.02645208e-04, 1.04596795e-04],\n",
       "           [1.69671546e-06, 5.34542210e-07, 4.12682812e-06,\n",
       "            9.43330160e-05, 3.27276386e-04, 1.73061751e-04,\n",
       "            9.20703292e-01, 5.11202845e-04, 7.71000534e-02,\n",
       "            9.62923747e-04, 1.21415127e-04],\n",
       "           [7.46558044e-06, 1.89749684e-07, 8.49380649e-06,\n",
       "            2.78793130e-04, 4.08509783e-02, 3.13713029e-02,\n",
       "            8.06695446e-02, 1.74227625e-01, 6.51435077e-01,\n",
       "            1.91859677e-02, 1.96457910e-03],\n",
       "           [1.25042834e-05, 2.60894126e-07, 7.02482339e-06,\n",
       "            1.75588619e-04, 2.15125550e-02, 1.34371361e-02,\n",
       "            5.34772314e-02, 2.93466777e-01, 5.38035214e-01,\n",
       "            6.85017854e-02, 1.13739073e-02],\n",
       "           [2.12090367e-06, 3.77144467e-08, 3.32947207e-06,\n",
       "            2.20612637e-05, 2.65903631e-03, 4.38744342e-03,\n",
       "            3.87564767e-03, 2.34883606e-01, 6.28736079e-01,\n",
       "            1.02789976e-01, 2.26406176e-02],\n",
       "           [9.82640245e-07, 4.99897283e-07, 7.12794645e-07,\n",
       "            1.60208833e-06, 4.62642201e-05, 2.19157191e-05,\n",
       "            5.11561567e-03, 1.11648459e-02, 9.62191820e-02,\n",
       "            6.37877882e-01, 2.49550462e-01],\n",
       "           [1.04053297e-05, 3.57514597e-04, 8.60447835e-05,\n",
       "            8.51053392e-06, 1.17584204e-05, 5.18762090e-06,\n",
       "            8.84298293e-04, 3.85278603e-04, 8.51503946e-03,\n",
       "            8.57304633e-02, 9.04005408e-01]],\n",
       "  \n",
       "          [[6.76849112e-02, 8.57307851e-01, 5.24527542e-02,\n",
       "            2.25355439e-02, 3.78389268e-06, 1.25879087e-05,\n",
       "            2.43911632e-06, 7.40550021e-08, 1.59610136e-09,\n",
       "            4.50545983e-08, 9.80054651e-08],\n",
       "           [7.23944083e-02, 1.94100793e-02, 8.69434536e-01,\n",
       "            3.70338894e-02, 6.95973926e-04, 9.37077508e-04,\n",
       "            9.33749616e-05, 5.77806020e-07, 1.51721871e-08,\n",
       "            6.82821399e-09, 3.61059005e-09],\n",
       "           [3.83194955e-03, 5.70204575e-05, 2.63674650e-03,\n",
       "            9.93174136e-01, 8.71405646e-05, 2.07844438e-04,\n",
       "            2.18730020e-06, 3.00158672e-06, 2.79741510e-08,\n",
       "            1.22947597e-09, 1.40539635e-10],\n",
       "           [4.34318965e-04, 1.60810785e-07, 1.29599342e-04,\n",
       "            2.54583196e-03, 9.37591136e-01, 5.47642782e-02,\n",
       "            1.11701118e-03, 3.12182261e-03, 2.90848693e-04,\n",
       "            4.69793076e-06, 3.52921916e-07],\n",
       "           [3.36394260e-05, 2.39861397e-09, 2.14531738e-05,\n",
       "            5.55329374e-04, 1.59219513e-03, 9.24418986e-01,\n",
       "            4.29785512e-02, 3.03015411e-02, 8.43960443e-05,\n",
       "            1.34768006e-05, 4.73568775e-07],\n",
       "           [1.02793483e-05, 7.13753110e-08, 2.19694066e-05,\n",
       "            5.52962185e-04, 8.47329211e-05, 4.06874828e-02,\n",
       "            6.76897705e-01, 2.14456320e-01, 6.32770807e-02,\n",
       "            3.95864761e-03, 5.27972916e-05],\n",
       "           [3.36456196e-07, 5.17732412e-10, 3.26504392e-07,\n",
       "            1.50842216e-05, 1.77439506e-05, 2.77063884e-02,\n",
       "            2.40247220e-01, 5.69516957e-01, 1.57806545e-01,\n",
       "            4.59344639e-03, 9.59495228e-05],\n",
       "           [4.42555893e-06, 9.29124244e-09, 8.36426977e-07,\n",
       "            2.62005982e-04, 7.53584100e-05, 4.21080366e-03,\n",
       "            9.80390329e-03, 6.08962953e-01, 2.46749640e-01,\n",
       "            1.23700038e-01, 6.22998737e-03],\n",
       "           [2.44050486e-08, 3.14199049e-11, 2.98957437e-09,\n",
       "            1.07647509e-06, 4.75553225e-06, 4.18505631e-04,\n",
       "            1.27471087e-03, 3.09350342e-01, 6.40563488e-01,\n",
       "            4.57892902e-02, 2.59781233e-03],\n",
       "           [1.84645913e-07, 3.65833652e-09, 1.82410940e-08,\n",
       "            5.87031309e-07, 4.44630359e-07, 5.65165510e-06,\n",
       "            6.74841749e-06, 1.49745680e-02, 1.76655352e-02,\n",
       "            7.31935799e-01, 2.35410467e-01],\n",
       "           [6.71168091e-05, 6.84123777e-04, 4.06735526e-05,\n",
       "            4.22745097e-06, 9.52327264e-06, 1.11125395e-04,\n",
       "            3.66527471e-04, 1.08350802e-03, 5.65244118e-04,\n",
       "            8.96112248e-02, 9.07456696e-01]],\n",
       "  \n",
       "          [[1.01781860e-01, 8.14103127e-01, 8.06850344e-02,\n",
       "            2.45608389e-03, 5.94055920e-04, 3.32770695e-04,\n",
       "            2.66313396e-06, 1.69535974e-06, 1.77132065e-07,\n",
       "            1.39845645e-06, 4.11030996e-05],\n",
       "           [2.42309645e-02, 9.74267498e-02, 8.50082934e-01,\n",
       "            2.34942492e-02, 4.52575507e-03, 2.04214230e-04,\n",
       "            3.33939206e-05, 9.20991624e-07, 2.39725864e-07,\n",
       "            1.53740331e-07, 4.41958576e-07],\n",
       "           [6.99683428e-02, 2.07296591e-02, 1.12961575e-01,\n",
       "            7.49385118e-01, 3.51899453e-02, 1.10444268e-02,\n",
       "            4.92013991e-04, 1.39201817e-04, 8.90565352e-05,\n",
       "            4.76954028e-07, 2.85938228e-07],\n",
       "           [2.65869498e-02, 2.57631508e-03, 5.73161058e-02,\n",
       "            8.60580355e-02, 6.65289521e-01, 1.47641823e-01,\n",
       "            7.22159306e-03, 6.29604748e-03, 9.16401041e-04,\n",
       "            6.96317584e-05, 2.76409191e-05],\n",
       "           [9.85120609e-03, 1.75379810e-05, 2.21426832e-03,\n",
       "            1.72642283e-02, 2.00765003e-02, 8.93908858e-01,\n",
       "            3.21966968e-02, 2.33068559e-02, 1.12600322e-03,\n",
       "            2.59969675e-05, 1.17683476e-05],\n",
       "           [7.35563799e-06, 2.35998286e-07, 3.38429381e-05,\n",
       "            7.42282646e-05, 4.47504368e-04, 2.11743619e-02,\n",
       "            2.36126676e-01, 1.92383632e-01, 5.33465624e-01,\n",
       "            1.10470243e-02, 5.23944059e-03],\n",
       "           [8.24626454e-07, 1.52201540e-09, 4.78626418e-07,\n",
       "            9.81288395e-05, 1.70304367e-04, 6.89815264e-03,\n",
       "            3.76486301e-01, 6.18717112e-02, 5.51130593e-01,\n",
       "            3.08757881e-03, 2.55876046e-04],\n",
       "           [5.96325435e-07, 4.58787452e-09, 1.98265198e-07,\n",
       "            1.18468624e-05, 1.76100482e-04, 1.74597895e-03,\n",
       "            3.95732373e-03, 1.07812725e-01, 8.80906999e-01,\n",
       "            4.55264142e-03, 8.35606596e-04],\n",
       "           [1.35585793e-07, 4.63934696e-10, 5.76667558e-09,\n",
       "            7.35946003e-07, 3.03334091e-05, 2.47286807e-04,\n",
       "            1.39020511e-03, 3.94901745e-02, 9.42334950e-01,\n",
       "            1.24365613e-02, 4.06959234e-03],\n",
       "           [2.77752952e-06, 2.62836028e-08, 3.08550376e-08,\n",
       "            1.09176426e-07, 1.50922460e-05, 7.83946423e-04,\n",
       "            9.65015788e-05, 2.90517002e-01, 1.26585796e-01,\n",
       "            2.29032636e-01, 3.52966070e-01],\n",
       "           [1.65461213e-04, 1.21090146e-04, 3.62031933e-05,\n",
       "            6.50074298e-06, 2.11668375e-05, 9.93788824e-04,\n",
       "            1.07426173e-03, 4.67206677e-03, 7.80669739e-04,\n",
       "            9.44821313e-02, 8.97646606e-01]]]], dtype=float32)>,\n",
       "  'decoder_layer4_block1': <tf.Tensor: shape=(1, 8, 11, 11), dtype=float32, numpy=\n",
       "  array([[[[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [9.76875067e-01, 2.31248979e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.62009865e-02, 9.02905047e-01, 3.08939721e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.54293144e-01, 3.45192403e-01, 9.08865035e-02,\n",
       "            3.09627980e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.45177290e-02, 8.43133032e-03, 8.88299465e-01,\n",
       "            2.71171667e-02, 1.16343033e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [9.54138413e-02, 3.96579914e-02, 1.03208952e-01,\n",
       "            1.16860099e-01, 1.05858192e-01, 5.39000928e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.25162946e-02, 1.27875600e-02, 4.20382572e-03,\n",
       "            1.45838633e-02, 2.64256060e-01, 6.87782705e-01,\n",
       "            3.86965577e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.19470286e-02, 6.42228201e-02, 2.63025075e-01,\n",
       "            1.24036185e-02, 2.88202241e-02, 1.33531779e-01,\n",
       "            3.07186246e-01, 1.08863220e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.06005895e-02, 1.86877385e-01, 1.51088275e-02,\n",
       "            6.17606416e-02, 8.95323679e-02, 1.06794320e-01,\n",
       "            3.26190919e-01, 7.28551075e-02, 6.02799021e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.96512833e-02, 6.52183592e-02, 1.05450660e-01,\n",
       "            1.24494471e-02, 2.04913095e-02, 2.52346266e-02,\n",
       "            6.33387983e-01, 1.98891051e-02, 2.53515653e-02,\n",
       "            2.28755791e-02, 0.00000000e+00],\n",
       "           [4.77495678e-02, 1.20799411e-02, 2.82869518e-01,\n",
       "            1.77581329e-02, 1.34596927e-02, 2.52804570e-02,\n",
       "            3.18028815e-02, 4.78559323e-02, 3.74787971e-02,\n",
       "            8.12476426e-02, 4.02417481e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.40217030e-01, 2.59783000e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.99070132e-01, 1.60980240e-01, 2.39949629e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.31867862e-01, 1.93921134e-01, 1.42204940e-01,\n",
       "            1.32006034e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.39832535e-01, 1.08626157e-01, 6.53405860e-02,\n",
       "            4.01556969e-01, 1.84643775e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.61009383e-01, 3.28905322e-02, 4.45613861e-02,\n",
       "            1.39356285e-01, 8.45293850e-02, 2.37653062e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.09697950e-01, 2.96635740e-02, 4.21069339e-02,\n",
       "            1.56295255e-01, 1.01680636e-01, 1.43876076e-01,\n",
       "            1.16679616e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.67744789e-02, 1.35544187e-03, 4.70348122e-03,\n",
       "            2.05284115e-02, 2.87917275e-02, 7.33161196e-02,\n",
       "            8.28875244e-01, 5.65519556e-03, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.64370322e-01, 2.32947301e-02, 2.95537077e-02,\n",
       "            9.47977975e-02, 3.87621298e-02, 1.29781574e-01,\n",
       "            3.03299546e-01, 4.64387499e-02, 6.97015226e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.21771172e-02, 6.18985330e-04, 1.19931716e-03,\n",
       "            3.97835160e-03, 7.07173813e-03, 9.07764807e-02,\n",
       "            7.28702664e-01, 1.96831021e-02, 9.17632580e-02,\n",
       "            4.40289490e-02, 0.00000000e+00],\n",
       "           [3.80294211e-02, 2.87852180e-03, 5.95554011e-03,\n",
       "            4.43727057e-03, 3.10718380e-02, 6.58255219e-02,\n",
       "            1.83126003e-01, 7.02562416e-03, 3.83339194e-03,\n",
       "            7.92021677e-03, 6.49896681e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.29460870e-02, 9.47053969e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.94832406e-03, 9.43917572e-01, 5.11340238e-02,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.48358822e-01, 5.37508428e-01, 1.75551414e-01,\n",
       "            1.38581336e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.00966934e-03, 6.47282079e-02, 3.79449390e-02,\n",
       "            4.59313899e-01, 4.33003277e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.27272341e-02, 2.41918843e-02, 7.85644203e-02,\n",
       "            2.62745589e-01, 3.85886490e-01, 2.15884387e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.24615128e-03, 1.87862257e-03, 1.23289004e-02,\n",
       "            1.98045024e-03, 4.68901591e-03, 1.87170021e-02,\n",
       "            9.59159851e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.78190884e-05, 7.70386192e-04, 7.50678650e-04,\n",
       "            7.17488816e-04, 3.26651521e-02, 1.09973766e-01,\n",
       "            7.89795339e-01, 6.52693808e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.19433098e-03, 5.69582125e-03, 1.18675176e-03,\n",
       "            2.38826801e-03, 2.14577746e-02, 9.11770388e-02,\n",
       "            8.48004222e-01, 2.04701833e-02, 8.42569210e-03,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.46128336e-03, 1.18132226e-01, 8.56086705e-03,\n",
       "            6.38736039e-02, 1.13172978e-01, 8.48597512e-02,\n",
       "            1.64261103e-01, 2.03806877e-01, 3.17241810e-02,\n",
       "            2.04147130e-01, 0.00000000e+00],\n",
       "           [1.43745005e-01, 2.52331663e-02, 1.91547964e-02,\n",
       "            1.17727049e-01, 1.25976596e-02, 5.04982471e-02,\n",
       "            1.20145408e-02, 1.99578013e-02, 4.23288494e-02,\n",
       "            3.65244299e-01, 1.91498548e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [9.85983193e-01, 1.40168015e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.45856905e-01, 5.90701923e-02, 5.95072865e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.74136356e-01, 3.20250876e-02, 7.60718226e-01,\n",
       "            3.31202820e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.70397377e-02, 3.35183577e-03, 9.01230276e-01,\n",
       "            2.46952735e-02, 1.36829177e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.41528252e-02, 5.38479863e-03, 4.61619616e-01,\n",
       "            2.70459577e-02, 1.35935709e-01, 2.85861075e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.87324991e-02, 4.82428493e-03, 9.59249362e-02,\n",
       "            2.50604413e-02, 5.15121639e-01, 3.22495878e-01,\n",
       "            7.84028973e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.67544785e-03, 2.05017044e-03, 1.31534457e-01,\n",
       "            5.23932697e-03, 7.48976367e-03, 4.17487174e-02,\n",
       "            3.74058783e-02, 7.71856189e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.04205012e-02, 7.47057097e-03, 4.09881361e-02,\n",
       "            9.28175915e-03, 2.77449600e-02, 6.35338053e-02,\n",
       "            5.92032485e-02, 6.10116780e-01, 1.71240285e-01,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.83307488e-04, 2.46904237e-05, 4.20859875e-03,\n",
       "            1.54951194e-04, 5.05449425e-04, 1.13188138e-03,\n",
       "            6.80943718e-04, 2.65446934e-03, 4.04574722e-03,\n",
       "            9.86209929e-01, 0.00000000e+00],\n",
       "           [8.03517643e-03, 9.21243578e-02, 1.01697445e-01,\n",
       "            5.68235014e-03, 2.82197464e-02, 6.80127740e-02,\n",
       "            9.07273740e-02, 2.20362738e-01, 6.99120685e-02,\n",
       "            1.51588574e-01, 1.63637370e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.69560593e-01, 5.30439377e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.18087754e-01, 7.33658373e-01, 1.48253873e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.30517173e-01, 2.15286121e-01, 1.43074453e-01,\n",
       "            3.11122298e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.02244878e-01, 3.70384485e-01, 9.18289572e-02,\n",
       "            1.10703200e-01, 2.24838465e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.23023435e-01, 8.06859508e-02, 5.59095554e-02,\n",
       "            6.61366656e-02, 5.53475857e-01, 1.20768577e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.47235560e-01, 5.07348739e-02, 3.95307988e-02,\n",
       "            5.41534945e-02, 1.22517772e-01, 1.89430803e-01,\n",
       "            1.96396753e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.16245508e-01, 1.39071971e-01, 5.17089628e-02,\n",
       "            6.92339167e-02, 1.38314471e-01, 1.12118743e-01,\n",
       "            3.01158011e-01, 7.21483827e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.09605515e-02, 4.15345356e-02, 7.86145553e-02,\n",
       "            6.31816164e-02, 1.65175050e-01, 2.16350779e-01,\n",
       "            5.54181673e-02, 2.82906026e-01, 2.58587413e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.09229847e-02, 1.02534123e-01, 2.21349578e-02,\n",
       "            5.78004904e-02, 2.87173241e-01, 1.04428813e-01,\n",
       "            6.24829717e-02, 5.97584434e-02, 3.07283700e-02,\n",
       "            2.42035627e-01, 0.00000000e+00],\n",
       "           [8.24322626e-02, 1.58513889e-01, 1.29312113e-01,\n",
       "            1.91559084e-02, 9.25642345e-03, 3.80509682e-02,\n",
       "            1.10026048e-02, 3.78746241e-02, 7.04246946e-03,\n",
       "            2.99560111e-02, 4.77402747e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.94221580e-01, 2.05778405e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.01338376e-03, 8.35523754e-03, 9.87631381e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.47918533e-02, 2.11966597e-02, 6.21006072e-01,\n",
       "            3.23005408e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.22234601e-02, 4.76478413e-03, 6.67076707e-02,\n",
       "            7.41225362e-01, 1.05078734e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.13496237e-01, 1.22469077e-02, 8.45801737e-03,\n",
       "            4.51839566e-02, 5.70604622e-01, 2.50010222e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [3.08797024e-02, 1.49771031e-02, 4.73910663e-03,\n",
       "            6.92770351e-03, 5.02985179e-01, 1.74996465e-01,\n",
       "            2.64494777e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.36838324e-04, 5.25652358e-05, 6.02807151e-03,\n",
       "            9.29244515e-03, 4.07392625e-03, 9.58189368e-03,\n",
       "            5.06439283e-02, 9.20190334e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.63555157e-01, 1.93454809e-02, 4.44015628e-03,\n",
       "            2.53354888e-02, 1.55977219e-01, 7.10007027e-02,\n",
       "            9.01989415e-02, 1.45125374e-01, 2.50213798e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.03567452e-05, 6.55262329e-06, 9.11272145e-05,\n",
       "            4.30364191e-04, 5.60397530e-06, 3.04842270e-05,\n",
       "            1.52121560e-04, 1.07014868e-02, 4.48825653e-04,\n",
       "            9.88113105e-01, 0.00000000e+00],\n",
       "           [7.11706653e-03, 2.28621555e-03, 1.63533911e-03,\n",
       "            7.67345680e-03, 6.32677507e-03, 1.41405850e-03,\n",
       "            4.43607569e-03, 1.55711044e-02, 6.04594778e-03,\n",
       "            7.62653500e-02, 8.71228576e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [4.44523990e-01, 5.55476010e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.49215916e-01, 3.79896551e-01, 3.70887518e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [8.49803686e-02, 2.77794693e-02, 6.62964404e-01,\n",
       "            2.24275753e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.30511025e-01, 2.74303406e-01, 9.47114378e-02,\n",
       "            2.52451539e-01, 1.48022503e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.56664640e-01, 4.31981266e-01, 9.85289514e-02,\n",
       "            1.10559054e-01, 7.30514824e-02, 1.29214615e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.14212506e-01, 5.57049997e-02, 3.32919508e-02,\n",
       "            3.14095803e-02, 9.42424908e-02, 8.75971466e-02,\n",
       "            5.83541274e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.46331140e-01, 1.56916216e-01, 1.14132032e-01,\n",
       "            1.96732029e-01, 9.50342715e-02, 1.01285160e-01,\n",
       "            5.14955297e-02, 3.80736627e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.04891805e-02, 5.82232978e-03, 8.52255747e-02,\n",
       "            1.87823083e-02, 1.22799147e-02, 2.08850894e-02,\n",
       "            1.15503162e-01, 6.67053044e-01, 5.39593548e-02,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [9.03049409e-02, 8.37869123e-02, 2.09953934e-01,\n",
       "            1.55791551e-01, 5.06700352e-02, 1.54649317e-01,\n",
       "            8.57582688e-03, 6.80462867e-02, 4.02902439e-02,\n",
       "            1.37930974e-01, 0.00000000e+00],\n",
       "           [3.70530672e-02, 4.23647510e-03, 1.15531022e-02,\n",
       "            2.61082184e-02, 1.61501989e-02, 8.46142471e-02,\n",
       "            1.68894064e-02, 1.15405647e-02, 2.13503577e-02,\n",
       "            1.36458566e-02, 7.56858528e-01]],\n",
       "  \n",
       "          [[1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.15475588e-01, 8.84524345e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.99447019e-03, 3.13791893e-02, 9.60626364e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.07160978e-01, 2.93129310e-02, 6.29949629e-01,\n",
       "            2.33576402e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [5.62742315e-02, 4.71339561e-02, 3.58479053e-01,\n",
       "            4.53762084e-01, 8.43506902e-02, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [7.88282230e-03, 2.21319329e-02, 1.66469254e-02,\n",
       "            6.10706024e-02, 6.76990330e-01, 2.15277404e-01,\n",
       "            0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [1.09195185e-03, 1.05107250e-03, 1.94824312e-03,\n",
       "            3.15087172e-03, 1.89812537e-02, 2.39964612e-02,\n",
       "            9.49780107e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [6.23066863e-03, 1.25362817e-02, 6.05241619e-02,\n",
       "            7.97173232e-02, 2.30705421e-02, 2.25614030e-02,\n",
       "            6.23490289e-03, 7.89124668e-01, 0.00000000e+00,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.37644687e-02, 4.58367285e-04, 2.20665205e-02,\n",
       "            2.86718439e-02, 7.80422473e-04, 4.05184925e-03,\n",
       "            2.83509251e-02, 6.67875230e-01, 2.23980308e-01,\n",
       "            0.00000000e+00, 0.00000000e+00],\n",
       "           [2.53933929e-02, 2.35905629e-02, 1.49884857e-02,\n",
       "            2.20195413e-01, 2.19252463e-02, 2.02314425e-02,\n",
       "            1.30319772e-02, 4.84343171e-02, 2.38636881e-01,\n",
       "            3.73572230e-01, 0.00000000e+00],\n",
       "           [1.75559020e-03, 1.45566592e-03, 8.39822809e-04,\n",
       "            4.10241628e-04, 6.45975524e-05, 1.40418089e-03,\n",
       "            4.69306251e-04, 1.67070146e-04, 9.86840751e-05,\n",
       "            3.86999338e-04, 9.92947817e-01]]]], dtype=float32)>,\n",
       "  'decoder_layer4_block2': <tf.Tensor: shape=(1, 8, 11, 11), dtype=float32, numpy=\n",
       "  array([[[[2.54415994e-04, 9.96727467e-01, 2.93690013e-03,\n",
       "            7.74136206e-05, 1.95037074e-07, 3.13239730e-06,\n",
       "            3.21097218e-07, 3.05621342e-08, 2.73008749e-09,\n",
       "            1.55471831e-08, 1.06799355e-07],\n",
       "           [1.17934458e-02, 1.49362842e-02, 9.63404894e-01,\n",
       "            5.45301801e-03, 2.30909092e-03, 1.82409352e-03,\n",
       "            2.65673967e-04, 1.20259692e-05, 1.44333782e-07,\n",
       "            5.85042073e-07, 7.25790073e-07],\n",
       "           [7.53445970e-03, 1.33881767e-04, 1.58404727e-02,\n",
       "            9.15179849e-01, 4.45001805e-03, 5.12598604e-02,\n",
       "            2.60617962e-04, 5.15491934e-03, 1.76488815e-04,\n",
       "            4.77751519e-06, 4.66403662e-06],\n",
       "           [2.60387012e-03, 2.77681629e-05, 3.80359287e-03,\n",
       "            3.94600891e-02, 8.59739125e-01, 6.92203715e-02,\n",
       "            2.16639750e-02, 3.03344033e-03, 4.23484395e-04,\n",
       "            2.17917823e-05, 2.38303573e-06],\n",
       "           [2.20737216e-04, 5.56427176e-06, 5.52995247e-04,\n",
       "            1.24750147e-03, 5.90751925e-03, 9.48660493e-01,\n",
       "            9.17819142e-03, 3.40598412e-02, 1.16886804e-04,\n",
       "            2.89334457e-05, 2.13496132e-05],\n",
       "           [1.38453950e-04, 2.76406994e-04, 3.29145929e-03,\n",
       "            4.01082769e-04, 4.15493778e-05, 4.34212107e-03,\n",
       "            9.87048566e-01, 2.97018187e-03, 1.20993331e-03,\n",
       "            1.63921490e-04, 1.16357754e-04],\n",
       "           [2.58758191e-05, 7.09196274e-06, 7.94259540e-05,\n",
       "            8.23063820e-05, 9.85265011e-04, 9.29999747e-04,\n",
       "            9.94124472e-01, 7.02837599e-04, 2.74878042e-03,\n",
       "            2.59024469e-04, 5.49420838e-05],\n",
       "           [8.20848276e-04, 6.26319379e-05, 8.45309580e-04,\n",
       "            9.07084998e-03, 1.87545493e-02, 5.31326197e-02,\n",
       "            2.95398474e-01, 3.14357400e-01, 2.60630697e-01,\n",
       "            3.54729407e-02, 1.14537487e-02],\n",
       "           [9.61264504e-06, 2.66836757e-08, 4.55252439e-06,\n",
       "            1.80465591e-04, 4.14374750e-03, 6.54773146e-04,\n",
       "            8.71540606e-02, 1.72317550e-02, 8.76878500e-01,\n",
       "            9.52343643e-03, 4.21908731e-03],\n",
       "           [1.13816152e-03, 4.13968257e-04, 1.91671905e-04,\n",
       "            1.58578693e-03, 7.66893027e-06, 5.52787620e-04,\n",
       "            3.70890903e-03, 1.76885560e-01, 5.40741198e-02,\n",
       "            2.66027510e-01, 4.95413870e-01],\n",
       "           [6.21363567e-03, 3.05324420e-02, 7.66334217e-03,\n",
       "            1.29540032e-03, 5.61306998e-03, 1.07189668e-02,\n",
       "            5.47175016e-03, 2.63914019e-02, 6.64873468e-03,\n",
       "            1.73903033e-01, 7.25548267e-01]],\n",
       "  \n",
       "          [[3.04383673e-02, 8.30881000e-01, 1.33986950e-01,\n",
       "            1.03498786e-03, 2.33806670e-03, 6.84978848e-04,\n",
       "            5.53474645e-04, 1.41904238e-05, 9.00398027e-06,\n",
       "            8.62791603e-06, 5.02730691e-05],\n",
       "           [3.28823067e-02, 5.83545677e-03, 9.54465985e-01,\n",
       "            4.29361407e-03, 2.25025625e-03, 3.44995969e-05,\n",
       "            2.36399341e-04, 9.01243084e-07, 3.40750404e-07,\n",
       "            6.36108766e-08, 5.26640065e-08],\n",
       "           [5.73566444e-02, 1.25989309e-02, 1.35106459e-01,\n",
       "            3.45174432e-01, 1.78119808e-01, 4.06846590e-02,\n",
       "            1.83204293e-01, 6.86051603e-03, 4.02361751e-02,\n",
       "            3.84186977e-04, 2.73927901e-04],\n",
       "           [8.23670160e-03, 3.66890687e-04, 1.06693059e-02,\n",
       "            1.02672368e-01, 8.44992578e-01, 1.12006022e-02,\n",
       "            7.59308832e-03, 2.63347593e-03, 1.11379679e-02,\n",
       "            3.27549787e-04, 1.69382431e-04],\n",
       "           [7.80359376e-03, 1.44737656e-04, 1.01007149e-02,\n",
       "            1.14907464e-02, 5.48160933e-02, 3.50876860e-02,\n",
       "            8.63703787e-01, 3.35391145e-03, 1.30796637e-02,\n",
       "            3.06710484e-04, 1.12467758e-04],\n",
       "           [3.18042177e-04, 5.04477612e-05, 1.40186748e-03,\n",
       "            4.35606635e-05, 1.77811908e-05, 2.01804796e-03,\n",
       "            9.94450808e-01, 1.05986814e-03, 5.79172978e-04,\n",
       "            4.02771911e-05, 2.02114315e-05],\n",
       "           [1.38245145e-04, 1.82824406e-05, 1.11585425e-03,\n",
       "            1.51196233e-04, 4.78243397e-04, 1.33199268e-03,\n",
       "            9.74393845e-01, 2.01327144e-03, 1.83706861e-02,\n",
       "            1.29992224e-03, 6.88580214e-04],\n",
       "           [2.34534498e-03, 5.13698760e-05, 1.24232448e-03,\n",
       "            4.86304145e-03, 6.73988461e-02, 8.92646890e-03,\n",
       "            1.37383476e-01, 7.28504136e-02, 5.80855429e-01,\n",
       "            8.55685100e-02, 3.85148115e-02],\n",
       "           [8.79690197e-06, 2.24851693e-09, 2.87505543e-07,\n",
       "            1.69225477e-05, 2.64737173e-04, 4.99921225e-05,\n",
       "            2.84705055e-03, 1.80973171e-03, 9.93819773e-01,\n",
       "            7.85587763e-04, 3.97155934e-04],\n",
       "           [1.56749651e-04, 5.17291619e-06, 1.13613294e-06,\n",
       "            1.03809516e-05, 3.68935493e-04, 1.98305701e-03,\n",
       "            2.28131819e-03, 1.43837810e-01, 3.49833012e-01,\n",
       "            1.97135419e-01, 3.04387033e-01],\n",
       "           [9.44393163e-04, 1.58162825e-02, 9.74641938e-04,\n",
       "            4.46544582e-04, 8.34402349e-03, 5.87417511e-03,\n",
       "            3.74775031e-03, 1.09527614e-02, 3.90563831e-02,\n",
       "            1.56736583e-01, 7.57106483e-01]],\n",
       "  \n",
       "          [[3.32114935e-01, 5.64202964e-01, 5.50664254e-02,\n",
       "            4.58137877e-02, 1.61458261e-03, 8.82280292e-04,\n",
       "            1.64079160e-04, 9.35159278e-06, 2.56886892e-06,\n",
       "            2.51455622e-05, 1.03826547e-04],\n",
       "           [7.20431097e-03, 4.25803335e-03, 9.21258748e-01,\n",
       "            2.62259524e-02, 2.72387825e-02, 1.89037749e-03,\n",
       "            1.18883671e-02, 2.56352560e-05, 6.49859112e-06,\n",
       "            1.90655055e-06, 1.50536039e-06],\n",
       "           [1.14900451e-02, 8.19510035e-03, 2.57413667e-02,\n",
       "            6.52816966e-02, 7.87414253e-01, 2.83739977e-02,\n",
       "            2.13863347e-02, 8.10766220e-03, 4.21192385e-02,\n",
       "            8.92038457e-04, 9.98432282e-04],\n",
       "           [4.84819539e-05, 3.17134763e-05, 2.58066750e-04,\n",
       "            6.69627392e-04, 9.97873306e-01, 1.01144996e-03,\n",
       "            5.52844467e-05, 3.62467472e-05, 1.45982121e-05,\n",
       "            9.84626467e-07, 1.79707541e-07],\n",
       "           [6.84460774e-02, 2.43566756e-05, 2.42165360e-03,\n",
       "            6.22497313e-02, 5.52720249e-01, 1.32007852e-01,\n",
       "            2.54499968e-02, 6.28691912e-02, 6.57550320e-02,\n",
       "            2.03681830e-02, 7.68765947e-03],\n",
       "           [8.25253036e-03, 5.49334101e-04, 1.00584896e-02,\n",
       "            8.85502342e-03, 1.02290725e-02, 1.81043416e-01,\n",
       "            4.25435424e-01, 1.51196688e-01, 4.94997278e-02,\n",
       "            9.81100500e-02, 5.67702353e-02],\n",
       "           [1.83870376e-04, 5.88652147e-05, 9.34872311e-03,\n",
       "            2.64758454e-03, 1.09462300e-03, 3.96791706e-03,\n",
       "            9.77075219e-01, 8.92580429e-04, 4.62624570e-03,\n",
       "            8.20819623e-05, 2.24091236e-05],\n",
       "           [5.56312152e-04, 4.87082107e-05, 2.50331289e-03,\n",
       "            7.83983245e-03, 4.09671478e-02, 5.05111460e-03,\n",
       "            3.95907372e-01, 1.42093562e-02, 5.00133157e-01,\n",
       "            2.60683317e-02, 6.71538338e-03],\n",
       "           [7.60887087e-06, 1.53282841e-07, 8.92861499e-06,\n",
       "            7.48697494e-05, 3.32061143e-04, 4.76747868e-04,\n",
       "            6.14086203e-02, 5.20134903e-03, 9.31977153e-01,\n",
       "            4.29437205e-04, 8.31431971e-05],\n",
       "           [3.53034557e-05, 2.15921887e-06, 3.77378683e-06,\n",
       "            3.63261752e-05, 6.13994780e-04, 1.14073162e-04,\n",
       "            3.32788040e-05, 7.47767044e-03, 2.63912473e-02,\n",
       "            5.06256998e-01, 4.59035188e-01],\n",
       "           [1.26833944e-02, 4.19174833e-03, 2.46952428e-03,\n",
       "            1.71661645e-03, 1.41053600e-03, 1.18709286e-03,\n",
       "            1.56247162e-03, 8.13902635e-03, 6.88176602e-03,\n",
       "            1.74440667e-01, 7.85317123e-01]],\n",
       "  \n",
       "          [[1.69811659e-02, 9.52117980e-01, 2.86998879e-02,\n",
       "            1.78343616e-03, 1.00622303e-04, 2.92917393e-04,\n",
       "            2.10884427e-05, 9.92465061e-07, 5.58554696e-08,\n",
       "            1.86556903e-07, 1.68481881e-06],\n",
       "           [2.83430994e-01, 3.14020738e-02, 1.60523146e-01,\n",
       "            9.27167684e-02, 3.18814099e-01, 1.08804807e-01,\n",
       "            2.73158913e-03, 1.36159523e-03, 1.29330569e-04,\n",
       "            4.09147979e-05, 4.46522863e-05],\n",
       "           [1.99491993e-01, 3.71049345e-03, 1.88205242e-02,\n",
       "            4.08390462e-01, 8.91923830e-02, 2.70032346e-01,\n",
       "            1.04315295e-04, 9.80153400e-03, 3.56455421e-04,\n",
       "            5.45904877e-05, 4.49245745e-05],\n",
       "           [4.86846635e-04, 9.21330229e-06, 2.09426202e-04,\n",
       "            3.75624094e-03, 9.77758408e-01, 1.70947593e-02,\n",
       "            3.78447803e-05, 5.44861890e-04, 1.00186007e-04,\n",
       "            1.62709307e-06, 6.45265970e-07],\n",
       "           [1.61553640e-03, 2.76349037e-05, 4.94635198e-04,\n",
       "            4.41781478e-03, 1.18710855e-02, 9.11125720e-01,\n",
       "            1.98146654e-03, 6.76970109e-02, 2.82475841e-04,\n",
       "            3.40878789e-04, 1.45778351e-04],\n",
       "           [3.83563456e-04, 7.40290052e-05, 5.18453307e-04,\n",
       "            3.38711325e-05, 5.27808850e-04, 1.92210209e-02,\n",
       "            8.27419758e-01, 2.57925149e-02, 7.08632246e-02,\n",
       "            4.22846489e-02, 1.28810210e-02],\n",
       "           [3.36706667e-04, 6.40373764e-05, 4.48661012e-04,\n",
       "            3.41197709e-04, 5.51341195e-03, 1.43675087e-02,\n",
       "            3.76379728e-01, 2.05072686e-02, 5.51882565e-01,\n",
       "            2.42782477e-02, 5.88069204e-03],\n",
       "           [1.22946268e-03, 1.15487401e-05, 3.20360734e-04,\n",
       "            1.68843276e-03, 7.98241422e-03, 7.33135119e-02,\n",
       "            1.14348806e-01, 2.81312644e-01, 3.23025674e-01,\n",
       "            1.63057789e-01, 3.37093882e-02],\n",
       "           [5.61968773e-06, 1.44747299e-08, 5.50170569e-07,\n",
       "            1.03081029e-05, 3.36628495e-04, 2.92511395e-04,\n",
       "            8.19260255e-04, 4.57059359e-03, 9.89647329e-01,\n",
       "            3.81477340e-03, 5.02453942e-04],\n",
       "           [8.61502599e-07, 2.26821726e-07, 3.75496768e-07,\n",
       "            1.11856842e-07, 1.31635966e-06, 3.22206251e-05,\n",
       "            8.27171025e-05, 6.95050880e-03, 3.56211178e-02,\n",
       "            4.36853647e-01, 5.20456910e-01],\n",
       "           [7.21799256e-03, 2.17652824e-02, 5.76861482e-03,\n",
       "            2.79330788e-03, 3.46147572e-03, 7.82115571e-03,\n",
       "            6.09702757e-03, 2.53530499e-02, 1.07347611e-02,\n",
       "            1.71632439e-01, 7.37354994e-01]],\n",
       "  \n",
       "          [[4.88421065e-04, 9.93793488e-01, 2.18542013e-03,\n",
       "            3.49079608e-03, 1.04245773e-05, 4.54959854e-06,\n",
       "            2.64267401e-05, 4.52792115e-08, 3.82302900e-08,\n",
       "            6.88744564e-08, 2.48386016e-07],\n",
       "           [1.52845345e-02, 2.31076572e-02, 8.87598455e-01,\n",
       "            8.26115347e-03, 4.69701476e-02, 1.63356727e-03,\n",
       "            1.70748401e-02, 2.61065961e-05, 1.47639057e-05,\n",
       "            1.39500989e-05, 1.48983008e-05],\n",
       "           [3.44645698e-03, 1.67186698e-03, 3.98216490e-03,\n",
       "            9.90302384e-01, 3.20062711e-04, 2.44160794e-04,\n",
       "            1.96702895e-05, 1.25742254e-05, 4.34276188e-07,\n",
       "            1.12818618e-07, 6.03048136e-08],\n",
       "           [4.92044084e-04, 1.49711595e-05, 2.11277351e-04,\n",
       "            5.59713983e-04, 9.97439384e-01, 1.24993210e-03,\n",
       "            3.34066704e-06, 2.81301491e-05, 9.36000049e-07,\n",
       "            2.14456037e-07, 5.03267117e-08],\n",
       "           [7.68027327e-04, 6.72231836e-05, 3.82320909e-03,\n",
       "            1.83212832e-02, 5.40459305e-02, 1.27388433e-01,\n",
       "            7.71262467e-01, 1.34136193e-02, 1.00951111e-02,\n",
       "            5.38013992e-04, 2.76634906e-04],\n",
       "           [4.61718514e-07, 6.35223898e-07, 5.09516804e-06,\n",
       "            1.77934078e-06, 2.71675020e-07, 7.10724953e-06,\n",
       "            9.99898672e-01, 1.43921216e-05, 4.46139929e-05,\n",
       "            1.66261307e-05, 1.02244312e-05],\n",
       "           [2.83615918e-05, 1.08987324e-05, 1.84406468e-04,\n",
       "            1.92083287e-04, 1.83619140e-05, 8.71509954e-04,\n",
       "            9.92366970e-01, 1.10434566e-03, 4.43920586e-03,\n",
       "            5.64002141e-04, 2.19898880e-04],\n",
       "           [6.95157505e-04, 2.57898819e-06, 4.28226718e-04,\n",
       "            6.62168907e-03, 2.51386175e-03, 2.60386635e-02,\n",
       "            4.72122729e-02, 3.61907423e-01, 4.63737667e-01,\n",
       "            7.06468374e-02, 2.01956723e-02],\n",
       "           [5.95785514e-06, 1.44537127e-09, 2.76341751e-07,\n",
       "            6.81834172e-06, 4.73216118e-04, 2.93168961e-03,\n",
       "            2.46370956e-03, 8.55552852e-02, 9.05305624e-01,\n",
       "            2.06849375e-03, 1.18891278e-03],\n",
       "           [1.08209417e-04, 6.34114895e-06, 4.04882894e-06,\n",
       "            2.78489926e-04, 5.65933369e-05, 2.29124373e-04,\n",
       "            6.93410286e-04, 1.66859403e-02, 2.10098084e-03,\n",
       "            4.01497900e-01, 5.78338981e-01],\n",
       "           [7.27649545e-03, 8.04899633e-02, 1.87140275e-02,\n",
       "            1.72969364e-02, 2.70141382e-02, 9.84260999e-03,\n",
       "            1.48157747e-02, 8.81505758e-03, 2.13951222e-03,\n",
       "            1.41721711e-01, 6.71873748e-01]],\n",
       "  \n",
       "          [[1.89745292e-01, 7.63629258e-01, 2.94612292e-02,\n",
       "            1.42155886e-02, 2.63079978e-03, 2.91132455e-04,\n",
       "            7.46521482e-06, 2.08367078e-06, 1.06273532e-07,\n",
       "            5.82853272e-06, 1.11902536e-05],\n",
       "           [3.92294735e-01, 5.82913309e-03, 4.72692400e-01,\n",
       "            9.36803445e-02, 3.08632106e-02, 3.09172249e-03,\n",
       "            9.17384285e-04, 1.96872046e-04, 2.30538455e-04,\n",
       "            1.48395455e-04, 5.51924386e-05],\n",
       "           [2.42827758e-01, 1.45753697e-02, 4.16205153e-02,\n",
       "            3.38027924e-01, 3.47132504e-01, 1.20191602e-02,\n",
       "            9.79668577e-04, 7.71676947e-04, 1.50581752e-03,\n",
       "            4.59231320e-04, 8.04235751e-05],\n",
       "           [7.29268510e-03, 1.31185472e-04, 1.37194886e-03,\n",
       "            1.33690368e-02, 9.67231035e-01, 1.02909077e-02,\n",
       "            1.22391706e-04, 1.53995279e-04, 2.25374752e-05,\n",
       "            1.20111281e-05, 2.20780817e-06],\n",
       "           [2.13508066e-02, 3.38282848e-06, 1.40856474e-03,\n",
       "            1.11799147e-02, 7.27662265e-01, 1.15137398e-01,\n",
       "            3.68413292e-02, 2.69681178e-02, 3.86855677e-02,\n",
       "            1.90884564e-02, 1.67416746e-03],\n",
       "           [8.57532676e-03, 2.39873247e-04, 1.45293237e-03,\n",
       "            1.16464999e-02, 4.68480177e-02, 7.57435337e-02,\n",
       "            1.95340872e-01, 8.81407931e-02, 3.63753647e-01,\n",
       "            1.70034647e-01, 3.82238589e-02],\n",
       "           [6.38186641e-04, 1.45095109e-04, 6.06468355e-04,\n",
       "            9.47985612e-03, 1.10330041e-02, 5.01594171e-02,\n",
       "            5.62726676e-01, 3.74621078e-02, 3.14486921e-01,\n",
       "            1.06490245e-02, 2.61330581e-03],\n",
       "           [2.21269391e-03, 3.20567742e-05, 3.71637318e-04,\n",
       "            6.66652946e-03, 2.56310217e-02, 5.76336794e-02,\n",
       "            8.83151889e-02, 1.63249478e-01, 5.43088615e-01,\n",
       "            1.00208297e-01, 1.25907538e-02],\n",
       "           [6.36726463e-06, 4.81289604e-08, 8.76560307e-07,\n",
       "            3.97982149e-05, 8.42025795e-04, 9.38865342e-05,\n",
       "            1.34943100e-03, 1.24625885e-03, 9.91692543e-01,\n",
       "            4.17433679e-03, 5.54483384e-04],\n",
       "           [1.43590572e-04, 4.61712443e-06, 1.54466907e-05,\n",
       "            4.39667783e-05, 1.58790522e-03, 1.31819033e-04,\n",
       "            1.50847307e-04, 6.18462497e-03, 4.41829972e-02,\n",
       "            5.51025391e-01, 3.96528751e-01],\n",
       "           [2.96884519e-03, 4.17879812e-04, 1.09930173e-03,\n",
       "            1.91028899e-04, 2.31997762e-03, 7.30665342e-04,\n",
       "            8.15380423e-04, 3.87672079e-03, 5.20118140e-03,\n",
       "            2.72680461e-01, 7.09698617e-01]],\n",
       "  \n",
       "          [[1.73282865e-02, 9.62632954e-01, 4.82759019e-03,\n",
       "            1.17498934e-02, 3.00053624e-03, 1.93676897e-04,\n",
       "            9.46537984e-05, 1.60475083e-05, 1.88674603e-05,\n",
       "            6.66965425e-05, 7.07180079e-05],\n",
       "           [2.01307133e-01, 2.09366810e-02, 7.59134889e-01,\n",
       "            1.44608095e-02, 1.29108794e-03, 3.97155469e-04,\n",
       "            2.43839365e-03, 2.44584626e-05, 2.69815337e-06,\n",
       "            3.89167508e-06, 2.86008253e-06],\n",
       "           [2.08276547e-02, 4.43736382e-04, 3.35354288e-03,\n",
       "            9.61089790e-01, 1.14558125e-02, 1.60072581e-03,\n",
       "            2.33572515e-04, 3.45868088e-04, 6.00092229e-04,\n",
       "            3.54363146e-05, 1.38510932e-05],\n",
       "           [1.31081175e-02, 4.88610640e-05, 4.48353589e-04,\n",
       "            6.82523753e-03, 9.75994229e-01, 3.02466704e-03,\n",
       "            4.32145825e-05, 2.94145982e-04, 1.35116745e-04,\n",
       "            6.74889234e-05, 1.05965637e-05],\n",
       "           [7.18085468e-02, 1.13612907e-04, 8.25646333e-03,\n",
       "            2.76049763e-01, 1.47173122e-01, 3.56134027e-01,\n",
       "            5.50618842e-02, 5.69039807e-02, 2.57939454e-02,\n",
       "            2.07622186e-03, 6.28399896e-04],\n",
       "           [2.32755672e-02, 3.20787728e-03, 1.17333680e-02,\n",
       "            4.66955118e-02, 1.25375791e-02, 1.31523013e-02,\n",
       "            6.75109267e-01, 1.83499716e-02, 9.58061144e-02,\n",
       "            7.56025165e-02, 2.45299302e-02],\n",
       "           [7.04341210e-06, 1.25310471e-05, 3.91037320e-04,\n",
       "            1.61071493e-05, 1.54289810e-05, 1.44850594e-04,\n",
       "            9.97144759e-01, 9.17040597e-05, 2.01747240e-03,\n",
       "            1.07825472e-04, 5.13290979e-05],\n",
       "           [7.43480958e-03, 1.15420728e-04, 1.47235664e-02,\n",
       "            1.89178772e-02, 6.03806488e-02, 4.08815034e-02,\n",
       "            5.08425295e-01, 1.11800134e-01, 1.91609263e-01,\n",
       "            3.08854301e-02, 1.48260416e-02],\n",
       "           [4.91907485e-06, 4.73229989e-09, 3.69534177e-07,\n",
       "            1.97869304e-05, 4.62511554e-03, 8.60840519e-05,\n",
       "            1.76186755e-03, 1.20611652e-03, 9.91299689e-01,\n",
       "            7.74659682e-04, 2.21513619e-04],\n",
       "           [3.16951046e-04, 8.02211525e-06, 1.42728040e-05,\n",
       "            1.54002360e-03, 3.14913387e-03, 6.95131428e-04,\n",
       "            1.59995383e-04, 4.53530736e-02, 1.60681054e-01,\n",
       "            3.83402348e-01, 4.04679894e-01],\n",
       "           [7.36914994e-03, 1.36762077e-03, 9.61261394e-04,\n",
       "            3.33193759e-03, 2.71164142e-02, 3.29357833e-02,\n",
       "            2.97257677e-03, 1.78051695e-01, 5.34912162e-02,\n",
       "            3.62867266e-01, 3.29535067e-01]],\n",
       "  \n",
       "          [[2.17418641e-01, 7.13093638e-01, 2.91056782e-02,\n",
       "            2.45721024e-02, 1.49741704e-02, 7.49300234e-04,\n",
       "            4.42974897e-06, 2.15283126e-05, 2.12552595e-06,\n",
       "            1.31718843e-05, 4.53383946e-05],\n",
       "           [8.21224153e-02, 1.29890265e-02, 5.78099370e-01,\n",
       "            2.27291882e-01, 9.65507850e-02, 1.84968475e-03,\n",
       "            8.74361955e-04, 7.87727186e-05, 7.80159098e-05,\n",
       "            4.97482833e-05, 1.58955172e-05],\n",
       "           [4.18275828e-03, 4.88427177e-05, 1.26402767e-03,\n",
       "            1.02505889e-02, 9.83397961e-01, 7.00634497e-04,\n",
       "            8.27302392e-06, 4.91461469e-05, 7.64451033e-05,\n",
       "            1.78032060e-05, 3.34995343e-06],\n",
       "           [2.44847888e-05, 1.02855313e-06, 2.47868065e-05,\n",
       "            1.09225053e-04, 9.99792874e-01, 4.47037783e-05,\n",
       "            4.01787730e-07, 1.71199815e-06, 7.53604297e-07,\n",
       "            7.66623529e-08, 1.92049452e-08],\n",
       "           [4.07678150e-02, 5.17502958e-05, 4.54028184e-03,\n",
       "            3.21220309e-02, 3.02650988e-01, 4.78625298e-01,\n",
       "            4.83259326e-03, 1.16675787e-01, 2.72704783e-04,\n",
       "            1.63994599e-02, 3.06129758e-03],\n",
       "           [1.41760614e-02, 6.23804342e-04, 7.91327097e-03,\n",
       "            7.32447160e-03, 3.03549524e-02, 1.56317547e-01,\n",
       "            3.77350926e-01, 2.00849935e-01, 6.92424253e-02,\n",
       "            1.20424144e-01, 1.54223535e-02],\n",
       "           [4.45457590e-05, 1.78214723e-05, 1.19995384e-04,\n",
       "            1.99780057e-04, 3.33242328e-03, 5.68080635e-04,\n",
       "            4.88043278e-02, 3.04322713e-03, 9.39029515e-01,\n",
       "            3.93689563e-03, 9.03504610e-04],\n",
       "           [2.40638779e-04, 1.99163878e-06, 7.98760506e-04,\n",
       "            4.59032890e-04, 1.87331755e-02, 3.52471322e-03,\n",
       "            8.74827281e-02, 2.75315456e-02, 6.30681694e-01,\n",
       "            2.17150897e-01, 1.33948419e-02],\n",
       "           [5.75058436e-07, 2.74514300e-10, 5.65767557e-08,\n",
       "            2.31421882e-06, 9.10489543e-05, 4.76064815e-06,\n",
       "            1.81063486e-04, 5.69051132e-04, 9.83648181e-01,\n",
       "            1.43498406e-02, 1.15311181e-03],\n",
       "           [4.75540355e-06, 3.53812055e-08, 6.39504037e-07,\n",
       "            4.46417289e-07, 1.57520306e-04, 2.02165465e-05,\n",
       "            2.29445559e-05, 1.92544283e-03, 3.95852746e-03,\n",
       "            8.76354754e-01, 1.17554694e-01],\n",
       "           [1.12924948e-02, 2.83844280e-03, 1.04509934e-03,\n",
       "            3.46650905e-03, 1.17533607e-02, 5.09237032e-03,\n",
       "            3.72559560e-04, 2.75256895e-02, 2.61713890e-03,\n",
       "            1.54280424e-01, 7.79715836e-01]]]], dtype=float32)>})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(tf.constant(sentence),max_length=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f2440",
   "metadata": {},
   "source": [
    "## Attention plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad34c0e6",
   "metadata": {},
   "source": [
    "The `Translator` class returns a dictionary of attention maps you can use to visualize the internal working of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "63526e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : este é o primeiro livro que eu fiz.\n",
      "Prediction     : this is the first book i did .\n",
      "Ground truth   : this is the first book i've ever done.\n"
     ]
    }
   ],
   "source": [
    "sentence = 'este é o primeiro livro que eu fiz.'\n",
    "ground_truth = \"this is the first book i've ever done.\"\n",
    "\n",
    "translated_text, translated_tokens, attention_weights = translator(\n",
    "    tf.constant(sentence),max_length=25)\n",
    "print_translation(sentence, translated_text, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6f85ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_head(in_tokens, translated_tokens, attention):\n",
    "  # The plot is of the attention when a token was generated.\n",
    "  # The model didn't generate `<START>` in the output. Skip it.\n",
    "  translated_tokens = translated_tokens[1:]\n",
    "\n",
    "  ax = plt.gca()\n",
    "  ax.matshow(attention)\n",
    "  ax.set_xticks(range(len(in_tokens)))\n",
    "  ax.set_yticks(range(len(translated_tokens)))\n",
    "\n",
    "  labels = [label.decode('utf-8') for label in in_tokens.numpy()]\n",
    "  ax.set_xticklabels(\n",
    "      labels, rotation=90)\n",
    "\n",
    "  labels = [label.decode('utf-8') for label in translated_tokens.numpy()]\n",
    "  ax.set_yticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aae6841f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([9, 11])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = 0\n",
    "# shape: (batch=1, num_heads, seq_len_q, seq_len_k)\n",
    "attention_heads = tf.squeeze(\n",
    "  attention_weights['decoder_layer4_block2'], 0)\n",
    "attention = attention_heads[head]\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "51ec75e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(11,), dtype=string, numpy=\n",
       "array([b'[START]', b'este', b'e', b'o', b'primeiro', b'livro', b'que',\n",
       "       b'eu', b'fiz', b'.', b'[END]'], dtype=object)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_tokens = tf.convert_to_tensor([sentence])\n",
    "in_tokens = tokenizers.pt.tokenize(in_tokens).to_tensor()\n",
    "in_tokens = tokenizers.pt.lookup(in_tokens)[0]\n",
    "in_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95ba22a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
       "array([b'[START]', b'this', b'is', b'the', b'first', b'book', b'i',\n",
       "       b'did', b'.', b'[END]'], dtype=object)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fa394924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention_head(in_tokens, translated_tokens, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "092fe221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(sentence, translated_tokens, attention_heads):\n",
    "  in_tokens = tf.convert_to_tensor([sentence])\n",
    "  in_tokens = tokenizers.pt.tokenize(in_tokens).to_tensor()\n",
    "  in_tokens = tokenizers.pt.lookup(in_tokens)[0]\n",
    "  in_tokens\n",
    "\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "  for h, head in enumerate(attention_heads):\n",
    "    ax = fig.add_subplot(2, 4, h+1)\n",
    "\n",
    "    plot_attention_head(in_tokens, translated_tokens, head)\n",
    "\n",
    "    ax.set_xlabel(f'Head {h+1}')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "00ae5823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention_weights(sentence, translated_tokens,\n",
    "                       attention_weights['decoder_layer4_block2'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ed98a",
   "metadata": {},
   "source": [
    "The model does okay on unfamiliar words. Neither \"triceratops\" or \"encyclopedia\" are in the input dataset and the model almost learns to transliterate them, even without a shared vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "580e777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : Eu li sobre triceratops na enciclopédia.\n",
      "Prediction     : i read about thriumps in the ecloom and hater .\n",
      "Ground truth   : I read about triceratops in the encyclopedia.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = 'Eu li sobre triceratops na enciclopédia.'\n",
    "ground_truth = 'I read about triceratops in the encyclopedia.'\n",
    "\n",
    "translated_text, translated_tokens, attention_weights = translator(\n",
    "    tf.constant(sentence))\n",
    "print_translation(sentence, translated_text, ground_truth)\n",
    "\n",
    "plot_attention_weights(sentence, translated_tokens,\n",
    "                       attention_weights['decoder_layer4_block2'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e051d4bd",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc0379c",
   "metadata": {},
   "source": [
    "That inference model is working, so next you'll export it as a `tf.saved_model`.\n",
    "\n",
    "To do that, wrap it in yet another `tf.Module` sub-class, this time with a `tf.function` on the `__call__` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ff46bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportTranslator(tf.Module):\n",
    "  def __init__(self, translator):\n",
    "    self.translator = translator\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "  def __call__(self, sentence):\n",
    "    (result,\n",
    "     tokens,\n",
    "     attention_weights) = self.translator(sentence, max_length=MAX_TOKENS)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b97c3",
   "metadata": {},
   "source": [
    "In the above `tf.function` only the output sentence is returned. Thanks to the [non-strict execution](https://tensorflow.org/guide/intro_to_graphs) in `tf.function` any unnecessary values are never computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "37e61fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = ExportTranslator(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86265e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ff519864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'this is the first book i did .'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator('este é o primeiro livro que eu fiz.').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4dfa875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_7_layer_call_fn, embedding_7_layer_call_and_return_conditional_losses, dropout_62_layer_call_fn, dropout_62_layer_call_and_return_conditional_losses, embedding_8_layer_call_fn while saving (showing 5 of 224). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(translator, export_dir='translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9706bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = tf.saved_model.load('translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "50e9507b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'this is the first book i did .'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded('este é o primeiro livro que eu fiz.').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018687a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "28351a7ac9c5c3f87d7e2cfd5b1f967c228653fc23bb7a0997ca4e9b6c4c6b30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
